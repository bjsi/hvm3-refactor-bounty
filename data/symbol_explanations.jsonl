{"name": "ATerm", "explanation": "The `ATerm` type, defined as `_Atomic(Term)`, represents a 64-bit unsigned integer that acts as a node in the computational graph within the HVM3 runtime. It is stored in the global heap (`HVM.heap`), which is shared across multiple threads during parallel execution. The atomic nature of `ATerm` ensures thread-safe updates to the heap, preventing data corruption or inconsistent states during concurrent operations like memory allocation (`allocNode`) or term manipulation (`set`, `got`). This atomicity is crucial for maintaining the integrity of the computational graph while enabling efficient parallel computation in the HVM3 runtime."}
{"name": "Bin", "explanation": "The `Bin` data type is a recursive structure with two constructors, `O` and `I`, each taking another `Bin` as an argument to form bit-strings of arbitrary length. For instance, `O (I (O E))` represents the bit-string \"010\", where `E` denotes the empty bit-string. In the `Collapse` monad, `Bin` is used to manage paths during parallel computations. The `fork` function in the `bind` operation leverages `Bin` to track and manipulate paths through the computation graph. Functions like `putO` and `putI` prepend `O` and `I` to existing bit-strings, respectively, enabling the construction and transformation of paths as the computation progresses. This mechanism ensures efficient handling of multiple parallel execution paths, ultimately reducing them to a single result or a list of results."}
{"name": "Book", "explanation": "The `Book` data structure is a central repository in the HVM3 runtime, storing function definitions and metadata essential for execution. It includes mappings such as `idToFunc'` (linking function IDs to definitions), `idToName'` (associating IDs with function names), `idToLabs'` (tracking labels for `DUP` and `SUP` operations), `nameToId'` (enabling name-to-ID lookups), and `ctrToAri`/`ctrToCid` (mapping constructors to their arity and IDs). Created during parsing, the `Book` is utilized across compilation, reduction, and execution phases, providing the necessary metadata for optimizing and executing terms. It ensures efficient handling of parallel computations by enabling quick access to function definitions and operational rules."}
{"name": "Collapse", "explanation": "The `Collapse` monad represents a tree structure for parallel computation, with three constructors: `CSup` for superposition (parallel evaluation), `CVal` for holding a single value, and `CEra` for representing an empty or erased value. Its core operation, `bind`, enables chaining computations by recursively applying a function to values within the structure, facilitating parallel evaluation. The monad is integral to the HVM3 runtime, supporting functions like `doCollapseAt` for reducing terms at specific graph locations and `doCollapseFlatAt` for flattening results into lists. It also offers flexible flattening strategies (`flattenDFS`, `flattenBFS`, `flattenPQ`) to adapt to different parallel computation needs. Overall, the `Collapse` monad efficiently manages parallel execution, making it a key component of the HVM3 system."}
{"name": "CompileState", "explanation": "The `CompileState` data type acts as the central state container for the compilation process in the HVM3 codebase. It is utilized within the `Compile` monad, a state monad that encapsulates the compilation logic, enabling the tracking and management of various compilation aspects such as counters, mappings, and intermediate results. The `compileWith` function initializes a `CompileState` with default values, ensuring a consistent starting point for the compilation process. By leveraging a state monad, the codebase maintains functional purity while allowing state updates in a composable manner, facilitating the transformation of high-level `Core` terms into efficient low-level C code. This design supports the codebase's emphasis on functional programming and efficient parallel execution."}
{"name": "Core", "explanation": "The `Core` data type serves as the foundational structure in the HVM3 codebase, representing the abstract syntax tree (AST) for functional programs. It defines key constructs such as variables (`Var`), function references (`Ref`), lambda abstractions (`Lam`), function applications (`App`), and superpositions (`Sup`), enabling the runtime to handle diverse operations. During compilation, `Core` facilitates the translation of high-level terms into low-level C code, while during execution, it supports term reduction to normal forms. Additionally, `Core` is integral to parsing and stringification, allowing terms to be read and displayed in a human-readable format. As the central representation of program structure, `Core` is indispensable for term manipulation, execution, and interaction within the HVM3 system."}
{"name": "DUP_f", "explanation": "The `DUP_f` function is a core component of the HVM3 runtime, responsible for creating `DUP` nodes that enable parallel computation. These nodes duplicate terms, allowing the runtime to distribute computations across multiple processing units, which is essential for leveraging parallelism in modern hardware. When invoked, `DUP_f` takes a `Term` reference and generates a new `DUP` node with a specified label. This node is then used by the runtime to manage parallel tasks efficiently. Registered in the `HVM.book` array, `DUP_f` ensures quick access and minimal overhead, making it a critical function for achieving high-performance parallel execution in the HVM3 system."}
{"name": "FRESH_f", "explanation": "The `FRESH_f` function is a placeholder in the HVM3 runtime designed to manage the creation and handling of fresh terms during the evaluation process. Fresh terms are unique references or nodes introduced during computation, particularly in parallel or concurrent reduction scenarios, to ensure correctness and avoid conflicts. While currently unimplemented (as indicated by the `TODO` message), `FRESH_f` is expected to interact with the runtime's memory management system (e.g., `allocNode`, `set`, `got`) to allocate and initialize new terms, integrating them into the computational graph. Once implemented, it will play a critical role in supporting the runtime's parallel execution model and maintaining the integrity of term reductions."}
{"name": "InjectState", "explanation": "The `InjectState` data type acts as the state container for the `InjectM` monad, facilitating state management during term injection or transformation in the HVM codebase. It typically holds metadata or mappings required for these operations, such as an empty map and list initialized by the `emptyState` function. This structure ensures that dynamic information, like context or metadata, is preserved and managed consistently throughout the injection process, maintaining correctness and integrity during term transformations in the HVM runtime."}
{"name": "LOG_f", "explanation": "The `LOG_f` function is a placeholder within the HVM3 runtime's C backend, intended for logging or debugging purposes. Currently, it is unimplemented and only outputs a \"TODO\" message, indicating that its functionality is yet to be developed. Registered in the `HVM.book` array during initialization (`hvm_init`), it is grouped with other core runtime functions like `SUP_f` and `DUP_f`, suggesting it will play a role in monitoring or debugging runtime behavior. Its exact implementation and integration into the system remain undefined."}
{"name": "Lab", "explanation": "The `Lab` type is a core component of the HVM3 runtime system, acting as a unique identifier for terms within the computational graph. It encodes metadata such as function IDs, constructor IDs, or other contextual information, enabling the runtime to efficiently identify and process terms during reduction. The `Lab` field is crucial for determining the type of term being processed (e.g., function application, constructor, or superposition) and applying the appropriate reduction rules. It also plays a key role in memory management, parallel computation, and compilation, ensuring efficient term manipulation, parallel execution, and optimized code generation. In the Interaction Combinator model, the `Lab` field facilitates parallel evaluation by handling specific interaction rules, making it essential for the system's ability to manage complex, parallel computations effectively."}
{"name": "Loc", "explanation": "The `Loc` type is a core element in the HVM3 runtime system, acting as a memory address or location identifier for terms within the computational graph. It is essential for memory management, enabling functions like `allocNode` to allocate memory and return a `Loc` representing the address of a new node. Additionally, `Loc` facilitates term access and manipulation through functions like `got` and `set`, which retrieve and modify terms at specific memory locations. It also supports parallel execution by managing term reductions in functions like `reduceAt` and `reduceRefAt`. During compilation, `Loc` values are generated to represent term memory locations in the compiled C code. In summary, `Loc` is pivotal for efficient memory handling, term manipulation, and parallel computation in the HVM3 runtime."}
{"name": "Mode", "explanation": "The `Mode` data type in the HVM3 codebase defines strategies for handling variable bindings during compilation or execution, particularly within the `Let` construct of the `Core` data type. It specifies how bindings should behave, such as being strict, lazy, or optimized for parallel execution. The `modeT` function converts a `Lab` (label) into a `Mode`, indicating that metadata associated with the term (e.g., type, role, or optimization requirements) influences the binding strategy. This dynamic adjustment allows the system to optimize performance and correctness based on the specific characteristics of the term. In essence, `Mode` enables flexible and efficient computation by tailoring the handling of variable bindings to the context or properties of the terms being processed."}
{"name": "Oper", "explanation": "The `Oper` data type represents a collection of binary operators used in the `Core` language of the HVM3 codebase. It includes arithmetic operators (e.g., `OP_ADD`, `OP_SUB`), logical operators (e.g., `OP_EQ`, `OP_AND`), and bitwise operators (e.g., `OP_LSH`, `OP_GT`). These operators are utilized in the `Op2` constructor of the `Core` type to define binary operations between two terms, such as `Op2 OP_ADD a b` for the expression `(+ a b)`. The `parseOper` function identifies operators from source code, while `operToString` converts them back to their string representations for debugging. `Oper` is essential for enabling and evaluating binary operations within the HVM3 computational graph."}
{"name": "PQ", "explanation": "The `PQ` data type represents a priority queue implemented as a binary heap, a structure designed to efficiently manage elements with associated priorities. It consists of two constructors: `PQLeaf`, representing an empty heap, and `PQNode`, representing a node containing a key-value pair (where the key, of type `Word64`, determines priority) and two child heaps. The `pqUnion` function merges two heaps while preserving the heap property, ensuring the smallest key remains at the root. The `pqPop` function extracts the highest-priority element (smallest key) and reconstructs the heap, while `pqPut` inserts a new key-value pair by merging it into the heap. These operations enable efficient priority-based element management, which is crucial for the parallel computation model in HVM3, particularly in functions like `flattenPQ` that process elements in priority order within the `Collapse` monad."}
{"name": "ParserState", "explanation": "The `ParserState` data type is a critical component in the HVM3 codebase, acting as the state container for the parser. It maintains context and metadata during the parsing of input programs into high-level `Core` terms or `Book` definitions. Initialized with empty structures and a counter, the state is dynamically updated as the parser processes the input, storing intermediate results such as function definitions and constructor mappings. These results are essential for subsequent compilation and execution phases. In functions like `doParseCore` and `doParseBook`, the `ParserState` is passed to `runParser`, which executes the parser and returns parsed results alongside the updated state. This state is then used to construct the `Book` data structure, which holds function definitions and metadata for the runtime. By preserving context and intermediate data, `ParserState` ensures the parsing process is context-aware and facilitates seamless downstream tasks."}
{"name": "RunMode", "explanation": "The `RunMode` data type in the HVM3 codebase specifies the execution mode for the runtime system, enabling control over evaluation strategies such as strict or lazy evaluation, as well as optimizations for parallel execution. By passing a `RunMode` value to functions like `cliRun`, users can tailor the runtime behavior to suit specific performance or debugging requirements. This flexibility is critical in a system optimized for massively parallel hardware, where execution strategies directly influence efficiency and resource utilization. `RunMode` thus serves as a key configuration tool for aligning runtime behavior with program and hardware needs."}
{"name": "SQ", "explanation": "The `SQ` data type is a functional queue implementation that uses two lists to maintain the order of elements. The first list (`xs`) represents the front of the queue, while the second list (`ys`) represents the back. Elements are added to the back list using `sqPut` and removed from the front list using `sqPop`. If the front list is empty, the back list is reversed and becomes the new front list, ensuring that the oldest element is always removed first. This design allows for efficient enqueue and dequeue operations with amortized constant time complexity. In the HVM3 codebase, `SQ` is utilized in the `flattenBFS` function to manage breadth-first traversal of a `Collapse` monad, ensuring elements are processed in the order they are encountered, which is essential for maintaining the correct traversal order in parallel computations."}
{"name": "SUP_f", "explanation": "The `SUP_f` function is a core component of the HVM3 runtime, designed to enable parallel computation by handling the creation and management of `SUP` nodes in the computational graph. When the runtime encounters a superposition operation (`SUP`), it invokes `SUP_f` to allocate a new `SUP` node, which represents a parallel evaluation of two terms. This function takes a `Term` reference as input, containing details such as the label and subterms required to construct the node. By facilitating the creation of `SUP` nodes, `SUP_f` allows the runtime to exploit parallel hardware, optimizing the execution of complex computations. It is integral to the Interaction Combinator model, which drives HVM3's efficient parallel execution capabilities."}
{"name": "State", "explanation": "The `State` symbol in the HVM3 codebase represents the runtime environment's core data structure, responsible for managing computational state and resources. It includes fields such as the reduction stack (`sbuf`, `spos`) for tracking intermediate computations, heap memory (`heap`, `size`) for term storage, and interaction counts (`itrs`) for monitoring reductions. Additionally, it handles fresh label generation (`frsh`) for duplication operations and stores function pointers (`book`) for efficient execution. In the Haskell frontend, the `State` monad is used to manage stateful operations during compilation, parsing, and term injection, ensuring consistent and efficient runtime behavior. Overall, `State` is pivotal in maintaining the runtime's integrity and performance."}
{"name": "TAG", "explanation": "The `TAG` data type is essential in the HVM3 runtime for classifying terms within the computational graph, enabling the `reduce` function to apply appropriate reduction rules based on the term's type. For instance, terms tagged with `ERA` are erased, while those tagged with `DUP` are duplicated for parallel evaluation. The `tagT` function converts a general `Tag` into a specific `TAG`, ensuring accurate interpretation and processing of terms. This classification mechanism is critical for the efficient execution of parallel computations in the HVM3 system."}
{"name": "Tag", "explanation": "The `Tag` is a type identifier used in the HVM3 runtime system to classify `Term` nodes within the computational graph. It specifies the type of a `Term`, such as `ERA`, `REF`, `NUM`, `CON`, or `DUP`, enabling the runtime to apply the correct reduction rules during computation. For instance, in the `reduceAt` function, the `Tag` determines whether to handle function application (`APP`), pattern matching (`MAT`), or duplication (`DUP`). The `Tag` is also utilized in the C backend for functions like `reduce_dup_era` and `reduce_dup_lam`, guiding how specific interaction rules are processed. Additionally, it aids in debugging by providing insights into the runtime state, helping developers diagnose and understand computational behavior. As a fundamental component, the `Tag` ensures efficient and accurate execution of parallel computations in HVM3."}
{"name": "Term", "explanation": "The `Term` data type is a fundamental component of the HVM3 runtime, representing nodes in the computational graph. It encapsulates three critical attributes: a **Tag** that identifies the term's type (e.g., `ERA`, `REF`, `NUM`, `CON`, `DUP`), a **Label** for metadata like function or constructor IDs, and a **Location** pointing to the memory address where the term is stored. These attributes enable efficient memory management, term reduction, and parallel execution. Functions such as `allocNode`, `set`, and `reduce` rely on `Term` instances to allocate memory, manipulate terms, and evaluate expressions to their normal form. Additionally, the `Term` type supports parallel operations through mechanisms like the `Collapse` monad and `Sup` operation, making it central to HVM3's ability to handle concurrent computations effectively."}
{"name": "_APP_", "explanation": "The `_APP_` tag is a constant (`0x06`) used in the HVM3 runtime to identify terms representing function applications, a fundamental operation in functional programming. It marks nodes in the computational graph that require reduction, where a function is applied to an argument to produce a result. During runtime, functions like `reduceAt` and `reduceAppLam` use this tag to determine the appropriate reduction rules. Additionally, the `_APP_` tag is utilized in the compilation process, where high-level `Core` terms are translated into low-level C code by functions such as `compileFullCore` and `compileFastCore`. This ensures that function applications are accurately represented and processed within the Interaction Combinator model, making `_APP_` a critical component for efficient term reduction and compilation."}
{"name": "_CHR_", "explanation": "The `_CHR_` symbol is a constant with the value `0x11`, used as a unique identifier for character terms in the HVM3 runtime. It plays a critical role in memory management, term reduction, compilation, and parsing. During memory allocation, the `_CHR_` tag ensures character terms are correctly identified and stored. In term reduction, it helps the runtime apply appropriate rules for character terms. During compilation, it optimizes the generation of low-level C code for parallel execution. Additionally, it aids in parsing character literals and representing them as `Chr` terms in the `Core` data structure. Overall, `_CHR_` is essential for efficiently handling character data within HVM3's graph-based computational model."}
{"name": "_CTR_", "explanation": "`_CTR_` is a tag in the HVM3 codebase used to identify constructor terms, which are fundamental for representing structured data in functional programs. Assigned the value `0x0F`, it distinguishes constructor terms from other types of terms. During execution, the runtime system uses this tag to apply specific reduction rules, such as evaluating fields or handling pattern matching, as seen in functions like `reduceAppCtr` and `reduceMatCtr`. The `_CTR_` tag is also used in term creation, parsing, and compilation to ensure proper representation and efficient handling of constructor terms, which are essential for algebraic data types like lists and trees. Its role is critical for enabling the functional programming paradigm and optimizing parallel execution in the HVM3 runtime."}
{"name": "_DP0_", "explanation": "`_DP0_` is a tag used in the HVM3 codebase to identify the first duplicated value (`dp0`) in a `Dup` operation, which is a core mechanism in the Interaction Combinator model for duplicating terms to enable parallel evaluation. During a `Dup` operation, `_DP0_` marks the term representing `dp0`, ensuring the runtime can correctly process it alongside the second duplicated value (`dp1`) and the body (`bod`) of the operation. This tag is critical during both term creation and reduction phases, where it helps construct and apply terms in parallel computations, ensuring efficient and accurate execution of complex operations."}
{"name": "_DP1_", "explanation": "In the HVM3 codebase, `_DP1_` is a tag with a value of `0x01` that identifies the second branch of a duplicated term created during a `Dup` operation. It works alongside `_DP0_` to differentiate between the two branches, enabling the runtime to manage parallel evaluation paths effectively. `_DP1_` is used in functions like `injectCore` to insert the second branch into the argument map (`args`) and in `reduceRefAt_DupF` to construct an application node (`APP`) for the second branch. This mechanism ensures efficient handling of duplication, which is crucial for optimizing parallel computations in HVM3."}
{"name": "_DUP_F_", "explanation": "The `_DUP_F_` symbol is a unique identifier for the `DUP` primitive function in the HVM3 runtime, which is crucial for dynamic term duplication in the Interaction Combinator system. This function enables parallel evaluation by duplicating terms, allowing multiple instances to be processed concurrently. During parsing, `_DUP_F_` constructs a `Dup` term with metadata like duplication labels (`dp0`, `dp1`), the value to duplicate (`val`), and the duplication body (`bod`). In the reduction phase, it identifies and handles `DUP` operations via the `reduceRefAt_DupF` function, ensuring correct execution. Listed among core primitives in the runtime, `_DUP_F_` is essential for enabling efficient parallel computations by managing term duplication and evaluation."}
{"name": "_ERA_", "explanation": "In the HVM3 codebase, `_ERA_` is a tag used to identify the `ERA` term type, which represents an erased or empty term. This tag is essential for memory management and term reduction, as it allows the runtime to efficiently handle cases where no meaningful computation or data is present. For instance, `_ERA_` is used in the `Collapse` monad to denote an empty computation (`CEra`) and in the `Core` data type to construct erased terms (`Era`). Functions like `termNew` utilize `_ERA_` to create new `ERA` terms, while reduction functions such as `reduceAppEra` and `reduceMatEra` handle specific scenarios involving `ERA` terms. By marking erased terms, `_ERA_` ensures optimal performance and resource utilization in the HVM3 runtime."}
{"name": "_FRESH_F_", "explanation": "The `_FRESH_F_` symbol is a key primitive in the HVM3 runtime, representing the `FRESH` operation. It generates unique labels for duplication (`DUP`) operations, which are essential for the parallel evaluation model of Interaction Combinators. When the runtime encounters `_FRESH_F_`, it triggers the `reduceRefAt_FreshF` function to create a new, unique label for a `DUP` operation. This ensures that each duplication has a distinct identifier, maintaining correctness and enabling efficient parallel computation. As a primitive operation, `_FRESH_F_` is integral to managing low-level term manipulation and supporting the runtime's parallel execution model."}
{"name": "_LAM_", "explanation": "The `_LAM_` tag, defined as `0x0C`, is a constant used in the HVM3 runtime to identify lambda terms (`Lam`), which represent anonymous functions in functional programming. As part of the `Core` data type, it plays a central role in term reduction, memory management, and compilation. During execution, the runtime uses the `_LAM_` tag to recognize lambda terms and apply appropriate reduction rules, such as in `reduceAppLam`. It also facilitates memory allocation and manipulation through functions like `termNew` and `set`. In compilation, the tag ensures lambda terms are correctly translated into low-level C code by functions like `compileFullCore` and `compileFastCore`. Additionally, it supports term manipulation in operations like `injectCore` and `liftDups`. The `_LAM_` tag is essential for efficiently handling lambda abstractions within the Interaction Combinator model, enabling accurate and performant execution of functional programs."}
{"name": "_LET_", "explanation": "The `_LET_` tag, defined as a constant with the value `0x05`, is used to identify `Let` terms in the runtime. These terms represent variable bindings and consist of a mode (e.g., `LAZY`, `STRI`, `PARA`), a variable name, a value expression, and a body expression. During execution, the `reduceLet` function evaluates `Let` terms by binding the value to the variable and then evaluating the body. In compilation, the `_LET_` tag ensures the correct translation of `Let` terms into low-level C code, enabling proper runtime instructions. This tag is essential for managing variable bindings and supporting the functional programming model in HVM3."}
{"name": "_LOG_F_", "explanation": "The `_LOG_F_` symbol is a primitive operation in the HVM3 codebase, identified by the label `0xFFD`, used for logging terms during evaluation. When the `reduceRefAt` function encounters a term with this label, it invokes the `reduceRefAt_LogF` function, which logs the term and returns `0`. This mechanism is designed for debugging and diagnostics, enabling developers to inspect the state of computations, particularly in parallel execution environments where tracking state can be challenging."}
{"name": "_MAT_", "explanation": "The `_MAT_` symbol represents the `Mat` (match) term in the HVM3 codebase, a core construct for pattern matching in functional programs. It enables conditional logic by evaluating different code branches based on the structure or value of a term. The `Mat` term consists of three components: the value to match (`val`), a list of moved variables (`mov`) for context, and a list of cases (`css`) defining patterns and corresponding code to execute. During compilation, `Mat` is translated into low-level C code, with functions like `compileFullCore` and `compileFastCore` handling memory allocation and execution flow. At runtime, the `reduce_mat_ctr` function reduces `Mat` terms by matching constructors (`CTR`) and executing the appropriate case, ensuring efficient parallel evaluation. This mechanism is essential for implementing pattern matching and conditional logic in HVM3's functional programming model."}
{"name": "_OPX_", "explanation": "The `_OPX_` tag is a fundamental term type in the HVM3 runtime, specifically used to represent binary operations (`Op2`). During compilation, the `injectCore` function generates a new `_OPX_` term using `termNew`, which is then processed by the runtime. The runtime applies specialized reduction rules depending on the operand types: for instance, `reduceOpxEra` handles `ERA` (erasure) operands, while `reduceOpxLam` processes `LAM` (lambda) operands. This design ensures efficient and correct evaluation of binary operations within HVM3's parallel execution model. The `_OPX_` tag acts as a critical identifier, enabling the runtime to manage and reduce binary operation terms effectively."}
{"name": "_OPY_", "explanation": "The `_OPY_` tag is a type identifier in the HVM3 codebase used to mark terms that require specialized reduction. When a term with this tag is encountered, the runtime system selects an appropriate reduction function (`reduceOpyEra`, `reduceOpyLam`, `reduceOpySup`, `reduceOpyCtr`, or `reduceOpyW32`) based on the term's type. This mechanism ensures efficient and correct reduction of terms, particularly in a parallel execution environment. The `_OPY_` tag plays a key role in enabling the runtime to handle diverse term types effectively, leveraging the Interaction Combinator model for high-performance computation."}
{"name": "_REF_", "explanation": "The `_REF_` tag, defined as `0x04`, is a constant used in the HVM3 runtime system to identify terms of type `REF`, which represent references to functions or other entities in the computational graph. This tag is essential for managing reference-based operations, such as function calls, within the system. It is utilized in key processes like term creation, reduction, memory management, and compilation. For instance, the `termNew` function uses `_REF_` to create `REF` terms, while the `reduce` function applies reduction rules to these terms. Additionally, memory allocation and term manipulation for `REF` terms are handled by functions like `allocNode` and `set`. During compilation, the `_REF_` tag ensures that low-level C code is correctly generated for reference-based operations. Overall, `_REF_` is a critical component that enables the HVM3 runtime to efficiently and accurately process reference terms."}
{"name": "_SUB_", "explanation": "`_SUB_` is a tag with the value `0x03` used in the HVM3 codebase to initialize and manage term structures. It serves as a placeholder during the creation of nodes like `Lam` (lambda) or `Dup` (duplication), ensuring that term fields are set to default values before being populated with actual data. This initialization step is critical for maintaining the integrity of the term structure and supporting the runtime's memory management system. By acting as a temporary value, `_SUB_` facilitates the correct handling and evaluation of terms, which is essential for the parallel execution model of HVM3."}
{"name": "_SUP_", "explanation": "The `_SUP_` tag is a key element in the HVM3 runtime system, specifically designed to manage superposed terms, which represent multiple states or values simultaneously for parallel evaluation. It identifies superposed terms during the reduction process, enabling the runtime to apply specialized rules like `reduceAppSup` or `reduceDupSup` for efficient parallel computation. During compilation, the `_SUP_` tag ensures the generation of low-level C code that supports parallel execution, making it essential for HVM3's ability to handle superposed terms in massively parallel hardware environments."}
{"name": "_SUP_F_", "explanation": "The `_SUP_F_` label in the HVM3 codebase represents the `Sup` operation, a fundamental mechanism for parallel computation. It combines two terms into a superposed term, enabling their parallel evaluation, which is crucial for leveraging the Interaction Combinator model's performance on massively parallel hardware. The label is used in the `reduceRefAt` function to identify terms processed by `reduceRefAt_SupF`, which handles the reduction of superposed terms. By including `_SUP_F_` in the `primitives` list, the codebase ensures proper recognition and management of the `Sup` operation during parsing and execution, making it a key enabler of HVM3's parallel evaluation capabilities."}
{"name": "_VAR_", "explanation": "The `_VAR_` tag in the HVM3 codebase is a critical identifier for variable nodes within the computational graph. It distinguishes variables from other term types, such as constructors or numbers, enabling the runtime to manage them effectively. During memory allocation, the `_VAR_` tag is used to create and track variable nodes, ensuring proper handling in functions like `injectCore`. In term reduction, the runtime retrieves the value associated with a `_VAR_`-tagged term to continue computation. Additionally, the tag plays a role in compilation, where it guides the generation of low-level C code for variable terms in functions like `compileFastCore` and `compileFullCore`. It also aids in parsing and debugging by marking variable terms for identification and display. Overall, the `_VAR_` tag is essential for the accurate representation and processing of variables throughout the HVM3 runtime system."}
{"name": "_W32_", "explanation": "The `_W32_` tag is a key component in the HVM3 runtime system, specifically used to denote 32-bit unsigned integers (`W32`). It plays a central role in term creation, reduction, and pattern matching within the Interaction Combinator model. During term creation, `_W32_` ensures that numeric terms are correctly identified and processed. In reduction operations, it directs the runtime to apply specific rules (e.g., `reduceAppW32`, `reduceMatW32`) for handling numeric terms. Additionally, `_W32_` is crucial for dynamic operations like `@DUP` and `@SUP`, where it validates numeric labels, and for debugging, where it aids in identifying term types during runtime inspection. Overall, `_W32_` is essential for the efficient management and processing of numeric data in HVM3."}
{"name": "allocNode", "explanation": "The `allocNode` function is a core utility in the HVM3 runtime responsible for dynamically allocating memory for nodes in the computational graph. These nodes, represented by the `Term` data type, have a specific arity that determines the number of child terms they can hold. `allocNode` is invoked during compilation to allocate memory for nodes representing constructs like `Lam`, `App`, `Sup`, and `Dup`, ensuring the correct arity for each term. During runtime, it facilitates term reduction by allocating memory for intermediate results, such as duplicated values in `Dup` operations or superposed terms in `Sup` operations. By efficiently managing memory allocation, `allocNode` supports the runtime's parallel execution model and ensures the smooth operation of the computational graph."}
{"name": "alloc_node", "explanation": "The `alloc_node` function is a core memory allocation utility in the HVM3 runtime, responsible for dynamically allocating space for nodes in the computational graph. Each node represents a term (e.g., `Lam`, `App`, `Sup`, `Dup`, `Ctr`), and its arity determines the number of child nodes it can hold. This function is critical during compilation, term reduction, and parallel execution, as it ensures efficient memory management for intermediate results and parallel constructs. For example, it allocates space for lambda bodies, duplicated terms, and superposed nodes. Implemented in the C backend and exposed via FFI to the Haskell frontend, `alloc_node` balances low-level performance with high-level memory management, enabling the runtime to handle the dynamic and parallel demands of the Interaction Combinator model effectively."}
{"name": "bind", "explanation": "The `bind` symbol serves distinct purposes in two contexts within the HVM3 codebase. In the `Collapse` monad, `bind` is defined as `bind :: Collapse a -> (a -> Collapse b) -> Collapse b`, functioning as a standard monadic bind to sequence computations and manage parallel outcomes by reducing them to a single result. In the `Compile` monad, `bind` is defined as `bind :: String -> String -> Compile ()`, where it associates variable names with their corresponding terms during compilation. This operation updates the `CompileState` by mapping variables to terms, ensuring proper linkage for generating low-level C code. Together, `bind` facilitates both high-level functional sequencing and low-level compilation mechanics, making it a critical component of the system."}
{"name": "cliRun", "explanation": "The `cliRun` function is the core entry point for executing programs in the HVM3 system. It processes a program file specified by `filePath` and executes it based on user-defined parameters, including `debug` for enabling debugging output, `compiled` for pre-compilation, `mode` for selecting execution behavior (e.g., `Collapse`, `Search`, or `Normalize`), and `showStats` for displaying runtime statistics. The function reads and optionally compiles the program, initializes the runtime environment, and executes the program according to the chosen mode. It handles debugging and statistics collection as needed and returns an `Either String ()` result, where `Left` indicates an error and `Right` signifies successful execution. This function bridges the Haskell frontend and the C runtime, ensuring seamless program execution within HVM3."}
{"name": "closeWith", "explanation": "The `closeWith` function is a parser combinator designed to consume a specified closing delimiter (e.g., `\")\"`, `\"]\"`, or `\"}\"`) from the input stream. It ensures that nested structures, such as function calls, lists, or other expressions, are properly terminated. For instance, in parsing `@foo(arg1, arg2)`, `closeWith \")\"` confirms the end of the argument list, while in `[elem1, elem2]`, `closeWith \"]\"` marks the list's closure. This function is critical for maintaining syntactic correctness and accurately representing nested expressions in the resulting `Core` terms."}
{"name": "collapseDupsAt", "explanation": "The `collapseDupsAt` function is a core component of the HVM3 runtime, designed to optimize the computational graph by collapsing duplicate terms. It takes four parameters: `state` (an `IntMap` for tracking paths), `reduceAt` (a function for applying reduction rules), `book` (a `Book` structure with function definitions), and `host` (the location of the term being processed). The function recursively processes terms based on their type, such as `LET`, `LAM`, `APP`, `SUP`, `DP0`, `DP1`, `CTR`, `MAT`, `OPX`, `OPY`, and `REF`. For instance, it handles superposition by selecting paths from the `IntMap` and manages duplication by updating the `IntMap` and processing subterms. By eliminating redundant terms, `collapseDupsAt` ensures efficient parallel execution, making it essential for optimizing complex computations in HVM3."}
{"name": "collapseSups", "explanation": "The `collapseSups` function is a critical component in the HVM3 codebase, responsible for processing superposed terms (`Sup`) and other term types within the `Collapse` monad. It recursively traverses the `Core` term structure, applying the `collapseSups` operation to each subterm. For instance, it processes the arguments of a `Ref` term, the body of a `Lam` term, and both the function and argument of an `App` term. The `Sup` case is particularly important as it handles superposed terms, a core feature of HVM3's parallel evaluation model. By collapsing these terms recursively, `collapseSups` ensures that parallel computations are efficiently managed and reduced to their normal forms, maintaining the correctness and performance of the parallel execution model."}
{"name": "collectLabels", "explanation": "The `collectLabels` function is responsible for identifying and gathering all labels associated with `Sup` (superposition) and `Dup` (duplication) operations within a `Core` term. These labels are essential for managing parallel execution, as they enable the runtime to synchronize and coordinate computations effectively. The function recursively traverses the `Core` term, collecting labels into a map that is later utilized during compilation and execution to ensure proper handling of parallel operations. By organizing and managing these labels, `collectLabels` ensures the efficient and accurate execution of parallel programs in the HVM3 system."}
{"name": "compile", "explanation": "The `compile` function is the core of the compilation process in the HVM3 codebase, responsible for translating high-level functional constructs into optimized C code. It orchestrates three distinct compilation modes: `compileFull`, `compileFast`, and `compileSlow`. `compileFull` ensures correctness by handling all possible term reductions, while `compileFast` prioritizes performance by optimizing common execution paths. `compileSlow` acts as a fallback for edge cases, ensuring robust execution. By combining these modes, `compile` generates efficient C code that leverages modern hardware parallelism, enabling the HVM3 runtime to execute programs with both high performance and correctness."}
{"name": "compileFast", "explanation": "The `compileFast` function compiles high-level `Core` terms into optimized low-level C code, focusing on performance and parallel execution. It operates within a `Book` context, using a function ID (`fid`) to identify the target function. The function processes arguments based on strictness, handles special cases like `ERA` and `SUP` terms, and generates C code for the function body using helper functions like `compileFastArgs` and `compileFastBody`. It manages memory allocation, term reduction, and parallel execution, ensuring efficient resource usage. The resulting C code is tailored for the HVM3 runtime, enabling high-performance execution on parallel hardware."}
{"name": "compileFastAlloc", "explanation": "The `compileFastAlloc` function is a key component of the HVM3 runtime's memory management system, responsible for allocating memory for nodes during compilation. It optimizes performance by leveraging a reuse map to recycle previously allocated memory locations, minimizing the overhead of frequent memory operations. This is especially critical in a parallel execution environment, where efficient memory handling is vital for scalability. The function is invoked within `compileFastCore` for various term types (e.g., `Lam`, `App`, `Sup`, `Dup`, `Ctr`, `Mat`), ensuring that each term's child nodes have the necessary memory allocated. This streamlined approach enhances the runtime's efficiency and supports high-performance execution."}
{"name": "compileFastArgs", "explanation": "The `compileFastArgs` function is a key part of the HVM3 runtime's compilation process, specifically designed for \"Fast-Mode\" to optimize function execution for parallel hardware. It compiles function arguments into a format suitable for parallel evaluation, ensuring efficient memory usage and correct integration into the function body. The function takes a `Book` (containing function definitions), a function ID (`fid`), the function's body (`Core` term), a context of compiled arguments (`ctx`), and a reuse map (`MS.Map Int [String]`) to track reusable terms. By processing strict and non-strict arguments and managing memory allocation, `compileFastArgs` prepares the arguments for parallel execution. It is invoked by `compileFast` to compile the entire function, passing the compiled context and reuse map to subsequent stages. This function is essential for enabling HVM3's parallel evaluation model."}
{"name": "compileFastBody", "explanation": "The `compileFastBody` function is a critical component in the HVM3 codebase, responsible for translating the body of functions into optimized C code for efficient runtime execution. It processes various `Core` term types, such as pattern-matching (`Mat`), duplication (`Dup`), and let bindings (`Let`), generating C code tailored to their specific behaviors. For pattern-matching, it produces code to evaluate term types and dispatch to the correct case, handling both numeric and constructor patterns. For duplication, it manages the creation and manipulation of duplicated terms, ensuring runtime efficiency. For let bindings, it evaluates and assigns values to variables, supporting lazy, strict, and parallel evaluation modes. Additionally, it optimizes memory usage by reusing memory locations. By converting high-level functional constructs into performant low-level C code, `compileFastBody` enables the HVM3 runtime to execute programs efficiently on massively parallel hardware."}
{"name": "compileFastCore", "explanation": "The `compileFastCore` function is a critical component of the HVM3 compilation pipeline, responsible for translating `Core` terms into optimized C code for efficient execution. It accepts four parameters: a `Book` (containing function definitions and metadata), a `Word64` (function ID), a `Core` term (the high-level term to compile), and a `Map` (for memory reuse optimization). The function processes the `Core` term recursively, generating C code tailored to the term's type. For instance, it handles `Era` by producing a simple eraser term, `Let` by supporting lazy, strict, and parallel evaluation modes, and `Lam`/`App` by managing memory allocation for lambda abstractions and function applications. It also generates code for `Sup`/`Dup` (superposition and duplication), `Ctr`/`Mat` (constructors and pattern matching), and primitive operations like `U32`, `Chr`, and `Op2`. Additionally, it manages references, including dynamic `SUP` and `DUP` operations. By optimizing each term type and leveraging the Interaction Combinator model, `compileFastCore` ensures high-performance execution, making it essential for the HVM3 system's efficiency."}
{"name": "compileFastSave", "explanation": "The `compileFastSave` function is a key component in the compilation pipeline, designed to finalize the compilation of terms in \"fast mode,\" optimized for parallel execution. It processes a `Book` data structure containing function definitions, a unique function identifier (`fid`), the `Core` term being compiled, a compilation context (`ctx`), an iteration count (`itr`), and a reuse map to optimize memory usage. Its primary purpose is to save the compiled code in a format ready for execution, ensuring proper context and reuse information are maintained. By emitting the compiled code and updating relevant structures, `compileFastSave` enables efficient execution in the HVM3 runtime, leveraging parallelism for performance."}
{"name": "compileFastUndo", "explanation": "The `compileFastUndo` function is a fallback mechanism in the HVM3 compilation pipeline, ensuring terms that cannot be optimized in \"fast mode\" are correctly compiled using the more thorough \"full mode.\" When fast mode encounters a term it cannot handle efficiently, `compileFastUndo` switches to full mode, recompiling the term with a comprehensive approach to guarantee correctness. It utilizes the `Book` data structure for function definitions and metadata, along with context and iteration details, to guide the process. The `reuse` map is employed to optimize performance by reusing previously compiled components, minimizing redundant work. In essence, `compileFastUndo` ensures both correctness and efficiency by bridging fast and full compilation modes."}
{"name": "compileFastVar", "explanation": "The `compileFastVar` function compiles variable references into low-level C code as part of the \"fast mode\" compilation process in HVM3. This mode prioritizes parallel execution efficiency. When a `Var` term is encountered during compilation, `compileFastVar` generates the corresponding C code to reference the variable in the runtime environment. It takes the variable's name as input and uses the `Compile` monad to manage state and produce the output. By encapsulating variable compilation in this function, the codebase ensures modularity, simplifies optimization, and enhances debugging for variable handling, which is critical for high-performance parallel execution."}
{"name": "compileFull", "explanation": "The `compileFull` function is a key component of the HVM3 compilation pipeline, responsible for translating high-level functional programming constructs into optimized C code. It takes a `Book` (containing function definitions), a function ID (`fid`), a `Core` term (representing the program structure), a `copy` flag, and a list of arguments (`args`). The function generates a C function declaration, binds arguments to local variables, and processes the `Core` term using `compileFullCore`, which recursively compiles subterms and manages memory allocation. The `copy` flag determines whether arguments are reduced or retrieved directly from memory. By producing efficient and correct C code, `compileFull` ensures the program is ready for execution in the HVM3 runtime, bridging the gap between high-level abstractions and low-level parallel execution."}
{"name": "compileFullCore", "explanation": "The `compileFullCore` function is a recursive compiler that translates high-level `Core` terms into low-level C code for execution by the HVM3 runtime. It takes four parameters: `book` (containing function definitions and metadata), `fid` (a function ID), `core` (the `Core` term to compile), and `host` (the memory location for the compiled term). For each term type (e.g., `Era`, `Var`, `Let`, `Lam`, `App`, `Sup`, `Dup`, `Ctr`, `Mat`, `U32`, `Chr`, `Op2`, `Ref`), it generates corresponding C code by allocating memory, binding variables, and compiling subterms. The function uses utilities like `alloc_node` for memory allocation and `set` for writing terms to memory. By recursively processing terms, `compileFullCore` ensures efficient translation of high-level constructs into executable C code, making it a critical component of the HVM3 compilation pipeline."}
{"name": "compileFullVar", "explanation": "The `compileFullVar` function is a key part of the HVM3 compilation pipeline, responsible for translating high-level variable names from the `Core` representation into low-level C code. It ensures that variables are properly managed within the runtime's memory model and parallel execution framework. Operating within the `Compile` monad, it interacts with the `Book` data structure and memory management utilities like `allocNode` and `set`. By generating efficient C code for variables, `compileFullVar` supports the runtime's parallel evaluation model, enhancing the system's overall performance."}
{"name": "compileSlow", "explanation": "The `compileSlow` function is a component of the HVM3 compilation pipeline, designed to generate straightforward and readable C code from high-level functional programs. Unlike `compileFast`, which prioritizes performance and parallel execution, `compileSlow` avoids aggressive optimizations, making it ideal for debugging, educational purposes, or understanding the compilation process. It takes a `Book` containing function definitions, a function ID (`fid`) to specify the target function, a `Core` term representing the program, a boolean `copy` flag to control term duplication, and a list of arguments (`args`) for additional context. The output is a sequence of C code instructions executable by the runtime, offering a simpler alternative to optimized compilation."}
{"name": "compileWith", "explanation": "The `compileWith` function is a flexible compilation utility in the HVM3 codebase, designed to handle various compilation strategies. It takes a compilation function (`cmp`) as its first argument, which determines the specific compilation approach (e.g., full, fast, or slow mode). The `Book` argument supplies the necessary function definitions and metadata, while the `fid` (function ID) identifies the target function for compilation. By abstracting the compilation process, `compileWith` enables the reuse of infrastructure across different modes, reducing redundancy and enhancing maintainability. This function plays a key role in translating high-level `Core` terms into low-level C code, ensuring efficient execution on massively parallel hardware. Its adaptability supports diverse evaluation strategies, allowing optimization for performance and resource efficiency."}
{"name": "consume", "explanation": "The `consume` function, defined as `consume :: String -> ParserM String`, is a key component in the parsing process. It first invokes `skip`, a utility function that skips irrelevant characters like whitespace, and then uses the `string` function to match and consume the exact sequence of characters provided as input. This function is essential for parsing specific tokens or symbols (e.g., `*`, `\u03bb`, `(`, `)`, `{`, `}`, `@`, `#`) in the input stream, ensuring they are correctly recognized and processed. By doing so, `consume` enables the parser to accurately interpret the input according to the language's syntax and proceed with further parsing."}
{"name": "cont", "explanation": "The `cont` function in the HVM3 codebase acts as a continuation mechanism for term reduction, facilitating the next step in the reduction process after a specific rule is applied. It takes two arguments: `host`, representing the current reduction state or context, and `action`, which specifies the next reduction step. By modularizing the reduction process, `cont` ensures consistent application of reduction rules, simplifying the logic and enabling efficient handling of complex term transformations. Its role is particularly crucial in parallel execution, where it coordinates simultaneous term reductions, maintaining system efficiency and scalability."}
{"name": "coreToString", "explanation": "The `coreToString` function converts a `Core` term into a human-readable string representation, facilitating debugging and error reporting. It processes various `Core` term types (e.g., `Lam`, `App`, `Sup`, `Dup`, `Ref`, `Ctr`, `Mat`, `Op2`, `Let`) by recursively transforming their components into strings and combining them into a structured format. For instance, `Lam` terms become lambda abstractions like `\u03bbx body`, `App` terms represent function applications like `(f x)`, and `Sup` terms denote superpositions like `&label{term1 term2}`. This function is essential for visualizing `Core` terms in debugging contexts (`putStrLn $ coreToString core`) and error messages, aiding developers in understanding and optimizing the runtime behavior of parallel, functional systems like HVM3."}
{"name": "createBook", "explanation": "The `createBook` function constructs the `Book` data structure, which acts as a central repository for function definitions, metadata, and constructor mappings in the runtime environment. It takes parsed definitions (`defs`), constructor-to-ID mappings (`ctrToCid`), and constructor arities (`ctrToAri`) as inputs, organizing them into a format that enables efficient lookup and retrieval during compilation and execution. This structure is crucial for the runtime's performance, particularly in parallel execution models like HVM3, where quick access to function IDs, names, and constructors is essential for managing resources and optimizing computations. By consolidating this information, `createBook` ensures the runtime can handle complex programs efficiently."}
{"name": "doCollapseAt", "explanation": "The `doCollapseAt` function is a key component of the HVM3 runtime system, responsible for collapsing parallel computations into a single result or a list of results. Operating within the `HVM` monad, it takes three parameters: `reduceAt` (a reduction function), `book` (a data structure containing function definitions), and `host` (a memory location storing the term to be collapsed). The function returns a `Collapse Core`, representing the outcome of the collapsing process, which can be further processed by other functions like `doCollapseFlatAt`. `doCollapseAt` ensures efficient reduction and combination of parallel computations, enabling the runtime to handle complex parallel evaluations effectively."}
{"name": "doCollapseFlatAt", "explanation": "The `doCollapseFlatAt` function is a core component of the HVM3 runtime, designed to handle the parallel evaluation and reduction of terms. It operates by collapsing multiple potential outcomes or states into a single result or a list of results, which is critical for efficient computation in `Collapse` and `Search` modes. The function takes three key arguments: `reduceAt` (a reduction function), `book` (a metadata storage structure), and `host` (a memory location for the term being processed). It returns a list of `Core` terms representing the collapsed results, which are essential for normalizing the main term during program execution. Used in functions like `cliRun` and `reduceRefAt_LogF`, `doCollapseFlatAt` ensures high-performance parallel evaluation, making it indispensable for modern hardware optimization."}
{"name": "doExtractCoreAt", "explanation": "The `doExtractCoreAt` function is a utility in the HVM3 runtime that extracts high-level `Core` terms from specific memory locations. It takes three parameters: `reduceAt` (a function to reduce terms to their normal form), `book` (containing function definitions and metadata), and `loc` (the memory location of the term to extract). The function first reduces the term at the specified location to its normal form using `reduceAt`, ensuring it is fully evaluated. It then converts the reduced term into a `Core` representation, a high-level data structure that facilitates inspection and manipulation. This capability is crucial for debugging, logging, and dynamic term evaluation, bridging low-level memory operations with high-level term analysis. For instance, it is used in `cliRun` to inspect the result of computations and in `reduceRefAt_LogF` to log debugging information. `doExtractCoreAt` is integral to HVM3's ability to interact with and analyze its computational graph."}
{"name": "doInjectCoreAt", "explanation": "The `doInjectCoreAt` function is a critical component of the HVM3 runtime, responsible for injecting `Core` terms into the runtime's memory model. It facilitates the dynamic evaluation of function calls and the initialization of computations, such as starting from the `main` function. When invoked, `doInjectCoreAt` binds the provided `argList` (a list of arguments) to the `Core` term and injects it into the runtime at the specified `Loc`. This process involves allocating memory for the term and updating the runtime's memory model. The function then returns the injected `Term`, enabling further reduction or evaluation. In the context of the Interaction Combinator model, `doInjectCoreAt` ensures the computational graph is correctly updated, supporting efficient parallel evaluation and reduction. Overall, it plays a vital role in maintaining the runtime's state during computation."}
{"name": "doLiftDups", "explanation": "The `doLiftDups` function is a utility in the HVM3 codebase that processes `Core` terms by lifting duplication (`DUP`) operations. In the Interaction Combinator model, duplication enables parallel evaluation by creating multiple copies of a term for simultaneous processing. This function is used in key operations such as term extraction, normalization, and debugging to ensure that `DUP` operations are properly lifted and optimized. By handling duplication efficiently, `doLiftDups` supports the runtime in managing parallel computations, aligning with HVM3's goal of high-performance evaluation. It plays a critical role in the compilation and execution pipeline, enabling the system to handle complex, parallel workloads effectively."}
{"name": "doParseBook", "explanation": "The `doParseBook` function processes a `String` input representing the contents of a file containing program definitions and metadata. It utilizes a parser (`parseBookWithState`) to convert this string into a `Book` data structure, operating within a `ParserState` context to manage parsing state, such as mappings or counters. The function returns an `IO Book`, a monadic action that yields the `Book` object when executed. This function is invoked in the `cliRun` function, the entry point for the HVM3 runtime, where it transforms raw program definitions into a structured format essential for compilation and execution. In essence, `doParseBook` bridges the gap between raw input and the runtime's ability to process and execute complex, parallel computations."}
{"name": "doParseCore", "explanation": "The `doParseCore` function is responsible for parsing a `String` representing source code into a `Core` term, which is an internal structured representation of the program. It utilizes a parser combinator (`runParser`) and a custom parser (`parseCore`) to interpret the syntax of the language and construct the corresponding `Core` term. The parsing process is managed using `ParserState`, which tracks the state and context of the parser. The function returns the parsed `Core` term wrapped in an `IO` monad, indicating potential side effects such as error handling or file operations. This `Core` term is then used in subsequent stages of the compilation process, enabling the translation of the program into low-level C code for execution. In essence, `doParseCore` serves as a critical component in transforming textual code into a structured, semantically meaningful format for further processing."}
{"name": "dumpHeap", "explanation": "The `dumpHeap` function, operating within the `HVM` monad, is designed to capture and analyze the current state of the heap. It retrieves the heap's length and the current iteration count using `getLen` and `getItr`, respectively. By invoking `dumpHeapRange` with a starting address of `0` and the heap's length, it recursively traverses the heap, fetching terms at each memory address using `got` and compiling them into a list of address-term pairs. The function ultimately returns a tuple containing this list and the heap length, providing a snapshot of the heap's state for debugging, analysis, or verification purposes."}
{"name": "dumpHeapRange", "explanation": "The `dumpHeapRange` function is a diagnostic utility in the HVM3 runtime system, designed to inspect a specific range of memory addresses within the heap. It retrieves and returns a list of tuples, each containing a memory address and the corresponding term stored at that location. This allows developers to analyze the state of the heap during execution, aiding in debugging and understanding memory management. The function is particularly useful for identifying anomalies, tracing data flow, and optimizing performance. By focusing on a specified range, `dumpHeapRange` complements broader heap inspection tools like `dumpHeap`, providing targeted insights into the runtime's memory behavior."}
{"name": "emit", "explanation": "The `emit` function is a core utility in the compilation process, responsible for generating C code from high-level `Core` terms. It is utilized in functions like `compileFull`, `compileFast`, and `compileSlow` to translate `Core` constructs\u2014such as function definitions, term allocations, and reduction rules\u2014into corresponding C code. The function ensures proper code formatting by leveraging the `tabs` field of the compilation state, which maintains the current indentation level for readability and correctness. By appending the generated code to the `code` field, `emit` incrementally constructs the final C program. This process is essential for bridging high-level functional abstractions with low-level C code, enabling efficient execution on massively parallel hardware."}
{"name": "emptyState", "explanation": "The `emptyState` symbol represents the initial, default state for the `InjectState` data structure in the HVM3 codebase. It serves as a clean slate for the injection process of `Core` terms into the runtime, ensuring that no residual data or unintended side effects from prior operations interfere with the current injection. This is particularly critical in HVM3's parallel, functional runtime, where precise state management is essential for correctness and efficiency. The `emptyState` is later populated with relevant context, such as the `argList`, during the `doInjectCoreAt` function, enabling the injection process to proceed with the necessary metadata and mappings."}
{"name": "extend", "explanation": "The `extend` function is used in the `lexify` function to ensure unique naming of variables within a given scope, preventing name conflicts in nested or shadowed contexts. It takes an old variable name, a new unique name, and a context (a mapping of existing variables to their unique counterparts). The function updates the context by adding the new mapping unless the old variable name starts with '$', in which case the context remains unchanged. This exception allows '$'-prefixed variables to remain unaltered, supporting specific conventions or use cases. `extend` is invoked during the processing of constructs like `Let`, `Lam`, `Dup`, and `Mat`, ensuring proper variable renaming and context management."}
{"name": "extractCoreAt", "explanation": "The `extractCoreAt` function is a critical component in the HVM3 compilation pipeline, responsible for transforming low-level `Term` nodes into high-level `Core` terms. This conversion bridges the gap between the Interaction Combinator-based runtime model and a more abstract representation suitable for optimization and compilation into C code. The function takes four parameters: `dupsRef` (an `IORef IS.IntSet` for tracking duplicated terms), `reduceAt` (a function specifying reduction behavior), `book` (a `Book` containing function definitions), and `host` (a `Loc` indicating the starting point in the computational graph). It processes various term types (e.g., `LET`, `LAM`, `APP`, `SUP`, `VAR`, `DP0`, `DP1`, `CTR`, `MAT`, `OPX`, `OPY`, `REF`) by recursively traversing the computational graph and constructing corresponding `Core` nodes. Using `unsafeInterleaveIO`, it enables lazy evaluation, ensuring efficient handling of large or infinite computations. By preserving the high-level structure of the program, `extractCoreAt` facilitates further optimizations and transformations in the compilation process."}
{"name": "extractExpectedTokens", "explanation": "The `extractExpectedTokens` function is a utility in the HVM3 codebase that processes `ParseError` objects to extract and format the list of expected tokens when a parsing error occurs. It transforms the raw expected token data into a human-readable string, which is then used by other functions (e.g., `showParseError`) to construct detailed error messages. These messages include the file name, input, error position, and the expected tokens, aiding developers in quickly identifying and resolving syntax errors. By providing clear and actionable feedback, `extractExpectedTokens` enhances the debugging experience and improves the usability of the parser."}
{"name": "flatten", "explanation": "The `flatten` function is a key utility in the HVM3 codebase, designed to convert the `Collapse` monad\u2014a structure representing parallel computations with multiple possible outcomes\u2014into a flat list of results. This transformation is crucial for aggregating and processing outcomes from parallel computations, enabling operations like reducing multiple states into a single result or collecting all possible outcomes for further analysis. Implemented using `flattenBFS`, the function employs a breadth-first search strategy to systematically traverse the `Collapse` structure, ensuring efficient and balanced exploration of all possible outcomes. This approach is particularly effective in parallel execution contexts, as it avoids bottlenecks associated with depth-first traversal. In functions like `doCollapseFlatAt`, `flatten` plays a vital role in preparing parallel computation results for evaluation or output, making it an essential component of HVM3's high-performance parallel processing capabilities."}
{"name": "flattenBFS", "explanation": "The `flattenBFS` function is a utility in the HVM3 codebase designed to flatten a `Collapse` monad, which represents a parallel computation with multiple potential outcomes, into a flat list of results. It employs a breadth-first search (BFS) strategy to traverse the `Collapse` structure, ensuring results are collected level by level. This approach is particularly useful in parallel runtime systems like HVM3, where computations can branch into multiple paths. By using a queue (`SQ`) for efficient traversal, `flattenBFS` systematically processes the structure, producing a list of outcomes in the correct order. Its alias as `flatten` indicates its role as the default method for handling `Collapse` structures, making it essential for managing and extracting results from parallel computations."}
{"name": "flattenDFS", "explanation": "The `flattenDFS` function is a utility in the HVM3 codebase designed to process parallel computations represented by the `Collapse` monad. It performs a depth-first traversal of the computation structure, converting it into a flat list of values. For instance, when encountering a superposition (`CSup`), it recursively flattens both branches and merges their results. If the computation is a single value (`CVal`), it returns a list containing that value, and for an empty computation (`CEra`), it returns an empty list. This function is essential for simplifying the analysis and debugging of parallel computations, ensuring that complex nested structures are transformed into a manageable, linear format. By doing so, `flattenDFS` enhances the clarity and efficiency of the HVM3 runtime system."}
{"name": "flattenPQ", "explanation": "The `flattenPQ` function is essential for managing parallel computations in the HVM3 runtime. It operates on the `Collapse` monad, which represents multiple potential outcomes or states of a computation. The function's primary purpose is to flatten this multi-branched structure into a single list of results, enabling the runtime to efficiently handle and combine the outcomes of parallel computations. \n\n`flattenPQ` achieves this by recursively traversing the `Collapse` structure using a priority queue (`PQ`) to control the order of traversal. The `PQLeaf` serves as the initial state of the queue, while the `go` function performs the traversal and collects results. By converting the `Collapse` structure into a list, `flattenPQ` simplifies the processing of parallel computation results, making it easier for the runtime to manage and combine them effectively."}
{"name": "fmap", "explanation": "In the HVM3 codebase, `fmap` is a function that applies a given function `f` to the values encapsulated within the `Collapse` monad, which represents parallel computations. The `Collapse` monad can hold three types of values: `CVal` for a single value, `CSup` for a superposition of two values, and `CEra` for an erased value. The `fmap` function processes each case as follows:\n- For `CVal v`, it applies `f` to `v`, yielding `CVal (f v)`.\n- For `CSup k x y`, it recursively applies `fmap f` to both `x` and `y`, resulting in `CSup k (fmap f x) (fmap f y)`.\n- For `CEra`, it returns `CEra` unchanged since no value exists to transform.\n\nThis behavior ensures that `f` is uniformly applied across all possible values within the `Collapse` monad, preserving the structure and semantics of parallel computations. This is essential for the HVM3 runtime, where `Collapse` manages and reduces parallel tasks efficiently."}
{"name": "fork", "explanation": "The `fork` function is a key component within the `bind` function, designed to process `Collapse` computations, particularly for `CSup` terms. It handles three cases: `CEra`, `CVal`, and `CSup`. For `CEra`, it returns `CEra` as there is nothing to process. For `CVal v`, it applies the continuation function `f` to `v` and updates the `paths` map by applying the transformation `E` to all paths, ensuring proper value propagation. For `CSup k x y`, it recursively processes the left (`x`) and right (`y`) branches, marking their paths with `putO` and `putI` respectively to track parallel computations. This enables the system to efficiently manage and combine parallel evaluations within the `Collapse` monad."}
{"name": "fresh", "explanation": "The `fresh` symbol is a utility function used to generate unique identifiers, ensuring name and label uniqueness in both compilation and runtime contexts. During compilation, it creates distinct variable names to avoid collisions in lexically scoped environments, particularly in constructs like `Let`, `Lam`, `App`, `Sup`, and `Dup`. At runtime, it generates unique labels for duplication operations (`Dup`) and parallel computations, incrementing a global counter to maintain uniqueness. This functionality is critical for avoiding ambiguity in variable binding and enabling correct parallel execution in the Interaction Combinator model. Overall, `fresh` ensures the integrity and efficiency of the HVM3 system across both phases."}
{"name": "genFreshLabel", "explanation": "The `genFreshLabel` function generates unique labels for terms or constructs in the Haskell frontend (`hvm.hs`), ensuring no two terms share the same identifier. It is primarily used during parsing when a term requires a label but none is provided, such as in `&` constructs. By producing distinct labels, `genFreshLabel` prevents conflicts in the computational graph, which is crucial for the HVM3 runtime's parallel execution and term reduction. The function uses `Word64` to guarantee a sufficiently large namespace, minimizing the risk of collisions even in complex computations. Its role is vital for maintaining the runtime's correctness and efficiency."}
{"name": "genMain", "explanation": "The `genMain` function is a key component in the Haskell frontend (`hvm.hs`) that generates the main C function during compilation. This function serves as the entry point for the compiled program when executed by the C backend. It takes a `Book` data structure as input, which encapsulates metadata about functions, their IDs, labels, and other execution details. `genMain` constructs the main C function by integrating runtime initialization code with compiled functions derived from the `Book`. This includes setting up the runtime environment, such as memory and data structures, and orchestrating the execution of compiled functions. Invoked within the `cliRun` function, `genMain` ensures the final C program is properly structured for execution, enabling efficient parallel computation via the Interaction Combinator model. Its role is pivotal in bridging the Haskell frontend and C backend, ensuring seamless program execution."}
{"name": "genName", "explanation": "The `genName` function is a key utility in the HVM3 codebase, responsible for generating unique names to avoid conflicts during compilation. It is invoked in contexts involving variables (`Var`), lambda bindings (`Lam`), let bindings (`Let`), and duplication operations (`Dup`). The function operates by consulting a reference (`namesRef`) that tracks existing names. If the requested name is already present, it retrieves the mapped name; otherwise, it generates a new unique name using `genNameFromIndex`, which derives a name from the current size of the name map. This mechanism ensures that all names remain distinct, which is vital for maintaining the correctness of the computational graph, particularly in parallel execution scenarios. By preventing name collisions, `genName` supports the reliable and efficient execution of programs in the HVM3 runtime."}
{"name": "genNameFromIndex", "explanation": "The `genNameFromIndex` function generates unique names for terms or variables in the HVM3 codebase by converting an integer index (`n`) into a string representation. It uses a recursive helper function `go` to construct the name incrementally, ensuring uniqueness by incrementing the index by 1 to avoid zero-based naming. This function is essential for creating distinct identifiers during compilation or when managing function definitions in the `Book` data structure, preventing naming conflicts and ensuring proper referencing within the runtime system. It is typically invoked by the `genName` function, which either retrieves an existing name from a map or generates a new one, maintaining the integrity of the symbol table."}
{"name": "getItr", "explanation": "The `getItr` function retrieves the number of interactions (reduction steps) performed by the HVM3 runtime, serving as a key interface between the Haskell frontend and the C backend. This interaction count is essential for performance analysis, enabling developers to monitor computational intensity and optimize program execution. It is utilized in functions like `cliRun` to display runtime statistics (e.g., total interactions, execution time, and MIPS) and in `dumpHeap` to provide diagnostic details about the runtime state, such as heap size and interaction count. By exposing this low-level metric, `getItr` facilitates performance tuning and debugging within the HVM3 system."}
{"name": "getLen", "explanation": "The `getLen` function acts as an interface between the Haskell frontend and the C backend, enabling the Haskell code to query the runtime's memory state. In the C backend, `get_len` is implemented to return the current length of the heap, which represents the number of allocated memory nodes. This function is primarily used for debugging, runtime monitoring, and heap inspection, providing insights into memory usage and aiding in performance optimization. By retrieving the heap size, `getLen` supports tasks such as displaying runtime statistics, dumping heap contents for analysis, and embedding heap size information in generated C code for post-execution summaries."}
{"name": "get_itr", "explanation": "The `get_itr` function retrieves the total number of interactions (`WORK`) performed during the execution of a program in the HVM3 runtime. It is primarily used for performance analysis, debugging, and diagnostics, providing insights into the computational workload and runtime behavior. By quantifying the reduction steps or interactions, `get_itr` helps developers evaluate the efficiency of the Interaction Combinator model, particularly in parallel execution environments. The function is implemented in C and exposed to the Haskell frontend via the Foreign Function Interface (FFI), making it accessible for high-level operations and runtime state monitoring."}
{"name": "get_len", "explanation": "The `get_len` function is a critical utility that retrieves the current length of the heap in the runtime's memory model, serving as a bridge between the Haskell frontend and the C backend. It is primarily used to monitor and debug memory usage, providing essential metrics such as the number of allocated nodes. In the Haskell frontend, `get_len` is employed in contexts like statistics generation, heap dumping, and main function generation, enabling developers to assess performance, inspect computational graphs, and summarize memory usage at the end of program execution. This function ensures efficient memory management and offers valuable insights into the runtime's behavior, particularly in parallel execution environments."}
{"name": "go", "explanation": "In the HVM3 codebase, `go` is a recursive helper function used to modularize and encapsulate traversal logic. It is commonly employed in functions like `flattenBFS`, `flattenPQ`, `lexify`, and `prettyRename` to handle recursive operations on data structures such as `Collapse` and `Core` terms. For instance, it traverses and flattens nested structures, renames variables for lexical scoping, or generates pretty-printed names. The `go` function typically takes an accumulator (e.g., a queue or map) to manage state during recursion, allowing the main function to focus on initialization and finalization. This pattern enhances code readability and maintainability by isolating recursive logic into a reusable and modular component."}
{"name": "got", "explanation": "The `got` function is a low-level operation that retrieves a `Term` from a specified memory location (`Loc`). It plays a central role in the runtime system by enabling access to terms during term reduction, memory management, compilation, and parallel execution. During term reduction, `got` fetches subterms for evaluation or manipulation, as seen in functions like `reduceAt`. In memory management, it accesses terms at specific addresses to support dynamic term manipulation and interaction combinator rules. In compilation, `got` retrieves terms when translating high-level `Core` terms into low-level C code, such as fetching arguments for function calls. Additionally, in parallel execution, `got` is used by the `Collapse` monad and `Sup` operation to manage terms involved in parallel computations. Overall, `got` is essential for efficient term access, underpinning the runtime's core operations and enabling HVM3's parallel execution model."}
{"name": "heapToString", "explanation": "The `heapToString` function is a utility designed to convert the contents of the heap into a human-readable string format, aiding in debugging and inspection within the HVM3 runtime. The heap stores `Term` nodes, which represent the computational graph, and this function processes a list of tuples containing memory addresses (`Word64`) and their corresponding `Term` values. By generating a string representation, developers can efficiently analyze the heap's state, identify anomalies, and ensure proper term management. The optional `itr` parameter may control the scope or granularity of the output, such as limiting the range of addresses or adjusting the level of detail. This function is particularly valuable for diagnosing runtime issues and verifying the correctness of heap operations."}
{"name": "hvmDefine", "explanation": "The `hvmDefine` function is a critical component in the HVM3 runtime system, responsible for linking compiled functions to their corresponding function IDs. During compilation, Haskell code is transformed into C code and compiled into shared libraries. `hvmDefine` registers these compiled functions by mapping a unique function ID (`fid`) to a function pointer (`func`) that references the compiled C code. This mapping allows the runtime to efficiently locate and execute the appropriate function when its ID is encountered during program execution. By enabling this dynamic linkage, `hvmDefine` ensures that the runtime can leverage native code execution for optimal performance, particularly in handling parallel and computationally intensive tasks. Its role is foundational to the runtime's ability to manage and execute compiled functions seamlessly."}
{"name": "hvmFree", "explanation": "The `hvmFree` function is responsible for cleaning up the HVM3 runtime environment after computation. It releases dynamically allocated memory, closes open resources, and resets the runtime state to ensure system stability and prevent memory leaks. This function is crucial for maintaining performance in parallel computing environments, where efficient resource management is vital. It works in tandem with `hvmInit`, which initializes the runtime, to complete the runtime's lifecycle management."}
{"name": "hvmGetState", "explanation": "The `hvmGetState` function retrieves the runtime state from the C backend, enabling the Haskell frontend to interact with and manage the state during execution. It is typically called after loading a dynamically compiled shared library (`bookLib`) and registering compiled functions. The retrieved state (`hvmGotState`) is then used to link the compiled state, ensuring proper initialization and continuity of the runtime environment. This function is crucial for maintaining synchronization between the Haskell and C components, facilitating seamless execution of compiled code."}
{"name": "hvmInit", "explanation": "The `hvmInit` function initializes the HVM runtime system, setting up essential components such as memory management, the `Book` data structure for function definitions, and the runtime state for parallel execution. It is invoked at the start of the `cliRun` function in the Haskell frontend and is also included in the C code generated by `genMain` to ensure proper runtime initialization before computation begins. This function is crucial for establishing the foundation required for the HVM's parallel evaluation model and efficient memory management."}
{"name": "hvmSetState", "explanation": "The `hvmSetState` function is a critical component of the HVM3 runtime, facilitating the synchronization of the internal state between the Haskell frontend and the C backend. It is invoked after the C code is compiled into a shared library and loaded into memory, ensuring that the runtime state\u2014including function definitions, memory allocations, and term representations\u2014is properly initialized and accessible. This function enables the Haskell frontend to update the C backend's state, maintaining consistency and integrity during execution. By doing so, `hvmSetState` supports efficient memory management and seamless parallel computation, ensuring the runtime operates as intended."}
{"name": "hvm_define", "explanation": "The `hvm_define` function is a critical component in the HVM3 runtime, responsible for linking function IDs (`fid`) with their corresponding function pointers (`func`). It is implemented in the C backend (`hvm.c`) and accessed via the Haskell frontend (`hvm.hs`) through a foreign function interface (FFI). During compilation, the Haskell frontend generates C code for functions in the `Book` data structure, which are compiled into a shared library. The `hvm_define` function is then used to register each function's ID and pointer in the runtime, enabling dynamic linking and execution of compiled functions. This mechanism ensures efficient management and execution of the compiled code during runtime."}
{"name": "hvm_free", "explanation": "The `hvm_free` function is responsible for cleaning up the HVM3 runtime system by releasing all allocated resources and resetting the runtime state. It deallocates memory used for nodes, terms, and other runtime structures, unloads dynamically loaded libraries, and releases system resources like file handles or network connections. Additionally, it resets global or runtime-specific state to its initial condition, ensuring the system is ready for subsequent executions. Called at the end of the `cliRun` function in the Haskell frontend and implemented in the C backend, `hvm_free` guarantees proper cleanup, maintaining the runtime's efficiency and reliability, particularly in parallel execution environments where resource management is crucial."}
{"name": "hvm_get_state", "explanation": "The `hvm_get_state` function retrieves the internal state of the HVM runtime, which includes details about memory allocation, term reduction progress, and other runtime-specific data. It is used in the Haskell frontend, particularly within the `cliRun` function, to link the compiled state with the runtime after loading the dynamic library. This ensures proper execution of compiled functions and management of the computational graph. The function returns a raw pointer (`Ptr ()`) to the `State` structure, enabling direct interaction between the Haskell code and the C backend's internal state, which is essential for maintaining consistency and efficiency during parallel execution in the HVM system."}
{"name": "hvm_init", "explanation": "The `hvm_init` function initializes the HVM3 runtime, setting up the environment for efficient program execution on massively parallel hardware. It prepares memory management structures, configures the Interaction Combinator model, and ensures all runtime components are ready. Called at the start of both the Haskell frontend (`cliRun`) and C backend (`main`), it guarantees the runtime is equipped to handle parallel term evaluation. This initialization is essential for enabling correct and efficient program execution, as it establishes the foundation for memory management, term reduction, and parallel computation. Without `hvm_init`, the runtime would lack the necessary setup, leading to errors or inefficiencies."}
{"name": "hvm_set_state", "explanation": "The `hvm_set_state` function, defined in the C backend (`hvm.c`) and imported into the Haskell frontend (`hvm.hs`) via FFI, is responsible for updating the runtime's internal state with a new state object. This function is critical for state transitions, such as when loading a compiled shared library or resetting the runtime environment. In the `cliRun` function, `hvm_set_state` is invoked after initializing the runtime and loading the compiled library, ensuring the runtime is correctly configured to execute the compiled code. By synchronizing the Haskell frontend and C backend, `hvm_set_state` facilitates seamless integration and efficient parallel computation in the HVM3 system."}
{"name": "ifLetLab", "explanation": "The `ifLetLab` function is a utility in the HVM3 codebase that identifies and optimizes \"if-let\" pattern matches, a simplified form of pattern matching with a single constructor and a default case. It takes a `Book` (containing function definitions) and a `Core` term (representing the pattern match) as inputs. If the pattern match is an \"if-let\" match, it retrieves the constructor ID (`cid`) from the `Book` and returns `1 + cid`, which serves as a label for runtime optimization. If the pattern is not an \"if-let\" match or the constructor is not found, it returns `0`, indicating no special handling is needed. This function is integral to the compilation of `Mat` terms, ensuring efficient execution of pattern matching constructs."}
{"name": "incItr", "explanation": "The `incItr` function is a critical component of the HVM3 runtime, responsible for incrementing a global iteration counter that tracks the number of reduction steps performed during program execution. It is invoked within various reduction functions (e.g., `reduce_ref`, `reduce_let`, `reduce_app_lam`) to ensure accurate counting of each reduction operation. This counter serves multiple purposes, including debugging (to detect inefficiencies or infinite loops), performance monitoring (to assess computational complexity), and execution control (to limit reductions and prevent resource exhaustion). Implemented in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`), `incItr` is imported as a foreign function in Haskell and defined as a counter-incrementing function in C, ensuring consistent iteration tracking across the runtime system."}
{"name": "inc_itr", "explanation": "The `inc_itr` function is a core utility in the HVM3 runtime system, designed to increment an iteration counter that tracks the number of reduction steps during term evaluation. This counter serves multiple purposes, including debugging, performance monitoring, and execution control. By logging reduction steps, it helps identify inefficiencies, infinite loops, and provides insights into runtime performance. Implemented in C (`hvm.c`) and exposed via FFI to Haskell (`hvm.hs`), `inc_itr` is called in nearly every reduction function, such as `reduce_ref`, `reduce_let`, and `reduce_app_lam`, making it a critical component for managing and optimizing the evaluation process."}
{"name": "injectCore", "explanation": "The `injectCore` function is a critical component in the HVM3 codebase, responsible for translating high-level `Core` terms into low-level runtime terms that the HVM3 runtime can execute. Operating within the `InjectM` monad, it manages state and effects during the injection process. The function takes a `Book` (containing function definitions and metadata), a `Core` term (the high-level term to be translated), and a `Loc` (the memory location for the runtime term). It handles various `Core` term types, such as `Era`, `Var`, `Let`, `Lam`, `App`, `Sup`, `Dup`, `Ref`, `Ctr`, `Mat`, `U32`, `Chr`, and `Op2`, ensuring each is correctly translated into a runtime term with the appropriate structure and semantics. This translation is vital for preserving program semantics during compilation and enabling efficient parallel execution on massively parallel hardware."}
{"name": "intoIfLetChain", "explanation": "The `intoIfLetChain` function transforms a list of pattern match cases into a nested chain of `if-let` expressions, ensuring proper evaluation order. It is primarily used in the `parseMat` function to handle pattern matches that include a default case (`_`). When the last case is a default, the function recursively constructs `if-let` expressions for each case, with the default case serving as the fallback. If the list of cases is empty, it returns the body of the default case. This transformation enables structured and efficient pattern matching, particularly in the HVM3 runtime, where such operations are frequent."}
{"name": "labToString", "explanation": "The `labToString` function converts a `Word64` value, representing a label or location in the computational graph, into a hexadecimal string. It uses `showHex` for the conversion and pads the result to 6 characters with leading zeros using `padLeft`, ensuring a consistent and readable format. This function is primarily used within `termToString` to provide a standardized string representation of labels, aiding in debugging and making the computational state more interpretable for developers."}
{"name": "lexify", "explanation": "The `lexify` function is a key component in the Haskell frontend (`hvm.hs`) that ensures lexical scoping correctness during the creation of the `Book` data structure. It processes `Core` terms by recursively traversing and renaming lexically scoped variables to guarantee uniqueness, preventing variable shadowing and ensuring unambiguous references. Using a state monad, it manages the naming context and assigns unique identifiers, while exempting variables prefixed with `$` to preserve their original names. For instance, the term `\u03bbx \u03bbt (t \u03bbx(x) x)` is transformed into `\u03bbx0 \u03bbt1 (t1 \u03bbx2(x2) x0)`, ensuring distinct identifiers for each variable based on its scope. This transformation is vital for maintaining program correctness, particularly in nested or complex functions where name clashes could otherwise occur."}
{"name": "liftDups", "explanation": "The `liftDups` function is a recursive transformation applied to `Core` terms, which represent high-level program constructs. It processes each type of `Core` term (e.g., `Var`, `Ref`, `Lam`, `App`, `Sup`, `Dup`, etc.) to manage duplication efficiently. For simple terms like `Var`, `Era`, `U32`, and `Chr`, it leaves them unchanged, as they do not involve duplication. For composite terms like `Ref`, `Lam`, `App`, `Sup`, `Ctr`, `Op2`, and `Let`, it recursively transforms their subterms and combines the results. For `Dup` terms, which explicitly handle duplication, it transforms the value and body, returning the modified body and a reconstruction function to preserve the original duplication logic. Helper functions (`liftDupsList`, `liftDupsMov`, `liftDupsCss`) handle lists, movement patterns, and case structures, ensuring comprehensive processing. The `doLiftDups` function applies `liftDups` and reconstructs the term, maintaining the duplication logic. This function is essential in the HVM3 runtime for enabling efficient parallel execution and supporting the Interaction Combinator model."}
{"name": "liftDupsCss", "explanation": "The `liftDupsCss` function is a critical component in the HVM3 runtime system, designed to optimize pattern matching constructs (`Mat`) during compilation. It processes case branches, represented as tuples `(c, fs, b)` where `c` is a constructor name, `fs` is a list of field names, and `b` is the body term. The function lifts duplications (`Dup` operations) within the body terms of these branches to the appropriate level, ensuring correctness and efficiency in the parallel evaluation model. By recursively applying the `liftDups` function to each branch, `liftDupsCss` returns a transformed list of case branches and a function to apply the lifted duplications to other terms, facilitating efficient parallel execution of the compiled code."}
{"name": "liftDupsList", "explanation": "The `liftDupsList` function processes a list of `Core` terms, which represent high-level computational constructs in the HVM3 system. It recursively applies the `liftDups` function to each term, ensuring that duplication operations are correctly lifted and handled during compilation and execution. This is particularly important for parallel evaluation, where duplication operations must be managed efficiently. The function returns a tuple containing a list of transformed `Core` terms and a function to apply the same transformation to additional terms, enabling modular and consistent term transformation across the codebase. `liftDupsList` is used in processing `Ref` and `Ctr` terms, transforming their associated arguments or fields, and is a key component in the term transformation pipeline for parallel computation in HVM3."}
{"name": "liftDupsMov", "explanation": "The `liftDupsMov` function processes movement patterns (`mov`) within a `Mat` term, which represents pattern matching in `Core` terms. It works recursively on the list of movement patterns, applying the `liftDups` function to each pattern's associated `Core` term. This returns a transformed term and a function for further transformations, which `liftDupsMov` combines to ensure consistent application across all patterns. When the list of movement patterns is empty, the function returns an empty list and the identity function (`id`), signaling no further transformations are needed. `liftDupsMov` is essential for lifting duplication operations in movement patterns, ensuring efficient and correct program execution in the HVM3 runtime."}
{"name": "locToString", "explanation": "The `locToString` function converts a `Word64` value, representing a memory location, into a formatted hexadecimal string. It uses `showHex` to generate the hexadecimal representation and then applies `padLeft` to ensure the string is exactly 9 characters long by adding leading zeros. This uniform formatting aids in readability and comparison of memory locations, particularly during debugging or runtime state inspection. The function is utilized in `termToString` to provide a clear string representation of the location component within a `Term`, facilitating analysis of the computational graph's structure and state."}
{"name": "main", "explanation": "The `main` function serves as the entry point for executing programs in the HVM3 runtime. It orchestrates the entire process, starting with initializing the runtime environment via `hvmInit`. It then parses the input file into a `Book` structure, which holds function definitions and metadata. Depending on the `compiled` flag, it optionally generates and compiles C code into a shared library using `gcc`. The function locates and normalizes the `main` function within the `Book` to execute the program, exiting with an error if `main` is not found. Finally, it handles cleanup by removing temporary files and shutting down the runtime. The `main` function is critical for integrating parsing, compilation, and execution, ensuring the program runs efficiently and correctly."}
{"name": "mget", "explanation": "The `mget` function is a fundamental utility in the HVM3 codebase, designed to retrieve values from a map using a specified key. It takes two arguments: a map and a key, and returns the value associated with that key. This function is widely used throughout the codebase for tasks such as accessing function definitions, retrieving metadata, and managing data during compilation. For instance, in the `compileWith` function, `mget` is employed to extract critical information like the copy flag, arguments, and core terms from the `Book` data structure. Similarly, in the `cliRun` function, it is used to fetch the function ID for the `main` function, ensuring proper program execution. Its consistent use underscores its role in enabling efficient and reliable access to mappings, which is essential for the HVM3 runtime system's functionality and performance."}
{"name": "modeT", "explanation": "The `modeT` function translates label values (`Lab`) into corresponding `Mode` values, which represent evaluation strategies such as lazy (`LAZY`), strict (`STRI`), and parallel (`PARA`). It uses pattern matching to map specific labels: `0x00` to `LAZY`, `0x01` to `STRI`, and `0x02` to `PARA`. If the label does not match any of these values, the function raises an error indicating an unknown mode. This function is essential for determining the evaluation strategy of a term based on its label, enabling the runtime to adapt its behavior during term reduction and execution. It works in conjunction with `modeToString`, which provides a human-readable representation of the mode for debugging or output purposes. `modeT` ensures the HVM3 system executes programs efficiently and correctly by dynamically selecting the appropriate evaluation strategy."}
{"name": "modeToString", "explanation": "The `modeToString` function converts evaluation modes into their corresponding string representations, aiding in the generation of human-readable or debug-friendly output for `Core` terms, particularly in `Let` expressions. It accepts one of three modes: `LAZY` (lazy evaluation, represented by `\"\"`), `STRI` (strict evaluation, represented by `\".\"`), or `PARA` (parallel evaluation, represented by `\"^\"`). This function is crucial for embedding the evaluation strategy into the output string, ensuring clarity in how bindings are evaluated. For instance, a `STRI` mode results in a dot preceding the variable name, indicating strict evaluation. This concise utility plays a key role in the codebase's string generation logic."}
{"name": "mut", "explanation": "The `mut` keyword in Rust is used to declare a mutable variable or reference, allowing the value it holds to be modified after its initial assignment. Unlike immutable variables, which cannot be changed once set, `mut` enables in-place updates, making it essential for scenarios where data needs to be altered during program execution. This feature is particularly useful in performance-critical code, as it avoids unnecessary allocations by reusing existing memory. However, Rust's strict borrowing rules ensure that mutable references are exclusive, preventing data races and maintaining memory safety. In the context of the HVM3 codebase, `mut` might be used to modify internal state during compilation or execution, such as updating term representations or function definitions in the `Book` data structure."}
{"name": "normal", "explanation": "The `normal` function is a core component of the HVM3 runtime, responsible for reducing terms to their normal form\u2014a fully evaluated state where no further reductions are possible. It ensures computations are complete and correct before proceeding to subsequent steps like output or further processing. In `hvm.hs`, `normal` is applied to the root term after runtime initialization, guaranteeing full evaluation before program termination. In `hvm.c`, it handles term types such as `LAM`, `APP`, `SUP`, `DP0`/`DP1`, `CTR`, and `MAT`, recursively reducing subterms to achieve full evaluation. Leveraging the Interaction Combinator model, `normal` optimizes parallelism and performance, making it essential for the runtime's efficient and accurate evaluation of complex computations."}
{"name": "operToString", "explanation": "The `operToString` function converts an internal operator representation (`Oper`) into its corresponding human-readable string form. It maps operator types (e.g., `OP_ADD` to `\"+\"`, `OP_SUB` to `\"-\"`) to facilitate parsing and string representation tasks. This function is essential for interpreting operator symbols during parsing and for generating readable output when converting `Core` terms to strings. By centralizing the mapping logic, `operToString` ensures consistency, simplifies maintenance, and promotes code reuse across the system."}
{"name": "padLeft", "explanation": "The `padLeft` function ensures consistent formatting of hexadecimal values by padding them with leading zeros to a specified length. It is primarily used in functions like `labToString`, `locToString`, and `heapToString` to format labels, memory addresses, and iteration counters into uniform-length hexadecimal strings. This standardization improves readability and debugging, particularly in low-level contexts such as memory address representation and runtime state visualization. By maintaining a consistent format, `padLeft` enhances code clarity and maintainability."}
{"name": "parseADT", "explanation": "The `parseADT` function parses algebraic data type (ADT) definitions in the input program. It begins by matching the `\"data\"` keyword using the `consume` function to identify the start of an ADT definition. Next, it extracts the ADT's name using `parseName`. The function then parses the constructors by consuming an opening brace `\"{\"` and using `parseADTCtr` to process each constructor, which returns a tuple of the constructor name and its parameters. This function is integrated into `parseBook`, which parses the entire program by repeatedly calling `parseADT` to build a structured representation of all ADT definitions. These parsed definitions are essential for the compiler to generate efficient low-level C code for the HVM3 runtime, enabling the handling of complex data types and operations."}
{"name": "parseADTCtr", "explanation": "The `parseADTCtr` function is a `ParserM` action that parses individual constructors within an algebraic data type (ADT) definition. It returns a tuple `(String, [String])`, where the first element is the constructor name and the second is a list of its argument types. This function is invoked by `parseADT` to handle constructor definitions in the source code. Using parser combinators, `parseADTCtr` extracts the necessary details, enabling the construction of an internal representation of the ADT. This representation is crucial for the compilation process, as it ensures the runtime can correctly interpret and execute programs utilizing ADTs."}
{"name": "parseBook", "explanation": "The `parseBook` function is responsible for converting a raw string input into a structured format that the HVM3 runtime can process. It parses the string representation of a book into a list of function definitions, each containing a function name, metadata (such as recursion status and argument patterns), and the corresponding `Core` term. This parsed data is then used by the `createBook` function to build a `Book` data structure, which stores all function definitions and metadata for efficient lookup and resource management during execution. As a foundational component of the compilation and execution pipeline, `parseBook` ensures the system can correctly interpret and process input programs."}
{"name": "parseBookWithState", "explanation": "The `parseBookWithState` function is responsible for parsing a program string into a structured `Book` object, which contains function definitions and metadata required for execution. It operates within the `ParserM` monad to manage parsing state and handle errors, ensuring the input is correctly interpreted. This function is crucial for transforming raw program text into a format that the runtime can process, enabling subsequent compilation and execution phases in the HVM3 system."}
{"name": "parseChr", "explanation": "The `parseChr` function is responsible for parsing character literals in the HVM3 codebase. When the parser encounters a single quote (`'`), it invokes `parseChr` to read and validate the subsequent character from the input stream. The function then constructs a `Core` term, which serves as an internal representation of the character for further processing, such as compilation or execution. By encapsulating this logic in a dedicated function, the codebase achieves modularity and clarity, ensuring consistent handling of character literals. `parseChr` also utilizes the `ParserM` monad to manage parsing state and handle errors, contributing to the robustness of the parsing process."}
{"name": "parseCore", "explanation": "The `parseCore` function is a key component in the HVM3 codebase, responsible for converting textual program representations into the internal `Core` term structure used by the compiler and runtime. It serves as the entry point for parsing user-defined programs, delegating specific tasks to specialized helper functions. For example, it handles lambda expressions (`Lam`) by identifying the `\u03bb` symbol and parsing the variable and body, while operators, references (`@`), constructors (`#`), and pattern matching (`~`) are processed by dedicated parsers like `parseOper`, `parseRef`, `parseCtr`, and `parseMat`. The function is recursive, enabling it to manage nested expressions, such as function applications, by parsing the function and its arguments in sequence. The resulting `Core` terms are then passed to the compilation phase, where they are translated into executable C code. This makes `parseCore` essential for accurately interpreting and preparing input programs for further processing in the HVM3 system."}
{"name": "parseCtr", "explanation": "The `parseCtr` function is a key part of the parsing process in the HVM3 codebase, specifically designed to handle constructor terms. Constructors are foundational in functional programming, used to define data types and their instances, and are crucial for pattern matching and term reduction. When the parser encounters the `#` symbol, it invokes `parseCtr` to process the constructor's name, arguments, and metadata. The function then constructs and returns a `Core` term representing the parsed constructor, ensuring it is ready for compilation and execution within the runtime. This precise parsing of constructor terms is vital for maintaining program structure and enabling efficient evaluation in the Interaction Combinator model, directly impacting the correctness and performance of the HVM3 system."}
{"name": "parseDef", "explanation": "The `parseDef` function is a core parsing utility in the HVM3 codebase, operating within the `ParserM` monad to parse function definitions. Its type signature, `ParserM (String, ((Bool, [(Bool, String)]), Core))`, reveals that it extracts a function's name, metadata, and body. The metadata includes a `Bool` indicating recursion and a list of parameters, where each parameter is annotated with a `Bool` (likely for strictness) and a `String` (the parameter name). The `Core` type represents the parsed function body, a high-level term in the `Core` language. `parseDef` is used by `parseBook` to compile function definitions into a `Book`, a repository of definitions and metadata for the runtime. This parsing step is essential for translating high-level `Core` terms into low-level C code, enabling efficient execution in the HVM3 runtime."}
{"name": "parseEscapedChar", "explanation": "The `parseEscapedChar` function is responsible for interpreting escaped characters (e.g., `\\n`, `\\t`, `\\\\`) during the parsing process. It uses a `choice` combinator to match the input against predefined patterns and returns the corresponding `Char` value, such as mapping `\\n` to a newline or `\\\\` to a backslash. This ensures that escaped characters are correctly processed, enabling accurate translation of the input program into the high-level `Core` representation. Without `parseEscapedChar`, the parser would fail to handle escaped characters, leading to errors in program compilation and execution."}
{"name": "parseLst", "explanation": "The `parseLst` function is responsible for parsing list structures in the input program. When the parser detects a '[' character, `parseLst` processes the subsequent elements, converting them into a `Core` term, which is the intermediate representation used by the compiler. This ensures that list operations are accurately represented and can be efficiently handled during compilation and execution. By transforming lists into `Core` terms, `parseLst` plays a crucial role in bridging the high-level input program and the low-level C code generated by the compiler, contributing to the system's overall efficiency and correctness."}
{"name": "parseMat", "explanation": "The `parseMat` function is a `ParserM Core` function responsible for parsing pattern matching constructs in the HVM3 codebase. When the parser encounters the `~` symbol, it calls `parseMat` to process the subsequent pattern matching expression, which may involve matching values against constructors, variables, or other patterns. The function ensures that the pattern matching construct is accurately represented in the `Core` term, the abstract syntax tree (AST) used for compilation. This representation is critical for enabling the compiler to generate efficient low-level code for pattern matching, a core operation in functional programming. By handling these constructs, `parseMat` supports the runtime's ability to execute complex, parallel computations effectively."}
{"name": "parseName", "explanation": "The `parseName` function is a key utility in the HVM3 codebase, designed to extract identifiers (names) from the input program. It skips leading whitespace and captures sequences of alphanumeric characters, underscores (`_`), dollar signs (`$`), and ampersands (`&`), accommodating diverse naming conventions. This function is widely used across various parsing contexts, including lambda expressions, references, constructors, pattern matching, function definitions, and algebraic data types. By accurately parsing identifiers, `parseName` ensures the correct interpretation of variables, functions, and other entities, forming a critical foundation for subsequent compilation and execution phases."}
{"name": "parseName1", "explanation": "The `parseName1` function is a key utility in the HVM3 codebase for parsing valid names, which are used to identify variables, functions, constructors, and other program entities. It employs the `many1` combinator to parse one or more characters from a set of allowed characters (alphanumeric, underscores, dollar signs, and ampersands), ensuring syntactically correct and unambiguous names. This function is reused across various parsing tasks, such as extracting variable names in lambda expressions, parsing references, identifying constructor names, and handling pattern matching cases. By centralizing name parsing logic, `parseName1` enhances code consistency, reduces redundancy, and minimizes parsing errors, contributing to the overall robustness and maintainability of the codebase."}
{"name": "parseOper", "explanation": "The `parseOper` function is a critical component in the HVM3 codebase, responsible for parsing binary and relational operators (e.g., `+`, `-`, `*`, `/`, `=`, `<`, `>`) from the input program and converting them into the `Core` representation used by the runtime. When the parser encounters an operator, it invokes `parseOper` with the corresponding `Oper` value (e.g., `OP_ADD` for `+`), which then constructs a `Core` term representing the operator in the intermediate format. This term is later translated into low-level C code during compilation, ensuring efficient execution. As part of the Haskell frontend's parsing logic, `parseOper` enables the compiler to handle complex expressions involving arithmetic, logical, and relational operations, ensuring accurate program execution. Its role is vital for the correct functioning of the compilation and execution pipeline."}
{"name": "parseRef", "explanation": "The `parseRef` function is responsible for parsing reference terms in the HVM3 codebase. When the parser encounters the `@` symbol, it invokes `parseRef` to interpret the following input as a reference. References are critical in the Interaction Combinator model, enabling terms to point to other terms or memory locations, which facilitates graph-based computation and parallel evaluation. By converting references into the `Core` representation, `parseRef` ensures that the input program is accurately transformed into a format suitable for runtime processing. This function is a key component of the parsing infrastructure, bridging the gap between high-level program input and low-level runtime execution, and ensuring all necessary information is captured for compilation and evaluation."}
{"name": "parseStr", "explanation": "The `parseStr` function is a monadic parser (`ParserM Core`) responsible for interpreting string literals in the HVM3 codebase. When the parser encounters a double-quote (`\"`), `parseStr` reads the subsequent characters until the closing double-quote is found, encapsulating the parsed string into a `Core` term. This ensures that string literals are accurately represented in the computational graph, enabling efficient runtime operations such as concatenation, pattern matching, and function application. By handling strings as first-class citizens, `parseStr` preserves the semantic integrity of the input program and facilitates their translation into the runtime's internal representation."}
{"name": "pass", "explanation": "The `pass` statement in Python is a null operation, meaning it does nothing when executed. It is commonly used as a placeholder in situations where syntax requires a statement but no action is desired, such as in empty functions, loops, or conditional blocks. Its primary purpose is to maintain the structural integrity of the code while allowing for future implementation. For example, it can be used to define a function or class skeleton without writing its logic immediately. This makes `pass` a useful tool during development for avoiding syntax errors and planning code structure."}
{"name": "pqPop", "explanation": "The `pqPop` function is responsible for extracting the highest-priority element from a priority queue. It handles two cases: if the queue is empty (`PQLeaf`), it returns `Nothing`; if the queue contains elements (`PQNode`), it retrieves the top element and merges the remaining left and right subtrees using `pqUnion` to form the updated queue. This function is essential in the `flattenPQ` process, where it ensures elements are processed in priority order during the flattening of a `Collapse` computation. By managing the priority queue efficiently, `pqPop` supports the HVM3 runtime in handling parallel computations effectively."}
{"name": "pqPut", "explanation": "The `pqPut` function is responsible for inserting elements into a priority queue, a key data structure used in the HVM3 runtime to manage parallel computations within the `Collapse` monad. It ensures that elements are added to the queue in a way that maintains their priority order, enabling efficient retrieval of the highest-priority tasks during execution. This functionality is critical for optimizing the traversal and processing of `Collapse` terms, as it allows the runtime to prioritize and schedule computations effectively, enhancing performance and resource utilization in parallel environments."}
{"name": "pqUnion", "explanation": "The `pqUnion` function merges two priority queues (`PQ`) into a single priority queue, maintaining the correct order of elements based on their priorities. If one queue is empty (`PQLeaf`), it returns the other queue. For non-empty queues, it compares the root nodes' keys (priorities) and recursively merges the queues by creating a new `PQNode` with the root of the queue having the higher priority and merging the other queue with its right subtree. This ensures the resulting queue preserves the priority order. `pqUnion` is a core operation used in functions like `pqPop` and `pqPut`, enabling efficient management of prioritized tasks or computations in the HVM3 runtime."}
{"name": "pretty", "explanation": "The `pretty` function in the HVM3 codebase is a utility designed to convert `Core` terms into a human-readable format, primarily for debugging and runtime inspection. It first attempts to use `prettyStr` to generate a string representation of the term. If this fails, it falls back to `prettyLst`, which handles list-like structures. `prettyStr` processes string-like terms, such as empty strings (`Ctr 0 []`) or character sequences (`Ctr 1 [Chr h, t]`), into readable strings (e.g., `\"ab\"`). Similarly, `prettyLst` processes list-like terms, such as empty lists (`Ctr 0 []`) or element sequences (`Ctr 1 [x, xs]`), into readable lists (e.g., `[1 2]`). This function is integral to tools like `showCore`, which displays `Core` terms, making it easier to understand and debug the code."}
{"name": "prettyLst", "explanation": "The `prettyLst` function is a utility in the HVM3 codebase designed to format and display list structures within the `Core` representation. It works in tandem with the `pretty` function, handling the specific formatting of lists while delegating other term types to `pretty`. This separation of concerns ensures clean and readable output, especially for debugging purposes. The function is recursive, enabling it to properly format nested lists, and it gracefully returns `Nothing` for non-list terms, making it flexible and error-resistant. By providing a clear visualization of list structures, `prettyLst` enhances the usability and maintainability of the codebase."}
{"name": "prettyRename", "explanation": "The `prettyRename` function transforms a `Core` term by renaming variables to more readable and meaningful identifiers, improving clarity when displaying the program's structure. It uses `unsafePerformIO` to handle potential side effects, such as generating unique names or maintaining a mapping between original and renamed variables. This function is particularly useful in conjunction with `showCore`, as it ensures that the displayed `Core` representation is easier to interpret, aiding developers in understanding the program's logic and behavior."}
{"name": "prettyStr", "explanation": "The `prettyStr` function is a utility in the HVM3 codebase designed to convert `Core` terms into human-readable strings, aiding in debugging and inspection. It provides a clear representation of the internal state of computations, which is especially valuable for understanding complex or parallel evaluations. When used in conjunction with the `pretty` function, `prettyStr` serves as the primary method for generating readable outputs. If `prettyStr` fails to produce a result, `pretty` falls back to alternative methods like `prettyLst`, ensuring robust and flexible pretty-printing capabilities. Overall, `prettyStr` enhances developer productivity by offering intuitive insights into the system's behavior."}
{"name": "primitives", "explanation": "The `primitives` list is a registry of primitive functions in the HVM3 runtime, where each entry is a tuple containing the function's name (as a `String`) and its associated label (`Lab`). These labels uniquely identify and reference primitive functions during compilation and execution. When the `createBook` function initializes the `Book` data structure, `primitives` is merged with other mappings (e.g., `n2i`) using `MS.union`, ensuring that primitive functions are included in the `Book` for efficient lookup and execution. This integration allows the runtime to seamlessly handle built-in operations, making `primitives` essential for managing function definitions and metadata in HVM3."}
{"name": "printHelp", "explanation": "The `printHelp` function is a utility designed to assist users by displaying usage instructions, available commands, and options for the HVM3 runtime system. It is invoked by the `main` function when the user requests help (e.g., via the `help` command) or provides invalid arguments. The function's return type, `IO (Either String ())`, indicates it handles potential errors internally, such as printing failures, and returns a result accordingly. This makes `printHelp` essential for user onboarding and error handling in the HVM3 codebase."}
{"name": "print_heap", "explanation": "The `print_heap` function is a debugging utility in the HVM3 runtime system that outputs the current state of the heap, which stores `Term` nodes representing the computational graph. It helps developers inspect memory allocation, verify correct node manipulation, and visualize the graph structure, aiding in identifying memory-related issues and ensuring proper program execution during development and testing."}
{"name": "print_tag", "explanation": "The `print_tag` function is a debugging utility in the HVM3 codebase designed to output the tag of a `Term`. Tags, such as `ERA`, `REF`, `NUM`, `CON`, or `DUP`, define the type of a term and are crucial for the runtime to apply the correct reduction rules during evaluation. This function is often used within `print_term` to display a term's tag, label, and location, aiding developers in inspecting the state of computations. It also appears in debugging code to log term tags during reduction, making it a valuable tool for diagnosing and understanding program behavior in the HVM3 runtime."}
{"name": "print_term", "explanation": "The `print_term` function is a debugging utility in the HVM3 runtime system, designed to output the internal representation of a `Term`, a fundamental data structure representing nodes in the computational graph. It prints details such as the term's tag, label, and other attributes, enabling developers to inspect and verify the state of terms during execution. This is particularly valuable in HVM3's parallel, graph-based environment, where tracking term states is critical for debugging and optimizing performance. Often used alongside related utilities like `print_term_ln` and `print_heap`, `print_term` plays a key role in ensuring the runtime's correctness and efficiency."}
{"name": "print_term_ln", "explanation": "The `print_term_ln` function outputs a human-readable representation of a `Term`, which is a node in the computational graph of the Interaction Combinator model. It takes a single `Term` argument, prints its structure and contents to standard output, and appends a newline for readability. This function is primarily used for debugging and development, enabling developers to inspect terms during runtime, verify term manipulations, and diagnose issues in the HVM3 runtime system."}
{"name": "putI", "explanation": "The `putI` function, defined as `putI bs = \\x -> bs (I x)`, takes a function `bs` of type `Bin -> Bin` and returns a new function that applies `bs` to an `I x` value, where `I` is a constructor for the `Bin` type representing binary choices in computation paths. This function is primarily used in the `fork` function when processing the right branch of a `CSup` (superposition) term. By modifying the paths in the `IntMap`, `putI` ensures that the right branch is correctly tracked during evaluation. Together with `putO`, `putI` plays a crucial role in the `Collapse` monad by updating paths to manage and reduce parallel computations efficiently, enabling the runtime to handle superposition and branching effectively."}
{"name": "putO", "explanation": "The `putO` function is essential for managing parallel computations within the `Collapse` monad. When a `CSup` (superposition) term is encountered by the `fork` function, the computation splits into two parallel branches. `putO` modifies the path map (`IntMap`) for the left branch, marking it with the `O` constructor. This marking ensures that the left branch is prioritized during the reduction process, enabling the `Collapse` monad to accurately handle and reduce parallel computations. By distinguishing between branches, `putO` plays a critical role in maintaining the integrity and efficiency of parallel evaluation."}
{"name": "reduce", "explanation": "The `reduce` function is a core evaluation mechanism in the HVM3 runtime system, responsible for reducing terms to their normal form based on their type. It processes terms by applying specific reduction rules depending on their tag, such as reducing function applications (`APP`) or pattern matches (`MAT`). This function is integral to both compilation and runtime execution, ensuring terms are evaluated correctly. Additionally, `reduce` supports parallel execution by working with constructs like the `Collapse` monad and the `Sup` operation, enabling the management of parallel computations and the combination of superposed terms. Its role is pivotal in maintaining the correctness and efficiency of the HVM3 system."}
{"name": "reduceAppCtr", "explanation": "The `reduceAppCtr` function is responsible for handling the reduction of application terms (`APP`) where the function part is a constructor (`CTR`). In functional programming, constructors are used to build data structures, and applying a constructor to an argument typically results in a new term representing the constructed data. Within the HVM3 runtime, `reduceAppCtr` ensures that this application is correctly evaluated by allocating memory for the new term, setting appropriate tags and labels, and updating the computational graph to reflect the new state. This function is part of a suite of reduction functions (`reduceAppEra`, `reduceAppLam`, etc.) that specialize in different term interactions, enabling the runtime to efficiently manage diverse computational scenarios. By handling constructor applications, `reduceAppCtr` plays a vital role in maintaining the integrity and efficiency of the runtime's execution model."}
{"name": "reduceAppEra", "explanation": "The `reduceAppEra` function is a key component in the HVM3 runtime, specifically designed to handle the interaction between an application (`APP`) term and an erasure (`ERA`) term. In the Interaction Combinator model, `ERA` terms represent computations that can be safely discarded or simplified without impacting the final result. When an `APP` term is encountered, the runtime reduces its function part. If this function part is an `ERA` term, `reduceAppEra` is invoked to perform the necessary simplification, typically by returning a placeholder or a simplified term. This function ensures efficient term reduction, enabling the HVM3 runtime to execute parallel computations with optimal performance and correctness."}
{"name": "reduceAppLam", "explanation": "The `reduceAppLam` function is a core component of the HVM3 runtime, responsible for performing beta-reduction when a lambda term is applied to an argument. It substitutes the argument into the lambda's body, simplifying the expression and advancing the evaluation process. This function is invoked by the `reduceAt` mechanism when a lambda abstraction (`LAM`) is detected, ensuring that terms are reduced to their normal forms efficiently. Optimized for performance, `reduceAppLam` leverages low-level memory and term manipulation to support HVM3's parallel computation model, making it essential for the runtime's ability to handle functional program evaluation at scale."}
{"name": "reduceAppSup", "explanation": "The `reduceAppSup` function handles the reduction of an application (`APP`) term where the function part is a superposition (`SUP`) term. In the Interaction Combinator model, a superposition represents multiple parallel states or outcomes. When an `APP` is applied to a `SUP`, `reduceAppSup` distributes the application across the superposed states, enabling parallel evaluation. It decomposes the `SUP` into its components (e.g., `x0` and `x1`) and applies the `APP` to each, producing a new superposition that combines the results. This mechanism is crucial for efficiently executing parallel computations in the HVM3 runtime, ensuring superposed terms are correctly reduced and evaluated."}
{"name": "reduceAppW32", "explanation": "The `reduceAppW32` function handles the reduction of an application term (`APP`) when the function being applied is a 32-bit word (`W32`). In the HVM3 runtime, terms are represented as nodes in a computational graph, and `APP` denotes function application. When the function is a `W32`, `reduceAppW32` processes this specific case, ensuring proper interaction between the application term and the 32-bit word. This function is crucial for the runtime's evaluation process, enabling efficient handling of term applications to 32-bit words, which is essential for computational tasks. It is implemented in both Haskell and C, highlighting its role in the broader reduction engine that powers the HVM3 runtime's high-performance execution on parallel hardware."}
{"name": "reduceAt", "explanation": "The `reduceAt` function is the core reduction engine in the HVM3 runtime system, responsible for evaluating terms to their normal forms. It operates on a `Book` (containing function definitions and metadata) and a `host` location (pointing to a term in memory). The function processes various term types (e.g., `LET`, `APP`, `MAT`, `DP0`, `DP1`) by applying specific reduction rules. For instance, it evaluates the value in a `LET` binding before reducing the body, and for `APP` terms, it reduces both the function and argument before application. Memory efficiency is achieved through `got` and `set` operations for term retrieval and updates. Additionally, `reduceAt` supports parallelism via the `Collapse` monad, which manages multiple states and reduces them to a single result. This function is essential for the correct and efficient execution of terms in HVM3."}
{"name": "reduceC", "explanation": "The `reduceC` function is a core operation in the runtime system, responsible for reducing a `Term` to its weak head normal form. It directly manipulates the runtime's memory model and term representation, ensuring efficient evaluation according to the Interaction Combinator model. This function is invoked by `reduceCAt`, which retrieves the term from memory and delegates the reduction task to `reduceC`. As part of the C backend, `reduceC` plays a critical role in enabling the HVM3 system's parallel execution model, leveraging hardware parallelism to optimize term evaluation. Its low-level implementation supports the high-level abstractions managed by the Haskell frontend, bridging the gap between theoretical computation and practical execution."}
{"name": "reduceCAt", "explanation": "The `reduceCAt` function is a specialized term reduction engine in the HVM3 runtime, designed for compiled execution mode where code is compiled to C and executed natively. It serves as an optimized version of the general-purpose `reduceAt` function, tailored to leverage the performance benefits of the C backend. The `Bool` parameter in `reduceCAt` likely controls debugging output, enabling developers to monitor the reduction process when needed. In the `cliRun` function, `reduceCAt` is invoked when the `compiled` flag is set to `True`, ensuring efficient term reduction in a native execution environment. This function is critical for achieving high-performance parallel computations in the HVM3 runtime's compiled execution pipeline."}
{"name": "reduceDupCtr", "explanation": "The `reduceDupCtr` function handles the interaction between duplication (`DUP`) and constructor (`CTR`) terms in the Interaction Combinator model. When a `DUP` term encounters a `CTR` term, `reduceDupCtr` applies reduction rules to decompose the constructor term and distribute the duplication across its components. This ensures the duplication is correctly propagated while preserving the structure of the computation. The function is critical for maintaining the semantics and efficiency of the parallel execution engine, as it enables proper reduction of terms in the HVM3 codebase."}
{"name": "reduceDupEra", "explanation": "The `reduceDupEra` function handles the interaction between a duplication term (`DUP`) and an erasure term (`ERA`) in the Interaction Combinator model. It simplifies the computational graph by replacing both branches of the duplication with the erasure term, effectively eliminating redundant computations. This optimization is critical for maintaining efficiency in HVM3's parallel execution model, as it reduces unnecessary memory usage and computational overhead. The function is invoked during the reduction process when an `ERA` term is encountered within a duplication context, ensuring that the reduction rules are applied correctly and efficiently."}
{"name": "reduceDupLam", "explanation": "The `reduceDupLam` function handles the reduction of terms involving the duplication of lambda terms (`DUP` and `LAM`) in the HVM3 runtime. It ensures correct computation by applying reduction rules when a lambda term is duplicated, enabling parallel evaluation. The function processes the duplication term (`dup`) and the lambda term (`lam`), transforming them into simpler forms by creating new lambda terms for duplicated parts and updating the computational graph. This maintains the graph's structure while supporting HVM3's parallel execution model. As part of the reduction engine, `reduceDupLam` is essential for efficiently evaluating terms that combine duplication and lambda abstraction."}
{"name": "reduceDupRef", "explanation": "The `reduceDupRef` function is a critical component of the HVM3 runtime, specifically designed to handle interactions between duplication (`DUP`) and reference (`REF`) terms. When a duplication encounters a reference, `reduceDupRef` applies the `DUP-REF-COPY` rule, which ensures that duplicated references are correctly propagated through the computational graph. This involves creating new terms for each duplicated reference and updating the graph to reflect these changes. By efficiently managing these interactions, `reduceDupRef` maintains the integrity of the computational graph and enables parallel evaluation, a core feature of the Interaction Combinator model. Its role is essential for the correct and efficient execution of programs in the HVM3 runtime."}
{"name": "reduceDupSup", "explanation": "The `reduceDupSup` function is a key component in the HVM3 runtime, responsible for handling interactions between duplication (`DUP`) and superposition (`SUP`) terms within the Interaction Combinator model. It ensures that duplications are correctly managed in the presence of parallel execution by applying specific rules based on the labels of the interacting terms. When labels match, it directly assigns the `SUP` components to the duplicated terms; otherwise, it creates new `SUP` terms to preserve the superposition structure. This function is invoked during the reduction of complex terms involving both duplication and parallelism, enabling efficient parallel computation and maintaining the integrity of the evaluation process."}
{"name": "reduceDupW32", "explanation": "The `reduceDupW32` function is a specialized operation in the HVM3 runtime designed to handle the duplication of 32-bit word terms (`W32`). In the context of Interaction Combinators, duplication is essential for sharing terms across parallel computational paths. When a `W32` term is encountered, `reduceDupW32` ensures the term is accurately duplicated and distributed within the computational graph, maintaining the integrity of the original term's semantics. This function is critical for enabling efficient parallel evaluation, as it ensures that duplicated terms are correctly propagated, supporting the runtime's performance and correctness in handling parallel computations."}
{"name": "reduceLet", "explanation": "The `reduceLet` function reduces `LET` terms in the HVM3 runtime, which bind values to variables for use in subsequent computations. It operates differently based on the evaluation mode: in `LAZY` mode, it retrieves the value directly from memory using the `got` function, deferring evaluation until necessary; in `STRI` mode, it fully reduces the value using `reduceAt` before binding, ensuring strict evaluation. Implemented in both Haskell (`hvm.hs`) and C (`hvm.c`), `reduceLet` integrates with the runtime's reduction logic, supporting efficient handling of lazy and strict evaluation strategies. This flexibility is crucial for optimizing parallel execution and managing complex computations effectively."}
{"name": "reduceMatCtr", "explanation": "The `reduceMatCtr` function is a critical component in the HVM3 runtime, responsible for handling the interaction between `MAT` (pattern match) and `CTR` (constructor) terms. It implements the `MAT-CTR` reduction rule, which transforms a pattern match applied to a constructor into a new term representing the result of the match. This transformation is essential for correctly evaluating expressions involving pattern matching on constructors, ensuring accurate program behavior. The function operates within the low-level C runtime and is invoked via a foreign function interface (FFI) from the Haskell frontend, leveraging the efficiency of C for performance-critical operations. By processing the `MAT` and `CTR` terms and returning the reduced result, `reduceMatCtr` plays a key role in the recursive reduction process that drives the HVM3 runtime's execution model."}
{"name": "reduceMatEra", "explanation": "The `reduceMatEra` function handles the reduction of a `MAT` term when it encounters an `ERA` term, which represents erasure or deletion. In the HVM3 codebase, `MAT` terms are used for pattern matching, and `ERA` terms signify the removal of terms. This function ensures the correct reduction of `MAT` and `ERA` interactions according to Interaction Combinator rules. Implemented in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`), the Haskell code imports `reduceMatEra` as a foreign function from the C runtime, where the actual reduction logic resides for performance optimization. The C implementation, `reduce_mat_era`, simplifies the `MAT` term in the presence of an `ERA` term, likely by erasing or collapsing the term structure. This function is essential for maintaining the correctness and efficiency of the reduction process, particularly in a parallel execution environment, ensuring that the runtime can proceed with further reductions accurately and without unnecessary overhead."}
{"name": "reduceMatLam", "explanation": "The `reduceMatLam` function simplifies a `MAT` term when it encounters a `LAM` term in the HVM3 system. `MAT` terms are used for pattern matching, while `LAM` terms represent lambda abstractions. When a `MAT` is applied to a `LAM`, `reduceMatLam` performs the reduction to streamline the expression, adhering to the Interaction Combinator model for parallel evaluation. In the Haskell frontend, this function is invoked within `reduceAt` when a `MAT` matches against a `LAM`, and the reduction is executed in the C backend. The C implementation ensures the computational graph is updated correctly, maintaining the system's parallel evaluation integrity. This function is crucial for efficient and accurate pattern matching on lambda terms within HVM3's parallel execution framework."}
{"name": "reduceMatSup", "explanation": "The `reduceMatSup` function handles the interaction between a `MAT` term (pattern matching) and a `SUP` term (superposition) in the HVM3 system. It ensures that pattern matching is correctly distributed across the superposed terms, enabling parallel evaluation. The function decomposes the `SUP` term into its components, applies the `MAT` operation to each part, and combines the results to preserve parallelism. This operation is critical for the runtime's ability to efficiently evaluate pattern matching in parallel contexts, adhering to the Interaction Combinator model."}
{"name": "reduceMatW32", "explanation": "The `reduceMatW32` function specializes in reducing pattern matching (`MAT`) terms when they encounter 32-bit word (`W32`) or character (`CHR`) terms in the HVM3 runtime. It operates by inspecting the matched term, extracting its value, and determining the appropriate reduction rule to apply. This function is crucial for branching computations based on the structure or value of terms, ensuring efficient pattern matching. As a low-level function in `hvm.c`, it directly manipulates term structures in memory and is integrated into the reduction engine to evaluate terms to their normal form. Its role is vital for enabling high-performance, parallel execution in the Interaction Combinator model."}
{"name": "reduceOpxCtr", "explanation": "The `reduceOpxCtr` function is a key part of the HVM3 runtime's reduction engine, specifically handling the interaction between `OPX` (extended operations) and `CTR` (constructor) terms. When an `OPX` term encounters a `CTR` term during evaluation, `reduceOpxCtr` applies the necessary reduction rules to ensure correct and efficient computation. This involves operations like pattern matching, term substitution, or other term manipulations, all while adhering to the Interaction Combinator model's principles. Implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), `reduceOpxCtr` ensures the runtime can execute parallel computations effectively, maintaining the integrity of the computational graph and optimizing performance on modern hardware."}
{"name": "reduceOpxEra", "explanation": "`reduceOpxEra` is a function in the HVM3 codebase that handles the interaction between `OPX` (operation) and `ERA` (erasure) terms during graph reduction. It simplifies computations by reducing `OPX` terms in the presence of `ERA` terms, effectively erasing unnecessary parts of the graph. Implemented in the C backend (`hvm.c`) and accessed via FFI in the Haskell frontend (`hvm.hs`), this function ensures efficient graph management and contributes to the runtime's ability to execute parallel computations effectively within the Interaction Combinator model."}
{"name": "reduceOpxLam", "explanation": "The `reduceOpxLam` function handles the reduction of an `OPX` term when it interacts with a `LAM` term in the HVM3 runtime. `OPX` represents an operation that requires reduction, while `LAM` represents a lambda abstraction (a function). When the reduction engine encounters an `OPX` term followed by a `LAM` term, `reduceOpxLam` is invoked to apply the specific reduction rule for this interaction. This function ensures the computation proceeds correctly by manipulating the term's structure, updating memory, or triggering further reductions. Defined in the C backend (`hvm.c`) and referenced in the Haskell frontend (`hvm.hs`), `reduceOpxLam` is integral to the runtime's ability to efficiently evaluate parallel computations under the Interaction Combinator model."}
{"name": "reduceOpxSup", "explanation": "The `reduceOpxSup` function is a critical component of the reduction engine, designed to handle the application of an `OPX` operation to a `SUP` term, which represents a superposition of two terms. Its primary role is to distribute the `OPX` operation across both components of the `SUP` term, ensuring that the operation is applied uniformly in parallel. This behavior is essential for maintaining the parallelism inherent in the Interaction Combinator model, as it allows for efficient evaluation of superposed terms. By processing the `OPX` and `SUP` terms together, `reduceOpxSup` generates a new term that encapsulates the results of the parallel operation, enabling high-performance computation within the HVM3 runtime."}
{"name": "reduceOpxW32", "explanation": "The `reduceOpxW32` function is a critical component in the HVM3 runtime, specifically designed to handle the reduction of `OPX` terms containing `W32` subterms. It operates within the Interaction Combinator model, a graph-based computational framework that enables parallel evaluation of terms. When the runtime encounters an `OPX` term with a `W32` subterm, `reduceOpxW32` is invoked to perform the necessary reduction, ensuring that operations involving 32-bit words are executed accurately and efficiently. This function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) during the reduction process, playing a key role in maintaining performance and correctness in a parallel execution environment."}
{"name": "reduceOpyCtr", "explanation": "The `reduceOpyCtr` function is a key part of the HVM3 runtime's reduction engine, specifically handling the interaction between `OPY` (operation) and `CTR` (constructor) terms in the Interaction Combinator model. When an `OPY` term is encountered during reduction and its interaction partner is a `CTR` term, `reduceOpyCtr` applies the appropriate reduction rule to ensure correct computation. This function is implemented in the C backend (`hvm.c`) and accessed via FFI in the Haskell frontend (`hvm.hs`). By managing the reduction of `OPY` and `CTR` interactions, `reduceOpyCtr` enables efficient parallel computation within the runtime."}
{"name": "reduceOpyEra", "explanation": "The `reduceOpyEra` function is a key component of the HVM3 runtime's reduction engine, specifically managing interactions between `OPY` (operation) and `ERA` (erasure) terms in the Interaction Combinator model. When an `OPY` term encounters an `ERA` term, `reduceOpyEra` performs the necessary reduction, simplifying the term structure or eliminating redundant terms to optimize computation and reduce memory overhead. Implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), this function ensures efficient and correct parallel evaluation within the HVM3 runtime."}
{"name": "reduceOpyLam", "explanation": "The `reduceOpyLam` function is a critical component in the HVM3 runtime, specifically designed to handle the reduction of an `OPY` term interacting with a `LAM` term. It implements the reduction rules of the Interaction Combinator model, enabling parallel evaluation by transforming terms according to predefined interaction patterns. In the C implementation (`hvm.c`), `reduce_opy_lam` performs operations such as substituting the lambda's body with the operand or simplifying the term structure to facilitate further evaluation. In the Haskell code (`hvm.hs`), `reduceOpyLam` is invoked by `reduceAt` when an `OPY-LAM` interaction is detected, ensuring modular and efficient reduction logic. This function is essential for the runtime's ability to process and evaluate complex, parallel computations effectively."}
{"name": "reduceOpySup", "explanation": "The `reduceOpySup` function handles the reduction of an `OPY` operation applied to a `SUP` term within the Interaction Combinator model. This occurs during parallel computation, where the function distributes the `OPY` operation across the components of the `SUP` term to ensure proper parallel evaluation. Implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), `reduceOpySup` enforces the reduction rule specific to this interaction, maintaining computational integrity and optimizing performance for parallel hardware."}
{"name": "reduceOpyW32", "explanation": "The `reduceOpyW32` function is a key component of the HVM3 runtime system, specifically designed to handle the reduction of terms involving the `OPY` operation when the operand is a `W32` (32-bit word) term. It ensures that the reduction process adheres to the rules of the Interaction Combinator model, which underpins the system's parallel execution capabilities. When the runtime encounters an `OPY` operation, it reduces the operand and dispatches to `reduceOpyW32` if the operand is a `W32` term. This function applies the necessary reduction rules, enabling efficient and correct evaluation of `OPY` operations with `W32` terms, and is integrated into both the Haskell frontend and C backend of the runtime system."}
{"name": "reduceRefAt", "explanation": "The `reduceRefAt` function is a core component of the HVM3 runtime, specializing in the reduction of `REF` terms, which represent references to other terms in the computational graph. It retrieves the referenced term from memory, extracts its metadata (such as label and location), and determines the appropriate reduction strategy based on the function ID (`fid`) and arity (`ari`). Depending on the function ID, it dispatches to specific reducers like `reduceRefAt_DupF` for dynamic duplication, `reduceRefAt_SupF` for superposition, `reduceRefAt_LogF` for logging, or `reduceRefAt_FreshF` for generating fresh duplication labels. By efficiently managing `REF` term reductions, `reduceRefAt` enables parallel evaluation and dynamic term manipulation, enhancing the runtime's performance and flexibility."}
{"name": "reduceRefAt_DupF", "explanation": "The `reduceRefAt_DupF` function is a specialized component of the HVM3 runtime, designed to handle the reduction of terms involving dynamic duplication (`_DUP_F_`). It ensures the correct execution of duplication operations, which are essential for parallel evaluation in the Interaction Combinator model. When a term with the `_DUP_F_` function ID is encountered, `reduceRefAt_DupF` retrieves relevant data from the `Book` and the term's location, allocates new nodes in the computational graph, and applies the necessary reduction rules. By managing dynamic duplication efficiently, this function supports the runtime's ability to perform parallel computations effectively, ensuring both correctness and performance in complex, parallelized workloads."}
{"name": "reduceRefAt_FreshF", "explanation": "The `reduceRefAt_FreshF` function is a core component of the HVM3 runtime, responsible for reducing terms tagged with the `FRESH_F` label. These terms represent requests for fresh duplication labels, which are essential for the `DUP` operation in the Interaction Combinator model. The function retrieves necessary information from its parameters (`book`, `host`, `loc`, and `ari`) to determine the context and structure of the term being reduced. It then generates a unique duplication label, ensuring proper identification and preventing conflicts during parallel execution. This process supports the efficient duplication and parallel evaluation of terms, maintaining the integrity of the computational graph. In essence, `reduceRefAt_FreshF` facilitates the dynamic generation of fresh labels, enabling the runtime to handle complex computations effectively."}
{"name": "reduceRefAt_LogF", "explanation": "The `reduceRefAt_LogF` function processes terms tagged with `LOG_F`, which denote logging operations in the HVM3 runtime. It takes a `book` (containing function definitions), a `host` (memory location of the term), a `loc` (subterm location to log), and `ari` (additional metadata). The function extracts the term from memory, logs it for debugging or diagnostics, and returns a result (e.g., `0`) to signify completion. This function is essential for monitoring program execution, enabling developers to inspect computational states and identify issues or optimizations."}
{"name": "reduceRefAt_SupF", "explanation": "The `reduceRefAt_SupF` function is a specialized handler within the `reduceRefAt` function, designed to process terms with the `SUP_F` function ID. It plays a critical role in the HVM3 runtime by managing the reduction of superposed terms, which are essential for parallel computation. The function takes parameters such as `book` (containing function definitions), `host` (the term's location), `loc` (the superposed term's location), and `ari` (the term's arity). By correctly reducing superposed terms, `reduceRefAt_SupF` enables the runtime to explore multiple computational paths simultaneously, ensuring efficient and accurate parallel evaluation. This functionality is key to the runtime's ability to handle complex, parallel computations effectively."}
{"name": "reduceRefSup", "explanation": "The `reduceRefSup` function is a critical component in the Interaction Combinator model, designed to handle the reduction of reference terms (`ref`) in the presence of superposition. It takes a reference term and an index (`idx`) as inputs, incrementing an iteration counter (`inc_itr()`) to track reductions. The function extracts the location (`ref_loc`) and label (`ref_lab`) from the reference term, decoding the label to obtain the function ID (`fun_id`) and arity (`arity`). These values are used to validate the index and ensure it falls within the bounds of the arity. If the index is invalid, the function logs an error and terminates. Otherwise, it applies reduction rules to manage superposition, creating new terms that represent parallel evaluation paths. This ensures the computational graph remains consistent and supports efficient parallel execution. By correctly reducing reference terms, `reduceRefSup` enables the runtime to handle complex, parallel computations, leveraging hardware parallelism for high performance."}
{"name": "reduce_app_ctr", "explanation": "The `reduce_app_ctr` function in the HVM3 codebase handles the reduction of application terms (`APP`) where the function is a constructor (`CTR`). Constructors are used to build data structures, and applying a constructor to an argument typically results in a new term representing the constructed value. This function ensures that such applications are correctly reduced by performing the necessary steps, such as creating or modifying terms in memory. It is part of a family of reduction functions (`reduce_app_era`, `reduce_app_lam`, etc.) that specialize in handling specific types of function applications, enabling the reduction engine to efficiently evaluate terms in the Interaction Combinator model. `reduce_app_ctr` is critical for managing constructor applications, ensuring proper and efficient term evaluation."}
{"name": "reduce_app_era", "explanation": "The `reduce_app_era` function is a key part of the HVM3 runtime's reduction engine, designed to handle the case where an application term (`APP`) interacts with an erasure term (`ERA`). In the Interaction Combinator model, an erasure term represents a computation that can be safely discarded, as it does not affect the final result. When the runtime encounters this scenario, `reduce_app_era` simplifies the term graph by eliminating the erasure term, ensuring that unnecessary computations are avoided. This optimization is crucial for maintaining efficiency, particularly in a parallel computing environment where computational resources are limited. The function is implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), ensuring seamless integration and efficient execution of reduction rules. By removing redundant computations, `reduce_app_era` enhances the runtime's ability to handle complex, parallel workloads effectively."}
{"name": "reduce_app_lam", "explanation": "The `reduce_app_lam` function implements beta-reduction in lambda calculus by substituting the argument of an application into the body of a lambda term. It takes two arguments: `app`, representing the application term, and `lam`, representing the lambda term. The function substitutes the argument from `app` into the body of `lam` and returns the reduced term. This operation is fundamental to evaluating functional programs, as it directly handles the application of functions to their arguments. In the HVM3 runtime, `reduce_app_lam` is part of a suite of reduction functions optimized for performance, ensuring efficient term evaluation in a parallel execution environment. Its low-level implementation in C is critical for achieving high performance on parallel hardware."}
{"name": "reduce_app_sup", "explanation": "The `reduce_app_sup` function in the HVM3 codebase handles the reduction of an application (`APP`) term applied to a superposition (`SUP`) term. A superposition represents a parallel combination of two terms, and an application represents a function application. The function distributes the application across the components of the superposition, enabling parallel evaluation. It decomposes the superposition into its constituent parts, applies the function to each part separately, and combines the results into a new superposition term. This process is essential for leveraging the parallelism of the Interaction Combinator model, ensuring efficient and correct parallel execution on HVM3's hardware."}
{"name": "reduce_app_w32", "explanation": "The `reduce_app_w32` function is a key component of the HVM3 runtime, specifically designed to handle the reduction of terms when a 32-bit word (`W32`) is applied to another term. It operates within the Interaction Combinator model, where terms are represented as nodes in a computational graph, and reduction rules govern their transformations. This function focuses on the case where an application term (`APP`) interacts with a `W32` term, ensuring proper execution within the runtime's memory model. As part of the low-level C backend, `reduce_app_w32` optimizes memory management and supports parallel execution, playing a critical role in numerical computations and bit-level operations. Its efficient implementation ensures the runtime's ability to process diverse term types and execute complex, parallel computations accurately and at high performance."}
{"name": "reduce_at", "explanation": "The `reduce_at` function is a core component of the HVM3 runtime, responsible for reducing terms to their normal forms by applying specific reduction rules based on the term's type. It operates recursively, processing terms by examining their tags and labels, and then performing the appropriate reduction operations. For instance, when encountering an `APP` term, it reduces both the function and its argument before applying the function. Similarly, for `MAT` terms, it reduces the value being matched and the corresponding case branches. The function also handles special cases like `DUP` and `SUP`, which are crucial for managing parallel computations. Additionally, `reduce_at` interacts with the memory system, using functions like `got` and `set` to read and write terms at specific memory locations, ensuring efficient term manipulation during reduction. This makes `reduce_at` essential for executing parallel and functional programs efficiently."}
{"name": "reduce_dup_ctr", "explanation": "The `reduce_dup_ctr` function is a critical component of the HVM3 runtime, specifically designed to handle interactions between duplication (`DUP`) and constructor (`CTR`) terms. In the Interaction Combinator model, `DUP` terms create multiple copies of a term, while `CTR` terms represent structured data or function applications. When a `DUP` encounters a `CTR`, `reduce_dup_ctr` ensures the correct propagation of the duplication by decomposing the constructor term and distributing its parts across the duplicated terms. This process maintains the integrity of the computational graph and supports efficient parallel evaluation. As part of the broader reduction rules in HVM3, `reduce_dup_ctr` enables the runtime to handle complex expressions and interactions, ensuring accurate and efficient computation."}
{"name": "reduce_dup_era", "explanation": "The `reduce_dup_era` function in the HVM3 codebase simplifies the interaction between `DUP` (duplication) and `ERA` (erasure) terms during graph reduction. When a `DUP` term encounters an `ERA` term, `reduce_dup_era` replaces both with a single `ERA` term, effectively erasing the duplicated structure. This optimization reduces unnecessary computations and ensures the graph remains compact, which is critical for maintaining the efficiency and correctness of parallel evaluation. Implemented in both Haskell (`hvm.hs`) and C (`hvm.c`), the function handles low-level term manipulation and memory management, contributing significantly to the performance of the HVM3 runtime."}
{"name": "reduce_dup_lam", "explanation": "The `reduce_dup_lam` function handles the interaction between a duplication (`DUP`) term and a lambda (`LAM`) term in the Interaction Combinator model. When a `DUP` term encounters a `LAM` term, this function ensures the duplication is correctly propagated through the lambda by creating new lambda terms for each duplicated copy. Specifically, it generates new lambda terms (`\u03bbx0(f0)` and `\u03bbx1(f1)`) and updates the term structure to maintain consistency in the computational graph. This process is essential for preserving the correctness of the reduction process, enabling efficient parallel evaluation by properly managing duplications within lambda contexts."}
{"name": "reduce_dup_ref", "explanation": "The `reduce_dup_ref` function handles the reduction of a term where a duplication (`DUP`) interacts with a reference (`REF`). In the HVM3 runtime, duplications create multiple copies of a term, while references point to specific terms in memory. This function ensures that the duplication is correctly applied to the referenced term, generating the necessary copies and updating memory locations efficiently. It is implemented in the C backend (`hvm.c`) and invoked via the Haskell frontend (`hvm.hs`) using FFI, enabling efficient low-level term manipulation. `reduce_dup_ref` is critical for supporting the parallel execution model of HVM3 by managing duplications and references in the Interaction Combinator framework."}
{"name": "reduce_dup_sup", "explanation": "The `reduce_dup_sup` function is a critical component of the HVM3 runtime, responsible for handling the interaction between `DUP` and `SUP` terms during parallel evaluation. It implements the DUP-SUP reduction rule, which ensures proper duplication and superposition of terms in two scenarios: when the labels of the `DUP` and `SUP` terms match, it directly assigns the `SUP` components to the `DUP` term; when the labels differ, it creates new `SUP` terms for the `DUP` components and correctly distributes the original `SUP` term's components. This mechanism enables efficient parallel computation by managing term duplication and superposition, ensuring optimal performance and correctness in the HVM3 runtime."}
{"name": "reduce_dup_w32", "explanation": "The `reduce_dup_w32` function is a specialized operation in the HVM3 runtime designed to handle the duplication of 32-bit word terms (`W32` or `CHR`). In the Interaction Combinator model, duplication is a core operation that enables terms to be shared across multiple contexts, facilitating parallel evaluation. When a 32-bit word term is duplicated, `reduce_dup_w32` ensures the value is correctly copied to both branches of the duplication, preserving its integrity and enabling subsequent operations to proceed without errors. This function is critical for maintaining the correctness of the computational graph, particularly in parallel execution environments where terms may be evaluated concurrently. Integrated into the reduction engine, `reduce_dup_w32` is invoked based on the term's tag, ensuring efficient and accurate handling of 32-bit word duplications."}
{"name": "reduce_let", "explanation": "The `reduce_let` function is a core component of the HVM3 runtime system, responsible for reducing `LET` terms that bind values to variables within the computational graph. It ensures that bound values are correctly propagated and evaluated, supporting both lazy and strict evaluation modes. In lazy mode, it retrieves values from memory using `got`, while in strict mode, it reduces values to their normal form using `reduceAt` before applying the reduction. Integrated with the runtime's memory management and parallel execution systems, `reduce_let` plays a critical role in maintaining the correctness and efficiency of the runtime, enabling seamless handling of variable bindings and supporting the Interaction Combinator model for high-performance computation."}
{"name": "reduce_mat_ctr", "explanation": "The `reduce_mat_ctr` function is a specialized reduction rule in the HVM3 runtime that handles pattern matching (`MAT`) operations when the term being matched is a constructor (`CTR`). It ensures the correct deconstruction of constructor terms, which represent data structures or specific values, by applying the appropriate reduction rule. This function simplifies the term graph, enabling further reductions or transformations as needed. Implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), `reduce_mat_ctr` plays a critical role in the efficient and accurate execution of pattern matching, contributing to the overall performance of the parallel evaluation process in HVM3."}
{"name": "reduce_mat_era", "explanation": "The `reduce_mat_era` function in the HVM3 codebase handles the reduction of a pattern matching (`MAT`) term when it interacts with an erasure (`ERA`) term. This function simplifies the computation by removing the `ERA` term, as it does not contribute to the final result, thereby optimizing the runtime performance. Implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), `reduce_mat_era` ensures correct interaction between `MAT` and `ERA` terms according to the Interaction Combinator model. By eliminating unnecessary terms, it reduces computational complexity and enhances the efficiency of the HVM3 runtime."}
{"name": "reduce_mat_lam", "explanation": "The `reduce_mat_lam` function is a key part of the HVM3 runtime's reduction engine, specifically handling the interaction between a pattern matching term (`MAT`) and a lambda term (`LAM`). This interaction follows the MAT-LAM reduction rule, which simplifies the computation by reducing the combination of these terms, often resulting in a `\u22a5` (bottom) term representing an undefined or non-computable value. The function is invoked during the reduction process when a `MAT` term is matched against a `LAM` term, ensuring terms are evaluated to their normal form. Implemented in C for performance, `reduce_mat_lam` is called via a foreign function interface (FFI) in the Haskell frontend, enabling efficient and parallel execution within the Interaction Combinator model."}
{"name": "reduce_mat_sup", "explanation": "The `reduce_mat_sup` function is a key component in the HVM3 runtime, designed to handle the parallel evaluation of pattern matching (`MAT`) operations on superposed (`SUP`) terms. When a `MAT` operation encounters a `SUP` term, `reduce_mat_sup` decomposes the superposition into its individual components and applies the pattern matching operation to each component in parallel. This enables efficient handling of scenarios where multiple possible values or states need to be matched simultaneously, a common requirement in parallel functional programming. By distributing the `MAT` operation across the superposed terms, `reduce_mat_sup` ensures both correctness and performance in the runtime's reduction process. It is one of several reduction rules in HVM3 that manage interactions between term types, contributing to the runtime's ability to execute highly parallel computations effectively on modern hardware."}
{"name": "reduce_mat_w32", "explanation": "The `reduce_mat_w32` function is a specialized reduction handler for pattern matching operations involving 32-bit words (`W32`). When a `MAT` term is evaluated and the matched term is of type `W32`, this function is called to determine the correct branch to execute based on the value of the `W32` term. It ensures the `MAT` term is reduced to its normal form efficiently, adhering to the Interaction Combinator model's principles for parallel evaluation. Implemented in `hvm.c`, it plays a critical role in maintaining the performance and correctness of the HVM3 runtime system by handling `W32`-specific reduction rules."}
{"name": "reduce_opx_ctr", "explanation": "The `reduce_opx_ctr` function is a key component of the HVM3 runtime's reduction engine, specifically designed to handle terms involving operation extensions (`OPX`) and constructors (`CTR`). It executes the necessary computational steps to reduce these terms to their normal form, ensuring correct and efficient interaction between `OPX` and `CTR`. Implemented in the low-level C backend for performance, `reduce_opx_ctr` is imported into the Haskell frontend via FFI, enabling seamless integration of high-level term manipulation with optimized low-level computation. This function is essential for the runtime's ability to process complex, parallel computations effectively."}
{"name": "reduce_opx_era", "explanation": "The `reduce_opx_era` function simplifies an `OPX` term when it interacts with an `ERA` term, which represents an erasure or deletion operation in the Interaction Combinator model. This function applies the appropriate reduction rule to streamline the computational graph by removing or simplifying terms. In the Haskell frontend (`hvm.hs`), it is invoked within the `OPX` reduction logic when an `ERA` term is detected, ensuring correct rule application. In the C backend (`hvm.c`), it directly manipulates memory to reduce the `OPX` term in the presence of an `ERA` term, optimizing execution. `reduce_opx_era` is essential for efficiently handling specific interactions in the HVM3 runtime, enabling effective evaluation of parallel computations."}
{"name": "reduce_opx_lam", "explanation": "The `reduce_opx_lam` function is a key part of the HVM3 runtime's reduction engine, specifically handling the interaction between `OPX` (operation extension) and `LAM` (lambda abstraction) terms. When an `OPX` term, which extends runtime functionality, encounters a `LAM` term, representing a lambda abstraction, `reduce_opx_lam` simplifies the interaction by reducing the terms. This reduction is crucial for maintaining computational efficiency and correctness within the runtime. As part of a broader set of reduction rules, `reduce_opx_lam` ensures that the runtime can effectively evaluate and process complex, parallel computations, leveraging the Interaction Combinator model for high performance."}
{"name": "reduce_opx_sup", "explanation": "The `reduce_opx_sup` function is a reduction rule in the HVM3 codebase that handles the interaction between `OPX` and `SUP` terms. It decomposes the `SUP` term into its constituent parts and applies the `OPX` operation to each part individually, enabling parallel evaluation. This process ensures that the resulting term correctly represents the combination of `OPX` and `SUP` while maintaining the integrity of the computational graph. By efficiently managing the superposition of terms, `reduce_opx_sup` enhances the system's performance and scalability, particularly in scenarios involving complex, parallel computations."}
{"name": "reduce_opx_w32", "explanation": "The `reduce_opx_w32` function is a specialized reduction handler in the HVM3 runtime, designed to process terms tagged with `OPX` and `W32`. It takes two arguments: `opx`, representing the operation to be performed, and `w32`, the 32-bit word on which the operation is applied. The function interprets the operation encoded in `opx` and executes it on `w32`, returning the resulting term. This typically involves arithmetic or bitwise operations, depending on the context. As part of a broader family of reduction functions, `reduce_opx_w32` ensures that terms are reduced to their normal form, adhering to the Interaction Combinator model and enabling efficient program execution in the HVM3 runtime."}
{"name": "reduce_opy_ctr", "explanation": "The `reduce_opy_ctr` function is a specialized reduction handler in the HVM3 runtime, designed to manage interactions between an `OPY` operation and a constructor (`CTR`) term within the Interaction Combinator model. This model facilitates parallel evaluation of terms through a graph-based computational approach. When an `OPY` operation encounters a `CTR` term, `reduce_opy_ctr` applies the specific reduction rules defined by the Interaction Combinator model, transforming the terms into their resulting normal form. This function is critical for ensuring the correct and efficient execution of programs in the HVM3 runtime, as it enforces the reduction logic required for term interactions."}
{"name": "reduce_opy_era", "explanation": "The `reduce_opy_era` function in the HVM3 runtime handles the interaction between an `OPY` term and an `ERA` term during the reduction process. An `OPY` term represents a specific operation or transformation, while an `ERA` term is used to erase or simplify parts of the computation graph. When these terms interact, `reduce_opy_era` ensures that the `ERA` term cancels out or simplifies the `OPY` term, optimizing the computation. This function is implemented in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`) when the runtime encounters this specific term pairing. By managing this interaction, `reduce_opy_era` contributes to the efficiency and correctness of the parallel evaluation process in HVM3."}
{"name": "reduce_opy_lam", "explanation": "The `reduce_opy_lam` function is a key component of the HVM3 runtime, specifically designed to handle the reduction of terms when an `OPY` operation interacts with a `LAM` (lambda) term. In the Interaction Combinator model, `OPY` represents a specific interaction rule that must be applied when certain term types interact. When the term being processed is a lambda (`LAM`), `reduce_opy_lam` ensures the correct application of the reduction rule, preserving the integrity of the computational graph. The function takes two arguments: `opy` (the `OPY` term) and `era` (the `LAM` term), and applies the reduction rule as defined in the C implementation (`hvm.c`). This rule is part of the broader reduction engine that ensures all terms are evaluated to their normal form, enabling efficient execution of programs on massively parallel hardware. By managing this specific interaction, `reduce_opy_lam` plays a crucial role in maintaining the performance and correctness of the HVM3 runtime."}
{"name": "reduce_opy_sup", "explanation": "The `reduce_opy_sup` function, implemented in the C backend of the HVM3 codebase and accessed via FFI in Haskell, applies the `OPY` operation to a `SUP` term, which represents a superposition of two terms. It takes `opy` (the operation) and `sup` (the superposition term) as inputs, constructing a new term that represents the parallel application of `OPY` to the components of `SUP`. This reduction rule is essential in the Interaction Combinator model, enabling correct and efficient parallel evaluation of terms on massively parallel hardware. The function is invoked during runtime when an `OPY` operation is applied to a `SUP` term, producing a result that can be further reduced or evaluated. As part of a broader family of reduction functions, `reduce_opy_sup` ensures the HVM3 runtime's correctness and performance, particularly in parallel computation scenarios."}
{"name": "reduce_opy_w32", "explanation": "The `reduce_opy_w32` function is responsible for reducing an `OPY` term when it interacts with a `W32` term in the HVM3 runtime. The `OPY` term represents an operation to be applied, while the `W32` term is a 32-bit word. This function performs the necessary computation to evaluate the interaction between these terms, ensuring correct and efficient execution. It is implemented in the C backend for performance optimization and integrated into the Haskell frontend to maintain high-level logic. This design leverages the Interaction Combinator model for parallel execution, combining Haskell's expressiveness with C's performance to handle complex computations effectively."}
{"name": "reduce_ref", "explanation": "The `reduce_ref` function is a critical component of the HVM3 runtime, responsible for reducing reference terms (`REF`). When a term is identified as a reference, `reduce_ref` resolves it by fetching the referenced term from memory using the `got` function. It then inspects the term's type and applies the appropriate reduction rules, which may involve recursive reductions for complex expressions or nested references. This function is integral to the parallel evaluation of terms, ensuring efficient and correct reduction in the HVM3 system. It works alongside other reduction functions like `reduce_ref_sup` and `reduceAt`, collectively enabling high-performance computation on massively parallel hardware."}
{"name": "reduce_ref_sup", "explanation": "The `reduce_ref_sup` function is a critical component for handling superposition terms within reference terms in a parallel computation model. It takes two inputs: `ref`, the reference term, and `idx`, the index of the argument within the reference term that is a superposition (`SUP`). The function increments an iteration counter to track reductions, extracts the location and label from the reference term, and validates the index against the arity to ensure correctness. It then decomposes the superposition term and applies the reference function to each component, enabling parallel evaluation of multiple computation branches. This approach optimizes performance on parallel hardware while maintaining the integrity of the evaluation process."}
{"name": "runtime_c", "explanation": "The `runtime_c` symbol acts as a critical link between the Haskell frontend and the C backend in the HVM3 codebase. It embeds the contents of the `Runtime.c` file, which provides the low-level functions and data structures necessary for executing HVM3 programs. When the `cliRun` function is called, it processes the input file, parses it into a `Book` structure, and compiles the functions into C code. The `runtime_c` string is embedded into the generated C file, ensuring that the runtime support is always available during execution. This design allows the Haskell frontend to dynamically generate C code while keeping high-level term manipulation separate from low-level runtime operations. By facilitating this integration, `runtime_c` enables efficient and parallel execution of HVM3 programs on modern hardware, making it a cornerstone of the compilation and execution pipeline."}
{"name": "set", "explanation": "The `set` function writes a `Term` to a specified memory location (`Loc`), playing a crucial role in the runtime's memory model based on Interaction Combinators. It is primarily used to update the state of terms during term reduction, memory management, and compilation. For example, during `DUP` term reduction, `set` ensures the computational graph is correctly updated by writing new terms to their respective locations. It also works with `allocNode` to initialize newly allocated memory and is essential in compiling high-level `Core` terms into low-level C code. Additionally, `set` supports parallel execution by managing term states across different execution paths, ensuring synchronization and consistency. Its use in reduction rules like `reduce_app_sup` and `reduce_dup_lam`, as well as in compilation functions like `compileFullCore`, underscores its importance in maintaining the runtime's efficiency and correctness."}
{"name": "setRefIds", "explanation": "The `setRefIds` function annotates `Ref` constructors in `Core` terms with their corresponding function IDs during the creation of a `Book` data structure. It recursively traverses `Core` terms (e.g., `Var`, `Let`, `Lam`, `App`) and, upon encountering a `Ref` constructor, assigns the appropriate ID by looking up the function name in the provided `fids` map. This ensures that all function references are correctly labeled, enabling efficient runtime lookup and execution. `setRefIds` is essential for maintaining the integrity and performance of the HVM3 system by linking function names to their IDs in the compiled code."}
{"name": "set_itr", "explanation": "The `set_itr` function is responsible for updating the iteration counter (`itr`) in the HVM3 runtime, which is crucial for tracking the progress of parallel computations. It ensures synchronization and accurate state management during the evaluation of multiple terms. In the Haskell frontend, `set_itr` is used when generating heap representations, while in the C backend, it directly modifies the iteration counter. This function plays a key role in maintaining computational integrity and enabling efficient parallel execution in the HVM3 system."}
{"name": "set_len", "explanation": "The `set_len` function is used to update the length of a memory block or data structure within the HVM3 runtime. This operation is critical for efficient memory management in a parallel execution environment, as it ensures the runtime can accurately track allocated and used memory space. By modifying the length property at a specific memory location (`Loc`), `set_len` enables dynamic resizing and allocation, working in tandem with other memory management functions like `allocNode` and `set`. This functionality is essential for maintaining the runtime's memory integrity and optimizing performance, particularly in systems leveraging the Interaction Combinator model for parallel computation."}
{"name": "showCore", "explanation": "The `showCore` function is a utility in the HVM3 codebase designed to convert `Core` terms\u2014high-level representations of the computational graph\u2014into a human-readable string format. It is primarily used for debugging and inspection purposes, enabling developers to visualize intermediate or final results of computations. By integrating with the `cliRun` function, `showCore` prints normalized or collapsed `Core` terms, depending on the run mode, aiding in verifying program correctness and simplifying the analysis of computational behavior."}
{"name": "showHex", "explanation": "The `showHex` function is a utility that converts numerical values into their hexadecimal string representation, ensuring a consistent and readable format. It is widely used across the codebase for tasks such as formatting memory addresses, labels, and other numerical data, particularly in debugging and logging contexts. By centralizing the conversion logic, `showHex` enhances code maintainability and ensures uniformity in hexadecimal output, such as zero-padding for consistent length."}
{"name": "showParseError", "explanation": "The `showParseError` function is responsible for formatting and displaying parsing errors in a user-friendly way. It takes three parameters: a `filename` (often empty), the `input` string being parsed, and a `ParseError` object. This function is crucial during development and debugging, as it helps developers identify and resolve parsing issues by providing clear error details. In the HVM3 codebase, `showParseError` is used within `doParseCore` and `doParseBook` to handle parsing failures gracefully, ensuring the program can continue running while offering meaningful feedback. Its role enhances the robustness and usability of the codebase by simplifying error diagnosis."}
{"name": "skip", "explanation": "The `skip` function is a utility in the HVM3 parser that ignores whitespace and comments in the input program. It operates as a `ParserM` monad, using `skipMany` to repeatedly skip spaces (via `parseSpace`) and single-line comments (via `parseComment`). By filtering out these non-essential elements, `skip` ensures the parser focuses on meaningful constructs like keywords and expressions, enhancing robustness and flexibility. It is widely used throughout the parsing process, making it a foundational tool for accurate and efficient program interpretation."}
{"name": "sqPop", "explanation": "The `sqPop` function is a key operation in the Simple Queue (`SQ`) data structure, designed to remove and return the first element from the queue while maintaining immutability. It operates by checking if the queue is empty (returning `Nothing` in such cases) or by reversing the pushing list if the popping list is empty, ensuring elements are processed in the correct order. When the popping list contains elements, it returns the first element and updates the queue by removing it. This function is essential for managing the queue in breadth-first search (`flattenBFS`), enabling efficient traversal and parallel computation handling in the HVM3 runtime."}
{"name": "sqPut", "explanation": "The `sqPut` function is a utility for appending an element to the back of a simple queue (`SQ`), which is represented by two lists: `xs` (front) and `ys` (back). It takes an element `x` and a queue `SQ xs ys`, then prepends `x` to the `ys` list using the cons operation (`x:ys`). This operation is efficient, requiring only constant time. In the context of the `flattenBFS` function, `sqPut` is used to enqueue elements during a breadth-first search (BFS) traversal of a `Collapse` monad, ensuring elements are processed in the correct order for parallel computations. Its simplicity and efficiency make it a key component for managing queues in the HVM3 codebase."}
{"name": "sub", "explanation": "The `sub` function is a core operation in the HVM3 runtime, responsible for dynamically updating the content of a memory location (`loc`) with a new term (`term`). It plays a critical role in the reduction process by facilitating term substitutions, which are essential for evaluating expressions and maintaining the computational graph's state. For instance, in `reduce_let`, `sub` substitutes a variable's value into a `let` expression's body, while in `reduce_app_lam`, it replaces a lambda abstraction's body with an applied argument. Additionally, `sub` supports complex operations like `reduce_dup_lam` and `reduce_dup_sup`, enabling efficient term duplication and superposition. By ensuring accurate and parallel term updates, `sub` underpins the runtime's ability to evaluate expressions dynamically and efficiently."}
{"name": "swap", "explanation": "The `swap` function is a core operation in the HVM3 runtime, enabling atomic term manipulation and memory management. It takes a memory location (`loc`) and a term (`term`) as arguments, swaps the term at the specified location with the provided term, and returns the original term. This atomic exchange is essential for maintaining consistency during parallel execution, as it allows for simultaneous retrieval and updating of terms. `swap` is often used in conjunction with functions like `set` and `got` to dynamically manage terms in the computational graph. For example, the `take` function leverages `swap` to retrieve a term and replace it with `VOID`, demonstrating its utility in both updating and clearing memory efficiently. Overall, `swap` plays a pivotal role in the HVM3 runtime's ability to handle term manipulation in a parallel and consistent manner."}
{"name": "tabDec", "explanation": "The `tabDec` function is a utility within the `Compile` monad that decrements the indentation level (`tabs`) in the compilation state by 1. It is used to adjust the formatting of emitted C code, ensuring proper indentation after nested blocks, such as function bodies, loops, or conditional statements. By reducing the indentation level, `tabDec` helps maintain readable and well-structured code, working in conjunction with `tabInc` to manage indentation throughout the compilation process."}
{"name": "tabInc", "explanation": "The `tabInc` function is responsible for increasing the indentation level in the generated C code by incrementing the `tabs` field within the `Compile` monad. This ensures that nested structures, such as function bodies or conditional blocks, are properly indented, enhancing code readability and maintainability. It is typically used in conjunction with `tabDec` to manage indentation levels dynamically during code generation."}
{"name": "tagT", "explanation": "The `tagT` function is a critical utility in the HVM3 runtime, responsible for interpreting raw hexadecimal tags to determine the type of a term. It acts as a bridge between low-level term representations and high-level runtime logic, enabling the system to apply appropriate reduction rules based on the term's type, such as `APP`, `MAT`, `OPX`, `DP0`, or `DP1`. This function is essential for the reduction engine, as seen in `reduceAt`, where it ensures correct handling of term types during evaluation. Additionally, `tagT` supports debugging and diagnostics by facilitating the conversion of tags and terms into human-readable formats in functions like `tagToString` and `termToString`. Its role in type-driven logic makes it indispensable for efficient and accurate term manipulation in the runtime."}
{"name": "tagToString", "explanation": "The `tagToString` function converts a `Tag` into its `String` representation, typically used for debugging or logging. The `Tag` is likely an enumeration representing term types in a computational graph, such as `ERA`, `REF`, `NUM`, `CON`, or `DUP`. By leveraging the `show` function, it transforms the `Tag` into a readable string. This functionality is particularly useful within the `termToString` function, where it aids in converting a `Term` into a string for inspection or debugging purposes. In the HVM3 codebase, `tagToString` helps developers visualize and understand the structure and types of terms in the runtime, facilitating development and maintenance."}
{"name": "take", "explanation": "The `take` function retrieves a term from a specified memory location (`loc`) within the runtime's memory model. This operation is fundamental for the reduction process, as it allows dynamic access to terms stored in memory. In the context of `reduce_dup_sup`, `take` is used to fetch terms from specific memory locations during the reduction of duplicated and superposed terms, ensuring accurate application of reduction rules. By enabling direct memory access, `take` supports efficient and parallel term evaluation, a key feature of the HVM3 runtime system."}
{"name": "termGetBit", "explanation": "The `termGetBit` function is a utility that extracts a specific bit from a `Term` object, a core data structure in the HVM3 runtime. This bit acts as a flag to influence runtime behavior during term reduction and evaluation. For instance, in `VAR`, `DP0`, and `DP1` terms, `termGetBit` checks if a subterm has a particular bit set, determining whether specific operations should proceed or if further reduction is needed. This function is critical for the runtime's decision-making, ensuring terms are processed accurately based on their internal state. Its implementation in both Haskell and C highlights its role in bridging high-level term manipulation with low-level runtime operations, making it a key component of the HVM3 architecture."}
{"name": "termLab", "explanation": "The `termLab` function extracts the label (`Lab`) from a given `Term`, which is a node in the computational graph. This label contains critical metadata, such as function IDs for `REF` terms, constructor IDs for `CTR` terms, and arity information, enabling operations like function lookup, pattern matching, and argument validation. It is utilized in reduction rules like `reduce_ref`, `reduce_dup_lam`, and `reduce_mat_ctr` to guide the execution strategy, as well as in debugging tools like `print_term` to provide insights into the computation's state. Essentially, `termLab` is a core utility that ensures accurate interpretation and manipulation of terms during parallel computation in the HVM3 runtime."}
{"name": "termLoc", "explanation": "The `termLoc` function, defined in the C backend (`hvm.c`) and imported into the Haskell frontend (`hvm.hs`) via FFI, retrieves the `Loc` field from a `Term` data structure, representing the memory address of the term. This function is crucial for operations like term reduction, where the runtime accesses and manipulates terms in memory. By providing the memory addresses of subterms, `termLoc` enables efficient application of reduction rules. It also supports debugging and diagnostic tools, such as `print_term`, by offering insights into the computation's state. In essence, `termLoc` is vital for the HVM3 runtime's parallel execution model, ensuring efficient memory access and term manipulation."}
{"name": "termNew", "explanation": "The `termNew` function is a utility for creating new terms in the HVM3 runtime system. It is used across different components, such as the Haskell frontend for generating C code representations of `Core` terms and the C backend for runtime term allocation and initialization. During reduction rules, `termNew` constructs new nodes (e.g., `REF`, `SUP`, `LAM`) as part of the evaluation process, enabling efficient parallel computation. Its role is central to term manipulation and execution in HVM3."}
{"name": "termRemBit", "explanation": "The `termRemBit` function is a low-level operation that removes a specific bit from a `Term`, altering its state or behavior. This bit often serves as a flag or marker within the term, and its removal is critical for maintaining correct term processing. The function is utilized in reduction operations (e.g., `reduce_dup_era`, `reduce_dup_lam`) to clear bits after term evaluation, ensuring proper state transitions. It also supports memory management by modifying terms before storage or after retrieval, preserving memory integrity in parallel execution. Additionally, `termRemBit` manages term states during operations involving variables (`VAR`) or duplication (`DP0`, `DP1`), ensuring accurate interpretation and processing. Its role is essential for the efficient execution of parallel computations in the HVM3 runtime."}
{"name": "termSetBit", "explanation": "The `termSetBit` function is a critical utility in the HVM3 runtime, responsible for setting a specific bit within a `Term` object's internal representation. This bit typically serves as a flag to indicate the term's state, such as whether it has been evaluated, normalized, or reduced. By marking terms with this bit, `termSetBit` ensures that subsequent operations, like those in `normalAtWith`, can efficiently determine whether further processing is required or if the term is already in its desired state. This mechanism prevents redundant evaluations, optimizing the runtime's performance. The function is closely tied to memory management, often working alongside `set` to update terms in memory, making it essential for the efficient execution of the Interaction Combinator model and enabling effective parallel computation handling."}
{"name": "termTag", "explanation": "The `termTag` function, defined in the C backend (`hvm.c`) and imported into the Haskell frontend (`hvm.hs`) via FFI, extracts the tag from a `Term`, a numeric identifier representing the term's type. This tag is crucial for guiding the reduction process, as it determines which reduction rule to apply in functions like `reduceAt`. Additionally, `termTag` is used in `compileFast` to generate conditional statements in the compiled C code, ensuring type-specific operations are performed. It also aids in debugging by allowing developers to inspect term states through tag inspection. Overall, `termTag` is a key utility for efficient term management and correct reduction rule application in the runtime system."}
{"name": "termToString", "explanation": "The `termToString` function is a utility that converts a `Term`, representing a node in the computational graph, into a human-readable string. This is primarily used for debugging purposes, enabling developers to inspect and understand the structure of terms during runtime. For instance, when errors occur in operations like dynamic DUP, `termToString` helps by providing a string representation of problematic labels or terms. It is also utilized in functions like `heapToString` to render the entire heap's state into a readable format, offering insights into the runtime's memory and term organization. By making internal term structures accessible, `termToString` significantly aids in diagnosing and resolving issues within the system."}
{"name": "term_get_bit", "explanation": "The `term_get_bit` function is a utility in the HVM3 runtime that retrieves the value of a specific bit within a `Term`. This bit often serves as a flag to indicate the state or properties of the term, such as whether it has been evaluated or requires further reduction. The function is integral to the reduction engine, particularly when handling `VAR`, `DP0`, and `DP1` terms, where it helps determine the appropriate evaluation steps. For instance, in `VAR` terms, it checks if a subterm has been fully evaluated (bit is 0) or needs reduction (bit is 1). In `DP0` and `DP1` cases, it inspects subterm states to decide whether to proceed with reduction or manage parallel execution. By enabling precise bit-level inspection, `term_get_bit` supports efficient term processing in a massively parallel environment, aligning with the Interaction Combinator model's principles."}
{"name": "term_lab", "explanation": "The `term_lab` function is a utility that retrieves the label of a `Term` in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`). In the Haskell code, it is used during operations like reduction, compilation, and pattern matching to determine the type of term being processed. For example, in `reduceAt`, it identifies the term's label to guide the reduction process, while in `compileFast`, it checks if a term is a `SUP` (superposition) to handle it appropriately. In the C backend, `term_lab` directly accesses the label field of a `Term` and is used in reduction rules like `reduce_ref_sup`, `reduce_dup_lam`, and `reduce_mat_ctr` to determine the correct reduction strategy. For instance, in `reduce_ref_sup`, it extracts the function ID and arity from a `REF` term's label to perform the reduction. Overall, `term_lab` is essential for accessing term labels, enabling the HVM3 runtime to execute programs correctly and efficiently across both high-level and low-level implementations."}
{"name": "term_loc", "explanation": "The `term_loc` function is a critical utility in the HVM3 runtime, responsible for retrieving the memory location of a `Term` within the computational graph. This location serves as a pointer to the term's storage in memory, enabling efficient access and manipulation during operations like reduction, allocation, and subterm traversal. For instance, in `reduceAt`, `term_loc` identifies the term's location for reduction, while in `compileFast`, it aids in generating C code for term access. It is also utilized in functions like `reduce_ref_sup` and `reduce_dup_lam` to locate terms involved in reduction rules. By providing precise memory access, `term_loc` ensures the runtime can navigate and process the computational graph effectively."}
{"name": "term_new", "explanation": "The `term_new` function is a fundamental utility in the HVM3 codebase responsible for dynamically creating new `Term` instances. It is extensively used during compilation, reduction, and memory management processes. For example, in the C backend (`hvm.c`), it constructs terms for constructs like `Lam`, `App`, `Sup`, and `Dup` during reduction rules such as `reduce_ref_sup` and `reduce_dup_lam`. Additionally, it plays a role in debugging and diagnostic output, as seen in the `print_term` function, where it formats and displays term information. By enabling efficient term creation and manipulation, `term_new` supports the HVM3 runtime's execution on massively parallel hardware."}
{"name": "term_rem_bit", "explanation": "The `term_rem_bit` function is a utility in the HVM3 runtime that clears a specific bit in a term's metadata, updating its state during reduction processes. This bit often represents a temporary flag or condition used in operations like duplication, substitution, or memory management. By clearing the bit, `term_rem_bit` ensures that terms are correctly prepared for subsequent computations, maintaining consistency in the Interaction Combinator model. It is frequently called in functions like `reduce_dup_era`, `reduce_dup_lam`, and memory-related operations to finalize term states after complex transformations."}
{"name": "term_set_bit", "explanation": "The `term_set_bit` function is a low-level operation in the HVM3 runtime that modifies a specific bit within the `Term` data structure, which represents nodes in the computational graph. This bit typically acts as a flag to indicate the evaluation status of a term, such as whether it has been fully reduced or normalized. By setting this bit, the runtime can efficiently track and manage term states, preventing redundant computations and ensuring correct parallel execution. It is often used after reducing a term to its weak head normal form (`whnf`) to mark the term as evaluated, enabling the runtime to skip further reductions when the term is accessed again. Implemented in the C backend and exposed via FFI, `term_set_bit` plays a crucial role in optimizing performance in the HVM3 runtime's parallel computation model."}
{"name": "term_tag", "explanation": "The `term_tag` function is a critical utility in the HVM3 runtime system, responsible for identifying the type of a `Term` through its associated tag, such as `ERA`, `REF`, `NUM`, `CON`, or `DUP`. This type information is essential for the runtime to apply the correct reduction rules and optimizations during evaluation. For instance, the `reduce` function relies on `term_tag` to determine the term's type and execute the appropriate reduction logic, while the `compileFastCore` function uses it to generate optimized C code tailored to the term's type. Additionally, `term_tag` aids in debugging and diagnostics, as seen in functions like `print_term`, which provide detailed insights into the computation's state. In essence, `term_tag` ensures the runtime can efficiently manage and process terms, enabling the correct and optimized execution of HVM3 programs."}
{"name": "u12v2New", "explanation": "The `u12v2New` function encodes two 12-bit values (`x` and `y`) into a single 64-bit unsigned integer, optimizing storage and retrieval of pairs of small integers in the HVM3 runtime. It is primarily used to compactly store metadata, such as function IDs with their arities or constructor IDs with their arities, within terms like constructors (`Ctr`), matchers (`Mat`), and references (`Ref`). Defined in the C backend (`hvm.c`) and invoked from the Haskell frontend (`hvm.hs`), this function plays a critical role in reducing memory overhead and enhancing runtime performance by efficiently encoding and managing term metadata during execution."}
{"name": "u12v2X", "explanation": "The `u12v2X` function is a utility designed to extract the first 12 bits from a 64-bit label (`Lab`), which is used to decode metadata such as constructor IDs (`cid`), function IDs (`fid`), and lengths (`len`) in various contexts. For instance:\n- In `CTR` blocks, it extracts the constructor ID (`cid`) from the term's label.\n- In `MAT` blocks, it retrieves the length (`len`) of the match pattern.\n- In `REF` blocks, it obtains the function ID (`fid`) for reference terms.\n\nThis function plays a critical role in the runtime's ability to interpret and process terms efficiently, particularly in the parallel execution model of HVM3. By consistently extracting and decoding metadata, `u12v2X` ensures that the system can accurately manipulate term labels, making it a foundational utility in the Interaction Combinator model."}
{"name": "u12v2Y", "explanation": "The `u12v2Y` function is a utility that extracts the arity (`ari`) from a term's label (`Lab`), which encodes metadata such as function IDs, constructor IDs, and arity. Arity represents the number of arguments a function or constructor expects, and this information is essential for term reduction and manipulation in the HVM3 runtime. By retrieving the arity, `u12v2Y` enables functions like `reduce_ref_sup`, `reduce_dup_ctr`, and `reduce_mat_ctr` to correctly handle term evaluation, duplication, and pattern matching. This ensures accurate and efficient parallel computation within the Interaction Combinator model."}
{"name": "u12v2_new", "explanation": "The `u12v2_new` function is a utility that combines two 64-bit values (`x` and `y`) into a single 64-bit label (`Lab`), used to encode metadata for terms in the HVM3 runtime system. It is employed to generate labels for various term types, such as `CTR` (constructor), `MAT` (pattern matching), and `REF` (reference), by encoding constructor IDs, arity, function IDs, or case counts. Defined in the C backend (`hvm.c`) and imported into the Haskell frontend (`hvm.hs`) via FFI, `u12v2_new` enables efficient label generation during compilation and runtime. Its compact representation optimizes memory usage and supports parallel execution in HVM3."}
{"name": "u12v2_x", "explanation": "The `u12v2_x` function is a utility in the HVM3 runtime that decodes metadata from a term's 64-bit unsigned integer (`u64`) label. It extracts specific portions of the label to retrieve information such as function IDs, constructor IDs, or lengths, depending on the term's type. For instance, it extracts the function ID (`fun_id`) in `reduce_ref`, the length (`mat_len`) in `reduce_mat_sup`, and the constructor number (`ctr_num`) in `reduce_mat_ctr`. This function is critical for interpreting term labels during reduction and evaluation, enabling operations like function application, pattern matching, and parallel execution by efficiently accessing encoded metadata."}
{"name": "u12v2_y", "explanation": "The `u12v2_y` function is a low-level utility in the HVM3 runtime that decodes the arity (number of arguments) from a term's label (`Lab`). Labels in HVM3 store metadata about terms, such as function IDs, constructor IDs, and arity. By extracting the arity, `u12v2_y` enables the reduction engine to correctly handle operations like function application, duplication, and pattern matching. For instance, it is used in `reduce_ref_sup` to determine the arity of a referenced function, in `reduce_dup_ctr` to handle constructor duplication, and in `reduce_mat_ctr` to apply pattern matching rules. This function is essential for ensuring the runtime can efficiently process terms based on their structure."}
{"name": "u32", "explanation": "In the HVM3 codebase, `u32` is a fundamental unsigned 32-bit integer type used to represent and manage key components of the computational graph. It is primarily employed for memory management, where it defines memory locations (`Loc`) and labels (`Lab`) for terms, enabling efficient allocation and access. Additionally, `u32` stores tags (`Tag`) that identify term types (e.g., `ERA`, `REF`, `NUM`, `CON`, `DUP`), allowing the runtime to apply appropriate reduction rules. During reduction operations, `u32` is used to handle indices, tags, and intermediate results, ensuring efficient parallel computation. In the compilation process, `u32` facilitates the generation of low-level C code, such as retrieving and manipulating term locations and tags. Overall, `u32` is essential for memory management, term representation, and parallel execution in HVM3."}
{"name": "u64", "explanation": "`u64` is a type alias for `uint64_t` in the HVM3 codebase, representing a 64-bit unsigned integer. It is widely used across the runtime for handling large numerical values, ensuring precision and avoiding overflow. Key applications include memory management (e.g., tracking memory addresses and iteration counts), parallel execution (e.g., managing indices and counters for parallel computations), and global state tracking (e.g., stack positions, heap sizes, and interaction counts). Its use is critical for the runtime's efficiency and scalability, particularly in the context of HVM3's massively parallel execution model."}
