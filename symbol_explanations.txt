# ATerm
The `ATerm` type is defined as `_Atomic(Term)`, where `Term` is a 64-bit unsigned integer representing a node in the computational graph. In the context of the HVM3 runtime, `ATerm` is used in the global heap (`HVM.heap`), which stores all the nodes of the computational graph. The heap is a shared resource accessed by multiple threads during parallel execution, so using `ATerm` ensures that updates to the heap are atomic and thread-safe. This is particularly important for operations like memory allocation (`allocNode`) and term manipulation (`set`, `got`), which must be synchronized across threads to maintain the integrity of the computational graph. By leveraging atomic operations, the HVM3 runtime can efficiently manage parallel computations without risking data corruption or inconsistent states.
# Bin
The `Bin` data type is defined as a recursive structure with two constructors: `O` and `I`. Each constructor takes another `Bin` as an argument, allowing for the construction of bit-strings of arbitrary length. For example, `O (I (O E))` represents the bit-string "010", where `E` is the empty bit-string. This structure is used in the `Collapse` monad to manage paths during parallel computations. Specifically, the `fork` function in the `bind` operation uses `Bin` to track and manipulate paths through the computation graph. The `putO` and `putI` functions are used to prepend `O` and `I` to existing bit-strings, respectively, which is essential for building and transforming paths as the computation progresses. This mechanism ensures that the system can efficiently handle multiple parallel execution paths and reduce them to a single result or a list of results.
# Book
The `Book` data structure is a core component of the HVM3 runtime, acting as a centralized store for function definitions and metadata. It contains several key mappings:
1. **`idToFunc'`**: Maps function IDs to their corresponding definitions, including whether the function is a copy and its argument list.
2. **`idToName'`**: Maps function IDs to their names, enabling reverse lookup from IDs to function names.
3. **`idToLabs'`**: Maps function IDs to sets of labels used in their bodies, which is essential for handling `DUP` and `SUP` operations efficiently.
4. **`nameToId'`**: Maps function names to their IDs, allowing quick lookup of function IDs by name.
5. **`ctrToAri`** and **`ctrToCid`**: Maps constructor names to their arity and IDs, respectively, which are used during pattern matching and term reduction.

The `Book` structure is created during the parsing phase (`doParseBook`) and is passed to various functions throughout the codebase, such as `compile`, `reduceAt`, and `collapseSups`. It ensures that the runtime has access to all necessary information for compiling, reducing, and executing terms. For example, during compilation, the `Book` is used to look up function definitions and labels, enabling the generation of optimized C code. During reduction, it provides the metadata needed to apply the correct reduction rules for terms like `DUP` and `SUP`.

In summary, the `Book` data structure is a critical component of the HVM3 runtime, enabling efficient management and lookup of function definitions and metadata, which are essential for the correct and optimized execution of parallel computations.
# Collapse
The `Collapse` monad is defined as a tree structure with three possible constructors: `CSup`, `CVal`, and `CEra`. The `CSup` constructor represents a superposition of two `Collapse` values, enabling parallel evaluation. The `CVal` constructor holds a single value, and `CEra` represents an empty or erased value. The `bind` function is the core operation of the `Collapse` monad, allowing for the chaining of computations by applying a function to the values within the `Collapse` structure. This function is essential for managing the flow of parallel computations, as it recursively processes the tree structure, applying the given function to each value and combining the results.

The `Collapse` monad is used in various parts of the codebase to handle parallel execution. For example, the `doCollapseAt` function uses the `Collapse` monad to reduce a term at a specific location in the computational graph, while `doCollapseFlatAt` flattens the resulting `Collapse` structure into a list of values. This is particularly useful in the context of the HVM3 runtime, where parallel evaluation is a fundamental aspect of the system's design. The `Collapse` monad also supports different flattening strategies (e.g., `flattenDFS`, `flattenBFS`, `flattenPQ`), allowing for flexible handling of parallel computations depending on the specific requirements of the task at hand.

Overall, the `Collapse` monad plays a crucial role in enabling efficient parallel execution within the HVM3 codebase, providing a structured way to manage and reduce multiple computational outcomes in a parallel environment.
# CompileState
The `CompileState` data type serves as the state container for the compilation process in the HVM3 codebase. It is used within the `Compile` monad, which is a state monad that encapsulates the compilation logic. The `compileWith` function initializes a `CompileState` with default values, indicating that this state is used to track and manage various aspects of the compilation process, such as counters, mappings, or intermediate results. By using a state monad, the codebase ensures that the compilation process can maintain and update its state in a functional and composable manner, enabling efficient and modular compilation of high-level `Core` terms into low-level C code. This approach aligns with the functional programming paradigm and supports the codebase's goal of efficient parallel execution.
# Core
The `Core` data type is the backbone of the HVM3 codebase, representing the abstract syntax tree (AST) of the functional programs being executed. It encapsulates various constructs such as variables (`Var`), function references (`Ref`), lambda abstractions (`Lam`), function applications (`App`), and more. Each variant of the `Core` type corresponds to a different construct in the functional language, allowing the runtime to handle a wide range of operations. For example, `Lam` represents a lambda abstraction, `App` represents a function application, and `Sup` represents a superposition of terms for parallel evaluation. The `Core` type is used throughout the compilation process, where high-level terms are translated into low-level C code, and during execution, where terms are reduced to their normal forms. The `Core` type also plays a crucial role in parsing and stringification, enabling the system to read and display terms in a human-readable format. Overall, `Core` is essential for the representation, manipulation, and execution of terms in the HVM3 system.
# DUP_f
The `DUP_f` function plays a crucial role in the HVM3 runtime by facilitating the creation of `DUP` nodes, which are essential for parallel computation. In the Interaction Combinator model, `DUP` nodes allow for the duplication of terms, enabling the runtime to distribute computations across multiple processing units. This is particularly important for achieving high performance on massively parallel hardware, as it allows the system to exploit parallelism at a fine-grained level.

When the `DUP_f` function is called, it takes a `Term` reference as input and returns a new `DUP` node with the specified label. This node is then used by the runtime to manage and process parallel computations. The function is registered in the `HVM.book` array, which serves as a lookup table for function implementations. This ensures that the runtime can quickly and efficiently access the `DUP_f` function when needed, minimizing overhead and maximizing performance.

Overall, the `DUP_f` function is a key component of the HVM3 runtime, enabling the system to handle complex, parallel computations efficiently. By creating `DUP` nodes, it allows the runtime to distribute and manage computations across multiple processing units, leveraging the full power of modern hardware to achieve high performance.
# FRESH_f
The `FRESH_f` function is intended to play a role in the runtime's term management or evaluation process, likely related to generating or handling fresh terms or references. In the context of the Interaction Combinator model, "fresh" terms often refer to newly created or unique terms that are introduced during the reduction process. These terms are essential for ensuring that computations proceed correctly, especially in parallel or concurrent scenarios where multiple reductions may occur simultaneously.

Given that `FRESH_f` is registered in the `HVM.book` array, it is likely invoked during the runtime's execution when a fresh term is needed. However, since the function is currently unimplemented (as indicated by the `TODO` message), its exact behavior and purpose remain undefined. Once implemented, `FRESH_f` would likely interact with the runtime's memory management system (e.g., `allocNode`, `set`, `got`) to allocate and initialize new terms, ensuring that they are correctly integrated into the computational graph.

In summary, `FRESH_f` is a placeholder function in the HVM3 runtime that is expected to handle the creation or management of fresh terms during the evaluation process. Its implementation will be crucial for supporting the runtime's parallel execution model and ensuring the correctness of term reductions.
# InjectState
The `InjectState` data type serves as the state container for the `InjectM` monad, which is used in the HVM codebase to manage state during term injection or transformation processes. The `InjectState` itself is a simple data structure, likely holding metadata or mappings necessary for these operations. The `emptyState` function initializes `InjectState` with an empty map and an empty list, indicating that the state is used to store and manage dynamic information during the injection process. This state management is crucial for maintaining consistency and correctness when transforming or injecting terms into the HVM runtime, ensuring that the necessary context and metadata are preserved throughout the computation.
# LOG_f
The `LOG_f` function is part of the HVM3 runtime's internal machinery, specifically within the C backend. Its purpose is likely to provide logging or debugging capabilities during the execution of the runtime. However, as of the current implementation, it is incomplete and only prints a "TODO" message, suggesting that its functionality has not yet been developed. The function is registered in the `HVM.book` array during the initialization phase (`hvm_init`), alongside other critical functions like `SUP_f` and `DUP_f`. This indicates that `LOG_f` is intended to play a role in the runtime's operation, possibly for tracking or debugging purposes, but its exact behavior and integration into the system remain to be defined.
# Lab
The `Lab` type is a fundamental part of the HVM3 runtime system, serving as a unique identifier for terms within the computational graph. It is used in several key areas:

1. **Term Representation**: Each `Term` in the system has a `Lab` field, which encodes metadata such as function IDs, constructor IDs, or other contextual information. This allows the runtime to quickly identify and process terms during reduction.

2. **Reduction Engine**: The `reduce` function and its variants (e.g., `reduceAt`, `reduceRefAt`) use the `Lab` field to determine the type of term being processed and apply the appropriate reduction rules. For example, the `Lab` field is used to identify whether a term is a function application (`APP`), a constructor (`CTR`), or a superposition (`SUP`), and to handle the reduction accordingly.

3. **Memory Management**: Functions like `allocNode`, `set`, and `got` use the `Lab` field to manage memory allocation and term manipulation. The `Lab` field helps the runtime locate and manipulate terms in memory efficiently.

4. **Parallel Computation**: The `Lab` field is used in the `Collapse` monad and `Sup` operation to manage parallel computations. It helps identify terms that can be evaluated in parallel and ensures that the correct reduction rules are applied.

5. **Compilation**: During the compilation process, the `Lab` field is used to generate low-level C code for terms. The `compile` function and its variants (e.g., `compileFullCore`, `compileFastCore`) use the `Lab` field to optimize the generated code for parallel execution.

6. **Interaction Combinators**: The `Lab` field is central to the Interaction Combinator model, which enables parallel evaluation of terms. Functions like `reduce_ref_sup`, `reduce_dup_lam`, and `reduce_mat_ctr` use the `Lab` field to handle specific interaction rules and ensure correct and efficient execution.

In summary, the `Lab` type is a critical component of the HVM3 runtime system, enabling efficient term identification, reduction, and parallel execution. It plays a key role in the system's ability to handle complex, parallel computations efficiently.
# Loc
The `Loc` type is a fundamental component of the HVM3 runtime system, serving as a memory address or location identifier for terms in the computational graph. It is used in various contexts, such as:
1. **Memory Allocation**: Functions like `allocNode` return a `Loc` value, which represents the memory address of a newly allocated node.
2. **Term Access and Manipulation**: Functions like `got` and `set` use `Loc` to retrieve and modify terms stored at specific memory locations.
3. **Term Representation**: The `termLoc` function extracts the `Loc` value from a `Term`, allowing the runtime to determine where the term is stored in memory.
4. **Parallel Execution**: The `Loc` type is used in functions like `reduceAt` and `reduceRefAt` to manage the reduction of terms in a parallel execution environment.
5. **Compilation**: During the compilation process, `Loc` values are generated and used to represent the memory locations of terms in the compiled C code.

Overall, `Loc` plays a critical role in the efficient management and execution of terms in the HVM3 runtime, enabling the system to handle complex, parallel computations effectively.
# Mode
The `Mode` data type in the HVM3 codebase is used to specify different strategies or modes for handling variable bindings during the compilation or execution of terms. It is particularly relevant in the `Let` construct of the `Core` data type, which represents a variable binding in the high-level representation of the program. The `Let` constructor takes a `Mode` as one of its arguments, indicating that the behavior of the binding (e.g., whether it is strict or lazy, or whether it should be optimized for parallel execution) is determined by the specified `Mode`.

The `modeT` function, which converts a `Lab` (label) into a `Mode`, suggests that the `Mode` is derived from metadata associated with the term. This metadata could include information about the term's type, its role in the computation, or its optimization requirements. By associating a `Mode` with a label, the system can dynamically adjust the compilation or evaluation strategy to optimize performance or correctness based on the specific characteristics of the term.

In summary, the `Mode` data type is a key component in the HVM3 codebase that influences how variable bindings are handled during compilation and execution. It allows the system to adapt its behavior based on the context or properties of the terms being processed, enabling more efficient and flexible computation.
# Oper
The `Oper` data type defines a set of binary operators that can be used in the `Core` language of the HVM3 codebase. These operators include arithmetic operations like addition (`OP_ADD`), subtraction (`OP_SUB`), multiplication (`OP_MUL`), division (`OP_DIV`), and modulus (`OP_MOD`); logical operations like equality (`OP_EQ`), inequality (`OP_NE`), logical AND (`OP_AND`), logical OR (`OP_OR`), and XOR (`OP_XOR`); and bitwise operations like left shift (`OP_LSH`), right shift (`OP_RSH`), less than (`OP_LT`), less than or equal to (`OP_LTE`), greater than (`OP_GT`), and greater than or equal to (`OP_GTE`).

The `Oper` type is used in the `Op2` constructor of the `Core` data type, which represents a binary operation between two `Core` terms. For example, the expression `(+ a b)` would be represented as `Op2 OP_ADD a b` in the `Core` language. This allows the runtime to evaluate expressions involving binary operations by applying the appropriate reduction rules based on the operator type.

The `parseOper` function is responsible for parsing these operators from the input source code. It uses a lookahead mechanism to determine the specific operator based on the characters in the input stream. For example, if the input contains `(+`, the `parseOper` function will recognize this as the `OP_ADD` operator and return the corresponding `Oper` value.

The `operToString` function converts an `Oper` value back into a string representation, which is useful for debugging or output purposes. For example, `operToString OP_ADD` would return the string `"+"`.

Overall, the `Oper` data type plays a crucial role in the HVM3 codebase by enabling the expression and evaluation of binary operations within the computational graph. It is a fundamental component of the `Core` language and is essential for performing a wide range of computations in the HVM3 system.
# PQ
The `PQ` data type is a priority queue implemented as a binary heap, which is a common data structure for managing elements with associated priorities. The `PQLeaf` constructor represents an empty heap, while the `PQNode` constructor represents a node in the heap, containing a key-value pair and two child heaps. The key (of type `Word64`) determines the priority of the element, with lower values indicating higher priority.

The `pqUnion` function merges two priority queues into a single queue, maintaining the heap property. It recursively compares the keys of the root nodes of the two heaps and constructs a new heap with the smaller key as the root, ensuring that the resulting heap remains balanced and correctly ordered.

The `pqPop` function removes and returns the element with the highest priority (i.e., the smallest key) from the heap, along with the remaining heap. If the heap is empty (`PQLeaf`), it returns `Nothing`. Otherwise, it returns the root element and merges the two child heaps to form the new heap.

The `pqPut` function inserts a new key-value pair into the priority queue by creating a new heap node with the pair and merging it with the existing heap.

The `flattenPQ` function uses the `PQ` data type to manage elements in a `Collapse` monad, ensuring that elements are processed in the correct order based on their priority. It initializes an empty heap and processes the elements of the `Collapse` monad, inserting them into the heap and then extracting them in order of priority.

Overall, the `PQ` data type and its associated functions provide an efficient mechanism for managing and processing elements with priorities, which is essential for the parallel computation model used in the HVM3 codebase.
# ParserState
The `ParserState` data type serves as the state container for the parser in the HVM3 codebase. It is essential for maintaining context and metadata during the parsing of input programs into high-level `Core` terms or `Book` definitions. The state is initialized with empty structures and a counter, which are updated as the parser processes the input. This state is then used to store intermediate results, such as function definitions and constructor mappings, which are crucial for the subsequent compilation and execution phases.

In the `doParseCore` and `doParseBook` functions, the `ParserState` is passed to the `runParser` function, which executes the parser and returns the parsed results along with the updated state. This state is then used to create the `Book` data structure, which stores function definitions and metadata for the runtime. The `ParserState` thus plays a critical role in ensuring that the parsing process is context-aware and that the necessary information is preserved for downstream tasks like compilation and execution.
# RunMode
The `RunMode` data type in the HVM3 codebase is used to define different execution modes for the runtime system. These modes could include options like strict evaluation, lazy evaluation, or specific optimizations for parallel execution. By passing a `RunMode` value to the `cliRun` function, users can control how the program is executed, allowing for flexibility in performance tuning and debugging. This is particularly important in a system designed for massively parallel hardware, where different execution strategies can significantly impact performance. The `RunMode` data type thus plays a crucial role in configuring the runtime behavior to match the specific needs of the program and the hardware it runs on.
# SQ
The `SQ` data type is a functional queue implementation that uses two lists to maintain the order of elements. The first list (`xs`) represents the front of the queue, while the second list (`ys`) represents the back. When an element is added to the queue using `sqPut`, it is appended to the back list. When an element is removed using `sqPop`, it is taken from the front list. If the front list is empty, the back list is reversed and becomes the new front list, ensuring that the oldest element is always removed first. This implementation allows for efficient enqueue and dequeue operations, with amortized constant time complexity.

In the context of the HVM3 codebase, `SQ` is used in the `flattenBFS` function to manage the traversal of a `Collapse` monad in a breadth-first manner. The queue ensures that elements are processed in the order they are encountered, which is crucial for the BFS algorithm. By using `SQ`, the codebase can efficiently handle parallel computations and ensure that the traversal order is maintained correctly.
# SUP_f
The `SUP_f` function plays a crucial role in the HVM3 runtime by facilitating parallel computation. When the runtime encounters a `SUP` operation, it calls `SUP_f` to allocate a new `SUP` node in the computational graph. This node represents a superposition of two terms, allowing the runtime to evaluate both terms in parallel. The function takes a `Term` reference as input, which likely includes the necessary information (e.g., label, subterms) to construct the `SUP` node. By creating and managing `SUP` nodes, `SUP_f` enables the runtime to leverage the massively parallel hardware, significantly improving the performance of complex computations. This function is a key component of the Interaction Combinator model, which underpins the HVM3 system's ability to execute programs efficiently in a parallel environment.
# State
The `State` data structure in the HVM3 codebase serves as the backbone for managing the runtime environment. It includes several key components:
1. **Reduction Stack**: The `sbuf` and `spos` fields manage the reduction stack, which is used during term reduction to keep track of intermediate computations.
2. **Heap Memory**: The `heap` and `size` fields handle memory allocation for terms, ensuring efficient storage and retrieval of nodes in the computational graph.
3. **Interaction Counts**: The `itrs` field tracks the number of interactions (reductions) performed, which is useful for debugging and performance monitoring.
4. **Fresh Labels**: The `frsh` field manages the generation of unique labels for duplication operations, ensuring that each duplicated term has a distinct identifier.
5. **Function Book**: The `book` array stores function pointers, allowing the runtime to quickly access and execute compiled functions.

In the Haskell frontend, the `State` monad is used to manage stateful operations during compilation and parsing. For example, the `CompileState` and `InjectState` structures are used to track the state of the compilation process and term injection, respectively. The `ParserState` structure is used to manage the state of the parser, including mappings for constructor IDs and labels.

Overall, the `State` symbol plays a crucial role in ensuring that the HVM3 runtime operates efficiently and correctly, managing both low-level memory and high-level compilation state.
# TAG
The `TAG` data type plays a crucial role in the HVM3 runtime by identifying the type of each term in the computational graph. This identification is necessary for the `reduce` function to apply the correct reduction rules based on the term's type. For example, a term tagged with `ERA` might be erased, while a term tagged with `DUP` might be duplicated for parallel evaluation. The `tagT` function facilitates the conversion from a general `Tag` to a more specific `TAG`, ensuring that the runtime can accurately interpret and process each term. This mechanism is vital for the efficient execution of parallel computations in the HVM3 system.
# Tag
The `Tag` serves as a type identifier for `Term` nodes in the HVM3 runtime system. Each `Term` in the computational graph is associated with a `Tag` that specifies its type, such as `ERA`, `REF`, `NUM`, `CON`, `DUP`, etc. This allows the runtime to efficiently manage and process terms by applying the appropriate reduction rules based on their `Tag`. For example, in the `reduceAt` function, the `Tag` of a `Term` is checked to determine whether to apply reduction rules for function application (`APP`), pattern matching (`MAT`), or duplication (`DUP`). Similarly, in the C backend, functions like `reduce_dup_era` and `reduce_dup_lam` use the `Tag` to decide how to handle specific interaction rules. The `Tag` is also used in debugging and diagnostic functions to provide insights into the state of the computation, making it easier for developers to understand and debug the runtime behavior. Overall, the `Tag` is a critical component of the HVM3 system, enabling efficient and correct execution of parallel computations.
# Term
The `Term` data type is the backbone of the HVM3 runtime, representing nodes in the computational graph. Each `Term` encodes three key pieces of information:
1. **Tag**: Identifies the type of the term (e.g., `ERA`, `REF`, `NUM`, `CON`, `DUP`). This determines how the term is processed during reduction.
2. **Label**: Provides additional metadata, such as function IDs or constructor IDs, which are used during evaluation and pattern matching.
3. **Location**: Points to the memory address where the term is stored, enabling efficient access and manipulation.

The `Term` type is used in various critical operations, including:
- **Memory Management**: Functions like `allocNode`, `set`, and `got` manipulate `Term` instances to allocate memory, write terms, and retrieve terms from specific locations.
- **Term Reduction**: The `reduce` function and its variants (e.g., `reduceAt`, `reduce_ref_sup`, `reduce_dup_lam`) operate on `Term` instances to apply reduction rules and evaluate terms to their normal form.
- **Parallel Execution**: The `Collapse` monad and `Sup` operation use `Term` instances to manage parallel computations and combine terms for parallel evaluation.

In summary, the `Term` data type is essential for representing and manipulating computational nodes in the HVM3 system, enabling efficient parallel execution and memory management.
# _APP_
The `_APP_` tag is a constant value (`0x06`) that represents the type of a term as a function application in the HVM3 codebase. Function application is a core operation in functional programming, where a function is applied to an argument to produce a result. In the HVM3 runtime, terms are represented as nodes in a computational graph, and the `_APP_` tag is used to mark nodes that correspond to function applications.

When the runtime encounters a term with the `_APP_` tag, it knows that this term represents a function application and must be reduced accordingly. The reduction process involves evaluating the function and the argument, and then applying the function to the argument. This is handled by functions like `reduceAt` and `reduceAppLam`, which use the `_APP_` tag to determine the appropriate reduction rules to apply.

The `_APP_` tag is also used during the compilation process, where high-level `Core` terms are translated into low-level C code. Functions like `compileFullCore` and `compileFastCore` generate C code that corresponds to application terms, using the `_APP_` tag to ensure that the generated code correctly represents function applications.

In summary, the `_APP_` tag is a key component of the HVM3 runtime, enabling the system to identify and process function applications efficiently. It is used throughout the codebase in functions related to term reduction, compilation, and memory management, ensuring that function applications are handled correctly in the Interaction Combinator model.
# _CHR_
The `_CHR_` symbol is defined as a constant with the value `0x11`, which serves as a unique identifier for character terms within the HVM3 runtime. This tag is used in several key operations:
1. **Memory Management**: When a character term is created or manipulated, the `_CHR_` tag is used to identify it in memory. For example, in the `injectCore` function, the `_CHR_` tag is passed to `termNew` to allocate memory for a character term.
2. **Term Reduction**: During the reduction process, the `_CHR_` tag helps the runtime determine the type of a term and apply the appropriate reduction rules. For instance, in the `reduce` function, the `_CHR_` tag ensures that character terms are handled correctly.
3. **Compilation**: The `_CHR_` tag is used during the compilation process to generate low-level C code for character terms. Functions like `compileFullCore` and `compileFastCore` use this tag to optimize the compilation of character data for parallel execution.
4. **Parsing and Representation**: The `_CHR_` tag is also involved in parsing character literals from the input program and representing them as `Chr` terms in the `Core` data structure. This ensures that character data is correctly interpreted and processed throughout the system.

Overall, the `_CHR_` tag plays a vital role in the HVM3 codebase by enabling the runtime to efficiently manage, process, and execute character terms within its parallel, graph-based computational model.
# _CTR_
In the HVM3 codebase, `_CTR_` is a tag that identifies constructor terms, which are essential for representing structured data in functional programs. Constructors are used to define and manipulate algebraic data types, such as lists, trees, and custom data structures. The tag `_CTR_` is assigned the value `0x0F` and is used throughout the codebase to distinguish constructor terms from other types of terms.

During the reduction process, the runtime system uses the `_CTR_` tag to apply specific reduction rules for constructors. For example, when a term with the `_CTR_` tag is encountered, the runtime knows to handle it as a constructor, which may involve evaluating its fields or applying pattern matching rules. This is evident in functions like `reduceAppCtr`, `reduceMatCtr`, and `reduceDupCtr`, which are responsible for reducing constructor terms in different contexts.

Additionally, `_CTR_` is used in the construction of new terms. The `termNew` function, which allocates and initializes new terms in memory, uses the `_CTR_` tag to create constructor terms. This ensures that the runtime can correctly interpret and manage these terms during execution.

In the parsing and compilation phases, `_CTR_` is used to identify constructor terms in the input program. The parser recognizes constructor terms and translates them into the appropriate internal representation, while the compiler generates the necessary low-level code to handle these terms during execution. This is particularly important for ensuring that the runtime can efficiently process and evaluate constructor terms in parallel.

Overall, `_CTR_` plays a critical role in the HVM3 codebase by enabling the representation, reduction, and compilation of constructor terms, which are fundamental to the functional programming paradigm and the efficient execution of programs in the HVM3 runtime system.
# _DP0_
In the HVM3 codebase, `_DP0_` serves as a tag that identifies a term as the first duplicated value (`dp0`) in a `Dup` operation. The `Dup` operation is a fundamental part of the Interaction Combinator model, allowing for the duplication of terms in a way that supports parallel evaluation. When a `Dup` node is created, it typically involves two duplicated values (`dp0` and `dp1`) and a body (`bod`) that will be evaluated with these duplicated values. The `_DP0_` tag is used to mark the term representing `dp0`, ensuring that the runtime can correctly identify and process it during reduction.

In the provided context, `_DP0_` is used in two key places:
1. **Term Creation**: In `BLOCK 187`, `_DP0_` is used to create a new term that represents `dp0` in a `Dup` operation. This term is then inserted into the `args` map, which is used to store function arguments and other runtime data.
2. **Reduction**: In `BLOCK 295`, `_DP0_` is used during the reduction of a `Dup` node. Here, a new `APP` node is created to represent the application of the body (`bod`) to `dp0`, and `_DP0_` is used to mark the term representing `dp0` in this application.

Overall, `_DP0_` plays a crucial role in the HVM3 runtime by ensuring that duplicated values are correctly identified and processed during parallel evaluation, enabling the efficient execution of complex, parallel computations.
# _DP1_
In the HVM3 codebase, `_DP1_` is a tag with a value of `0x01` that is used to identify one of the two branches of a duplicated term. When a `Dup` operation is performed, the system creates two branches, `_DP0_` and `_DP1_`, to represent the two possible paths of evaluation. The `_DP1_` tag is used to mark the second branch, allowing the runtime to differentiate between the two branches during the reduction process.

In the provided context, `_DP1_` is used in the `injectCore` function to insert the second branch of a duplicated term into the argument map (`args`). This ensures that the runtime can correctly access and manipulate the second branch when needed. Additionally, `_DP1_` is used in the `reduceRefAt_DupF` function to create an application node (`APP`) for the second branch, further facilitating the parallel evaluation of the duplicated term.

Overall, `_DP1_` plays a critical role in the HVM3 codebase by enabling the system to handle duplication operations efficiently, which is essential for achieving high performance in parallel computations.
# _DUP_F_
The `_DUP_F_` symbol serves as a unique identifier for the `DUP` primitive function within the HVM3 codebase. This function is essential for handling dynamic duplication of terms, which is a key operation in the parallel evaluation model of the Interaction Combinator system. The `DUP` operation allows the runtime to duplicate terms, enabling parallel evaluation of expressions by creating multiple instances of a term that can be processed concurrently.

In the parsing phase (BLOCK 220), `_DUP_F_` is used to construct a `Dup` term when parsing a duplication construct in the input program. This term includes metadata such as the duplication labels (`dp0`, `dp1`), the value to be duplicated (`val`), and the body of the duplication (`bod`).

During the reduction phase (BLOCK 294 and BLOCK 295), `_DUP_F_` is used to identify and handle the `DUP` operation. The `reduceRefAt_DupF` function is specifically designed to reduce terms that involve the `DUP` primitive, ensuring that the duplication operation is executed correctly within the runtime.

Finally, `_DUP_F_` is listed in the `primitives` section (BLOCK 515) as one of the core primitive functions supported by the runtime, alongside other primitives like `SUP`. This listing ensures that the `DUP` operation is recognized and managed appropriately during the compilation and execution phases.

Overall, `_DUP_F_` plays a critical role in enabling parallel computations within the HVM3 runtime, facilitating the efficient duplication and evaluation of terms in a massively parallel environment.
# _ERA_
In the HVM3 codebase, `_ERA_` serves as a tag to identify the `ERA` term type, which represents an erased or empty term. This is crucial for the system's memory management and term reduction processes. For example, in the `Collapse` monad, `CEra` is used to signify an empty computation, and in the `Core` data type, `Era` is a constructor that represents an erased term. The `_ERA_` tag is also used in functions like `termNew` to create new terms with the `ERA` type, and in reduction functions like `reduceAppEra` and `reduceMatEra` to handle specific cases where an `ERA` term is encountered. Overall, `_ERA_` plays a key role in managing and processing erased terms within the HVM3 runtime, ensuring efficient execution and memory usage.
# _FRESH_F_
The `_FRESH_F_` symbol plays a crucial role in the HVM3 runtime by identifying the `FRESH` primitive operation. This operation is used to generate a fresh label for duplication (`DUP`) operations, which are fundamental to the parallel evaluation model of the Interaction Combinators. When the runtime encounters a term with the `_FRESH_F_` label, it invokes the `reduceRefAt_FreshF` function to handle the reduction. This function is responsible for creating a new duplication label, ensuring that each `DUP` operation has a unique identifier, which is necessary for maintaining the correctness and efficiency of parallel computations. The `_FRESH_F_` label is part of the system's primitive operations, which are essential for managing the low-level details of term manipulation and parallel execution in the HVM3 runtime.
# _LAM_
The `_LAM_` tag is a constant defined as `0x0C` and is used to identify lambda terms (`Lam`) in the HVM3 runtime. Lambda terms are a core construct in functional programming, representing anonymous functions. In the HVM3 codebase, lambda terms are part of the `Core` data type, which is used to represent high-level terms during compilation and execution. The `_LAM_` tag is used in several key operations:

1. **Term Reduction**: When the runtime encounters a term with the `_LAM_` tag, it knows that the term is a lambda abstraction and applies the appropriate reduction rules. For example, in the `reduceAppLam` function, the runtime handles the application of a lambda term to an argument.

2. **Memory Management**: The `_LAM_` tag is used when allocating and manipulating terms in memory. For instance, the `termNew` function creates a new term with the `_LAM_` tag, and the `set` function writes this term to a specific memory location.

3. **Compilation**: During the compilation process, the `_LAM_` tag is used to generate low-level C code for lambda terms. The `compileFullCore` and `compileFastCore` functions handle the translation of lambda terms into C code, ensuring that the runtime can efficiently execute them.

4. **Term Manipulation**: The `_LAM_` tag is also used in functions that manipulate terms, such as `injectCore`, which injects a lambda term into the runtime memory, and `liftDups`, which handles the lifting of lambda terms in the presence of duplication operations.

Overall, the `_LAM_` tag is a critical component of the HVM3 runtime, enabling the system to correctly identify, reduce, and execute lambda terms within the Interaction Combinator model. Its presence ensures that lambda abstractions are handled efficiently and correctly during the evaluation of functional programs.
# _LET_
The `_LET_` tag is defined as a constant with the value `0x05` in the codebase, and it is used to mark `Let` terms in the runtime. When a `Let` term is created, it is assigned the `_LET_` tag, which allows the runtime to identify and process it correctly. The `Let` term itself consists of a mode (e.g., `LAZY`, `STRI`, `PARA`), a variable name, a value expression, and a body expression. During reduction, the `reduceLet` function handles the evaluation of `Let` terms, ensuring that the value is properly bound to the variable before evaluating the body. In the compilation process, `Let` terms are translated into low-level C code, with the `_LET_` tag used to generate the appropriate runtime instructions. Overall, the `_LET_` tag plays a critical role in the HVM3 runtime by enabling the correct handling of variable bindings and ensuring the proper evaluation of expressions within the functional programming model.
# _LOG_F_
The `_LOG_F_` symbol represents a primitive operation in the HVM3 codebase that is used for logging terms during the evaluation process. It is defined as a label with the value `0xFFD` and is included in the list of primitives in the `primitives` data structure. When the `reduceRefAt` function encounters a term with the `_LOG_F_` label, it delegates the handling of this term to the `reduceRefAt_LogF` function. This function is responsible for extracting the term and logging it, returning `0` as the result. The purpose of `_LOG_F_` is to provide a mechanism for debugging and diagnostic output, allowing developers to inspect the state of the computation by logging specific terms during the evaluation process. This is particularly useful in a parallel execution environment where tracking the state of computations can be complex.
# _MAT_
The `_MAT_` symbol is a tag that identifies the `Mat` (match) term in the HVM3 codebase. The `Mat` term is a fundamental construct used for pattern matching, allowing the runtime to evaluate different branches of code based on the structure or value of a term. This is crucial for implementing conditional logic in functional programs.

The `Mat` term consists of three main components:
1. **Value (`val`)**: The term being matched against the cases.
2. **Moved Variables (`mov`)**: A list of external variables that are moved into the match context.
3. **Cases (`css`)**: A list of cases, each containing a constructor, fields, and a body. The constructor specifies the pattern to match, the fields are the variables bound in the case, and the body is the code to execute if the pattern matches.

During the compilation process, the `Mat` term is translated into low-level C code. The `compileFullCore` and `compileFastCore` functions generate the necessary C code to allocate memory for the `Mat` term, set the value being matched, and manage the execution flow for each case.

In the runtime, the `reduce_mat_ctr` function handles the reduction of `Mat` terms when they match a constructor (`CTR`). This function evaluates the matched value and selects the appropriate case to execute, ensuring that the correct branch of the program is followed. The function also handles the allocation of memory and the construction of new terms as needed during the reduction process.

The `Mat` term is a key component of the HVM3 runtime, enabling pattern matching and conditional logic in functional programs. It supports the parallel execution model by allowing the runtime to efficiently evaluate and reduce terms based on their structure or value.
# _OPX_
The `_OPX_` tag is a critical component of the HVM3 runtime, representing a term type used for binary operations. When a binary operation (`Op2`) is encountered during compilation, the `injectCore` function creates a new term of type `_OPX_` using the `termNew` function. This term is then processed by the runtime, which applies specific reduction rules based on the type of the operands. For example, if the operand is an `ERA` (erasure), the `reduceOpxEra` function is called, while for a `LAM` (lambda), the `reduceOpxLam` function is used. This mechanism ensures that binary operations are evaluated correctly and efficiently within the parallel execution model of HVM3. The `_OPX_` tag thus serves as a key identifier for terms involved in binary operations, enabling the runtime to handle them appropriately during reduction.
# _OPY_
The `_OPY_` tag is a specific type identifier used within the HVM3 codebase to categorize terms that require a particular kind of reduction. When a term with the `_OPY_` tag is encountered during the reduction process, the runtime system dispatches to one of the specialized reduction functions (`reduceOpyEra`, `reduceOpyLam`, `reduceOpySup`, `reduceOpyCtr`, or `reduceOpyW32`) based on the term's specific type. This allows the system to handle different kinds of terms efficiently, ensuring that the reduction process is both correct and optimized for parallel execution. The `_OPY_` tag is thus a crucial part of the runtime's ability to manage and reduce terms in a massively parallel environment, leveraging the Interaction Combinator model to achieve high performance.
# _REF_
In the HVM3 codebase, the `_REF_` tag is defined as a constant with the value `0x04`. This tag is used to identify terms of type `REF`, which are used to represent references to functions or other entities in the computational graph. The `REF` type is a fundamental part of the term representation in the HVM3 runtime system, allowing the system to efficiently manage and process function calls and other reference-based operations.

The `_REF_` tag is used in several key functions and operations within the codebase:
1. **Term Creation**: The `termNew` function uses the `_REF_` tag to create new `REF` terms. This function is called when a new reference term is needed, such as during the compilation or execution of a program.
2. **Reduction Engine**: The `reduce` function and its variants use the `_REF_` tag to identify `REF` terms and apply the appropriate reduction rules. This ensures that function calls and other reference-based operations are correctly evaluated.
3. **Memory Management**: The `allocNode` and `set` functions use the `_REF_` tag to manage memory allocation and term manipulation for `REF` terms. This ensures that the runtime system can efficiently handle the memory requirements of reference-based operations.
4. **Compilation**: The `compile` function and its variants use the `_REF_` tag to generate low-level C code for `REF` terms. This ensures that the compiled code correctly represents and handles reference-based operations.

Overall, the `_REF_` tag plays a crucial role in the HVM3 runtime system, enabling the efficient and correct handling of reference terms in the computational graph. Its use in term creation, reduction, memory management, and compilation ensures that the system can effectively manage and process function calls and other reference-based operations.
# _SUB_
In the HVM3 codebase, `_SUB_` is a tag with the value `0x03` that is used during the creation and initialization of terms. Specifically, it is employed in functions like `injectCore` and `reduceRefAt_DupF` to set default values for term fields. For example, when a `Lam` (lambda) or `Dup` (duplication) node is allocated, `_SUB_` is used to initialize certain fields of the node before they are populated with actual data. This ensures that the terms are in a valid state during their creation and manipulation. The `_SUB_` tag acts as a placeholder, maintaining the integrity of the term structure and supporting the memory management system of the runtime. Its role is crucial in the correct initialization and handling of terms, which is fundamental to the parallel evaluation model of the HVM3 system.
# _SUP_
The `_SUP_` tag is a fundamental component of the HVM3 runtime system, specifically designed to handle superposed terms. In the Interaction Combinator model, superposed terms allow for parallel evaluation by representing multiple possible states or values simultaneously. The `_SUP_` tag is used to identify these terms during the reduction process, enabling the runtime to apply specific reduction rules that handle parallel computations efficiently.

For example, when a term with the `_SUP_` tag is encountered, the runtime knows to treat it as a superposed term and applies the appropriate reduction rules, such as `reduceAppSup` or `reduceDupSup`, to manage its evaluation. This tag is also used during the compilation process to generate low-level C code that supports parallel execution, ensuring that superposed terms are handled correctly by the runtime.

Overall, the `_SUP_` tag plays a crucial role in enabling the parallel execution model of HVM3, allowing the system to efficiently manage and process superposed terms in a massively parallel hardware environment.
# _SUP_F_
The `_SUP_F_` label represents the `Sup` operation in the HVM3 codebase, which is essential for parallel computation. The `Sup` operation allows two terms to be combined into a single superposed term, enabling the runtime to evaluate them in parallel. This is particularly important in the Interaction Combinator model, where parallel evaluation is a key feature for achieving high performance on massively parallel hardware. The label `_SUP_F_` is used in the `reduceRefAt` function to identify terms that should be processed by the `reduceRefAt_SupF` function, which handles the reduction of superposed terms. By including `_SUP_F_` in the `primitives` list, the codebase ensures that the `Sup` operation is recognized and managed correctly during both parsing and execution. Overall, `_SUP_F_` plays a critical role in enabling the parallel evaluation capabilities of the HVM3 runtime.
# _VAR_
In the HVM3 codebase, the `_VAR_` tag plays a crucial role in identifying and managing variable nodes within the computational graph. Hereâ€™s how it is used:

1. **Term Representation**:
   - The `_VAR_` tag is part of the `Term` data type, which represents nodes in the computational graph. When a term is created with the `_VAR_` tag, it signifies that the term is a variable. This allows the runtime to differentiate between variables and other types of terms (e.g., constructors, numbers, or duplications).

2. **Memory Management**:
   - During memory allocation and term manipulation, the `_VAR_` tag is used to identify variable nodes. For example, in the `injectCore` function, when a new variable is introduced (e.g., in a `Let` or `Lam` construct), the `termNew` function is called with the `_VAR_` tag to create a new variable node in memory.

3. **Term Reduction**:
   - The `reduce` function uses the `_VAR_` tag to handle variable terms during the reduction process. When a term with the `_VAR_` tag is encountered, the runtime retrieves the value associated with the variable from memory and continues the reduction process.

4. **Compilation**:
   - During compilation, the `_VAR_` tag is used to generate low-level C code for variable terms. The `compileFastCore` and `compileFullCore` functions handle variable terms by generating appropriate C code based on the `_VAR_` tag.

5. **Parsing and Debugging**:
   - The `_VAR_` tag is also used in parsing and debugging. For example, when parsing a variable from the input program, the parser creates a `Var` term with the `_VAR_` tag. Similarly, during debugging, the `print_term` function can identify and display variable terms using the `_VAR_` tag.

Overall, the `_VAR_` tag is a fundamental part of the HVM3 runtime system, enabling efficient handling of variables in the computational graph. It ensures that variables are correctly identified, managed, and processed during memory allocation, term reduction, compilation, and debugging.
# _W32_
The `_W32_` tag plays a critical role in the HVM3 runtime system, which is built around the Interaction Combinator model. It is used to identify terms that represent 32-bit unsigned integers (`W32`). This tag is essential for several operations:

1. **Term Creation**: When a numeric term is created (e.g., via `term_new`), the `_W32_` tag is used to specify that the term is a 32-bit unsigned integer. For example, in the Haskell code, `term_new(W32, 0, val)` creates a new term with the `W32` tag.

2. **Term Reduction**: During reduction, the `_W32_` tag is used to determine how to handle numeric terms. For instance, in the `reduce` function, terms with the `W32` tag are processed by specific reduction rules like `reduceAppW32`, `reduceMatW32`, or `reduceOpxW32`.

3. **Pattern Matching**: In pattern matching operations, the `_W32_` tag is used to identify numeric terms and apply the appropriate logic. For example, in the `reduce_mat_w32` function, the `W32` tag is checked to determine how to handle the term.

4. **Dynamic Operations**: In dynamic operations like `@DUP` and `@SUP`, the `_W32_` tag is used to verify that the label provided is a numeric value. If the label is not a `W32` term, an error is raised.

5. **Debugging and Output**: The `_W32_` tag is also used in debugging and diagnostic output, such as in the `print_tag` function, where it helps identify the type of a term during runtime inspection.

Overall, `_W32_` is a fundamental part of the HVM3 runtime, enabling the system to efficiently handle and process numeric terms within the Interaction Combinator model.
# allocNode
The `allocNode` function is a low-level memory allocation utility that plays a central role in the HVM3 runtime. It is used to allocate memory for nodes in the computational graph, which are represented by the `Term` data type. Each node has a specific arity, which determines how many child terms it can hold. For example, a node with arity 2 can store two child terms, while a node with arity 1 can store only one. The function is called in various scenarios, such as when compiling high-level terms into low-level C code, when reducing terms to their normal form, and when managing parallel computations.

During compilation, `allocNode` is used to allocate memory for nodes representing different constructs like `Lam`, `App`, `Sup`, and `Dup`. For instance, when compiling a `Lam` term, a node with arity 1 is allocated to store the lambda's body. Similarly, when compiling an `App` term, a node with arity 2 is allocated to store the function and its argument.

In the runtime, `allocNode` is used during term reduction to allocate memory for intermediate results. For example, when reducing a `Dup` term, a node with arity 2 is allocated to store the duplicated values. The function is also used in parallel execution scenarios, such as when combining terms using the `Sup` operation, where nodes are allocated to store the superposed terms.

Overall, `allocNode` is a fundamental building block of the HVM3 runtime, enabling efficient memory management and supporting the parallel execution model by dynamically allocating memory for terms as needed.
# alloc_node
The `alloc_node` function is a low-level memory management utility that allocates space for nodes in the HVM3 runtime. Each node represents a term in the computational graph, and the arity specifies how many child nodes it will have. This function is used in various contexts:
1. **Compilation**: During the compilation process, `alloc_node` is called to allocate memory for terms like `Lam`, `App`, `Sup`, `Dup`, and `Ctr`. For example, when compiling a `Lam` term, `alloc_node(1)` is used to allocate space for the lambda's body.
2. **Term Reduction**: During term reduction, `alloc_node` is used to allocate memory for intermediate results. For instance, in `reduce_dup_lam`, `alloc_node(2)` is used to allocate space for a duplicated lambda.
3. **Parallel Execution**: In parallel execution scenarios, `alloc_node` is used to allocate memory for superposed terms (`Sup`) and other parallel constructs. For example, in `reduce_ref_sup`, `alloc_node(arity)` is used to allocate space for a new reference node.
4. **Memory Reuse**: The `compileFastAlloc` function in the Haskell frontend attempts to reuse previously allocated nodes to optimize memory usage, although this feature is temporarily disabled due to bugs.

The function is implemented in the C backend (`hvm.c`) and is exposed to the Haskell frontend via a foreign function interface (FFI). This allows the Haskell code to manage memory allocation while leveraging the low-level efficiency of C. The `alloc_node` function is fundamental to the runtime's ability to handle the dynamic and parallel nature of the Interaction Combinator model, ensuring that memory is allocated and managed efficiently during program execution.
# bind
1. **`bind` in the `Collapse` Monad**:
   - The `bind` function in the `Collapse` monad is defined as `bind :: Collapse a -> (a -> Collapse b) -> Collapse b`. This is a standard monadic bind operation, which sequences computations within the `Collapse` monad. It takes a `Collapse` computation and a function that produces another `Collapse` computation, and it combines them into a single `Collapse` computation. This is essential for managing parallel computations, as the `Collapse` monad handles multiple possible outcomes or states and reduces them to a single value or a list of results.

2. **`bind` in the `Compile` Monad**:
   - The `bind` function in the `Compile` monad is defined as `bind :: String -> String -> Compile ()`. This function is used during the compilation process to associate variable names with their corresponding terms. It modifies the `CompileState` by inserting a mapping from the variable name to the term (or binder host) into the `bins` field of the state. This mapping is crucial for ensuring that variables are correctly linked to their respective terms during the generation of low-level C code. The `bind` function is used extensively in various compilation functions, such as `compileFullCore`, `compileFastCore`, and `compileFastBody`, to manage the binding of variables to terms in different contexts, such as lambda expressions, let bindings, and pattern matching.

In summary, the `bind` symbol plays a critical role in both the high-level functional programming constructs and the low-level compilation mechanics of the HVM3 codebase. In the `Collapse` monad, it sequences computations, while in the `Compile` monad, it manages the association of variables with their corresponding terms during the compilation process.
# cliRun
The `cliRun` function serves as the entry point for running programs within the HVM3 system. It takes several parameters:
1. `filePath`: The path to the file containing the program to be executed.
2. `debug`: A boolean flag indicating whether to enable debugging output.
3. `compiled`: A boolean flag indicating whether to compile the program before execution.
4. `mode`: The execution mode, which can be `Collapse`, `Search`, or `Normalize`, depending on the user's choice of flags.
5. `showStats`: A boolean flag indicating whether to display execution statistics.

The function first reads and processes the input file, then compiles it if the `compiled` flag is set. It then initializes the runtime environment and executes the program according to the specified mode. During execution, it handles debugging output and statistics collection if the corresponding flags are enabled. Finally, it returns an `Either String ()` result, where a `Left` value indicates an error message, and a `Right` value indicates successful execution.

This function is crucial for integrating the high-level Haskell frontend with the low-level C runtime, ensuring that user commands are correctly interpreted and executed within the HVM3 system.
# closeWith
The `closeWith` function is a parser combinator that takes a string (representing a closing delimiter, such as `")"`, `"]"`, or `"}"`) and attempts to consume it from the input stream. It is used in various parsing functions (e.g., `parseRef`, `parseCtr`, `parseMat`, `parseLst`, `parseDef`, `parseADTCtr`) to handle the closing of nested structures. For example, when parsing a function call like `@foo(arg1, arg2)`, `closeWith ")"` ensures that the parser correctly identifies the end of the argument list. Similarly, when parsing a list like `[elem1, elem2]`, `closeWith "]"` ensures the list is properly closed. This function is essential for maintaining the correct structure of the parsed program and ensuring that nested expressions are accurately represented in the resulting `Core` terms.
# collapseDupsAt
The `collapseDupsAt` function plays a pivotal role in the HVM3 codebase by managing the traversal and optimization of the computational graph. Its primary purpose is to collapse duplicate terms, which is crucial for efficient parallel execution. The function takes four parameters:
1. `state`: An `IntMap` that tracks paths for handling superposition and duplication terms.
2. `reduceAt`: A function that applies reduction rules to terms.
3. `book`: The `Book` data structure containing function definitions and metadata.
4. `host`: The location of the term being processed.

The function operates recursively, processing terms based on their type. For example:
- For `LET` terms, it processes the value and body separately.
- For `LAM` terms, it processes the body.
- For `APP` terms, it processes the function and argument.
- For `SUP` terms, it handles superposition by selecting a path from the `IntMap` and processing the corresponding term.
- For `DP0` and `DP1` terms, it manages duplication by updating the `IntMap` and processing the relevant subterms.
- For `CTR`, `MAT`, `OPX`, `OPY`, and `REF` terms, it processes the necessary subterms or arguments.

By collapsing duplicates, `collapseDupsAt` ensures that the computational graph is optimized for parallel execution, reducing redundancy and improving performance. This function is integral to the HVM3 runtime, enabling efficient evaluation of complex, parallel computations.
# collapseSups
The `collapseSups` function plays a crucial role in the HVM3 codebase by ensuring that superposed terms (`Sup`) and other term types are properly processed within the `Collapse` monad. This function recursively traverses the `Core` term structure, applying the `collapseSups` operation to each subterm. For example, in the case of a `Ref` term, it processes the arguments; for a `Lam` term, it processes the body; and for an `App` term, it processes both the function and the argument. The `Sup` case is particularly significant because it handles superposed terms, which are a key feature of the parallel evaluation model. By recursively collapsing these terms, `collapseSups` ensures that the parallel computations are correctly managed and reduced to their normal forms. This function is essential for maintaining the efficiency and correctness of the parallel execution model in HVM3.
# collectLabels
The `collectLabels` function plays a crucial role in the HVM3 codebase by identifying and gathering all labels used in `Sup` (superposition) and `Dup` (duplication) operations within a `Core` term. These labels are critical for the parallel execution model, as they help the runtime manage and synchronize parallel computations. The function operates recursively, traversing the entire `Core` term and collecting labels into a map. This map is then used during the compilation and execution phases to ensure that the runtime can correctly handle the parallel aspects of the computation. By isolating and managing these labels, `collectLabels` contributes to the efficient and correct execution of parallel programs in the HVM3 system.
# compile
The `compile` function serves as the entry point for the compilation process in the HVM3 codebase. It works by invoking three different compilation modes (`compileFull`, `compileFast`, `compileSlow`) and combining their outputs. Each mode is tailored for specific evaluation strategies:
- **`compileFull`**: Generates comprehensive C code that handles all possible term reductions, ensuring correctness but potentially at the cost of performance.
- **`compileFast`**: Optimizes the compilation for speed, focusing on common execution paths and reducing overhead for frequently used operations.
- **`compileSlow`**: Provides a fallback mode for cases where the fast mode might not be applicable, ensuring that the program can still execute correctly.

The `compile` function uses these modes to produce C code that is then executed by the runtime. This process is crucial for translating the high-level functional programming constructs into efficient low-level code that can leverage the parallel capabilities of modern hardware. By generating optimized C code, the `compile` function enables the HVM3 runtime to achieve high performance while maintaining the correctness of the program's execution.
# compileFast
The `compileFast` function is responsible for compiling high-level `Core` terms into low-level C code with a focus on performance optimization. It operates within the context of a `Book` data structure, which contains function definitions and metadata, and a function ID (`fid`) that identifies the specific function being compiled. The function takes additional parameters, such as the `Core` term to be compiled, a `copy` flag indicating whether to copy terms, and a list of arguments (`args`) that are passed to the function.

The function begins by emitting the C function signature and initializing an iteration counter (`itrs`). It then processes the arguments, generating C code to either reduce or retrieve them based on their strictness. If the `copy` flag is set and the argument is strict, additional checks are performed to handle special cases like `ERA` and `SUP` terms. The function then binds the arguments to their respective names and proceeds to compile the function body using `compileFastArgs`.

The `compileFastArgs` function handles the compilation of the function's argument list, while `compileFastBody` manages the compilation of the function body, including pattern matching (`Mat`), duplication (`Dup`), and other term types. The `compileFastCore` function is a helper that compiles individual `Core` terms, generating C code for constructs like `Lam`, `App`, `Sup`, and `Dup`. It also handles memory allocation and reuse, ensuring efficient resource management.

Throughout the compilation process, the `compileFast` function emits C code that is optimized for parallel execution, leveraging the Interaction Combinator model to achieve high performance. It also includes mechanisms for handling errors and ensuring correct term manipulation. The resulting C code is designed to be executed by the HVM3 runtime, which manages memory, term reduction, and parallel execution.

In summary, `compileFast` is a critical component of the HVM3 codebase, enabling the efficient compilation of high-level functional programs into low-level C code that can be executed with minimal overhead on massively parallel hardware.
# compileFastAlloc
The `compileFastAlloc` function plays a crucial role in the memory management strategy of the HVM3 runtime. By allocating memory for nodes during the compilation process, it ensures that the runtime can efficiently manage and manipulate terms during execution. The reuse map passed to the function allows for the reuse of previously allocated memory locations, reducing the overhead associated with frequent memory allocations and deallocations. This is particularly important in a massively parallel execution environment, where efficient memory management is essential for achieving high performance. The function is called in various contexts within the `compileFastCore` function, such as when compiling `Lam`, `App`, `Sup`, `Dup`, `Ctr`, and `Mat` terms, ensuring that each term has the necessary memory allocated for its child nodes. This contributes to the overall efficiency and scalability of the HVM3 runtime.
# compileFastArgs
The `compileFastArgs` function is used during the compilation phase of the HVM3 runtime, specifically when compiling functions in "Fast-Mode." This mode is designed to optimize the execution of functions by leveraging parallel hardware capabilities. The function takes the following parameters:
- `book`: A `Book` data structure that contains function definitions, metadata, and other necessary information for compilation.
- `fid`: A `Word64` value representing the function ID, which is used to identify the function being compiled.
- `body`: The `Core` term representing the body of the function, which will be compiled into low-level C code.
- `ctx`: A list of strings representing the compiled arguments, which are used as context during the compilation process.
- `reuse`: A map (`MS.Map Int [String]`) that tracks reusable terms, allowing the compiler to optimize memory usage by reusing terms when possible.

The function's main task is to compile the argument list in a way that is compatible with the parallel execution model. It does this by processing the arguments and ensuring that they are correctly integrated into the compiled function body. This involves handling strict and non-strict arguments, managing memory allocation, and ensuring that the arguments are ready for parallel evaluation.

The `compileFastArgs` function is called by the `compileFast` function, which is responsible for compiling the entire function in "Fast-Mode." After compiling the arguments, `compileFastArgs` passes the compiled context and reuse map to the next stage of the compilation process, ensuring that the function body is compiled with the correct argument context.

In summary, `compileFastArgs` is a critical component of the HVM3 compilation process, enabling efficient parallel execution by compiling function arguments in a way that aligns with the runtime's parallel evaluation model.
# compileFastBody
The `compileFastBody` function plays a pivotal role in the HVM3 codebase by translating the body of functions into C code that can be executed efficiently by the runtime. It handles various `Core` term types, including pattern-matching (`Mat`), duplication (`Dup`), and let bindings (`Let`), ensuring that each term is compiled according to its specific semantics. For pattern-matching, it generates C code that checks the type of the term and dispatches to the appropriate case, handling both numeric and constructor patterns. For duplication, it generates code that manages the creation and manipulation of duplicated terms, ensuring that the runtime can handle them efficiently. For let bindings, it generates code that evaluates the bound value and assigns it to the appropriate variable, supporting different evaluation modes (lazy, strict, and parallel). The function also manages the reuse of memory locations, optimizing memory usage and performance. Overall, `compileFastBody` is essential for translating high-level functional constructs into efficient low-level C code, enabling the HVM3 runtime to execute programs with high performance on massively parallel hardware.
# compileFastCore
The `compileFastCore` function is a key part of the HVM3 compilation pipeline, designed to optimize the translation of `Core` terms into C code for fast execution. It takes four parameters: a `Book` (which stores function definitions and metadata), a `Word64` (representing the function ID), a `Core` term (the high-level term to be compiled), and a `Map` (used for memory reuse optimization). The function recursively processes the `Core` term, generating C code that is tailored to the specific term type. For example:
- For `Era`, it generates a simple C term representing an eraser.
- For `Let`, it handles lazy, strict, and parallel evaluation modes, generating appropriate C code for each.
- For `Lam` and `App`, it allocates memory for lambda abstractions and function applications, respectively.
- For `Sup` and `Dup`, it generates code for superposition and duplication, enabling parallel evaluation.
- For `Ctr` and `Mat`, it handles constructors and pattern matching, ensuring efficient execution of these constructs.
- For `U32`, `Chr`, and `Op2`, it generates code for numeric, character, and binary operations.
- For `Ref`, it handles references, including dynamic `SUP` and `DUP` operations.

The function ensures that the generated C code is optimized for performance, leveraging the Interaction Combinator model and the parallel capabilities of the runtime. By handling each term type with specific optimizations, `compileFastCore` plays a crucial role in the overall efficiency of the HVM3 system.
# compileFastSave
The `compileFastSave` function is responsible for completing the compilation of terms in "fast mode," which is optimized for parallel execution. It takes the following parameters:
- `book`: The `Book` data structure, which contains function definitions and metadata necessary for compilation.
- `fid`: A unique identifier for the function being compiled.
- `term`: The `Core` term that is being compiled.
- `ctx`: The context in which the term is being compiled, represented as a list of strings.
- `itr`: An iteration count, which tracks the number of iterations performed during compilation.
- `reuse`: A map that tracks reused terms to optimize memory usage and avoid redundant computations.

The function's primary role is to save the compiled code, ensuring that it is correctly formatted and ready for execution. This involves emitting the compiled code and updating the necessary data structures to maintain the context and reuse information. By doing so, `compileFastSave` ensures that the compiled terms can be efficiently executed in the runtime, leveraging the parallel capabilities of the HVM3 system. This function is a critical part of the compilation pipeline, bridging the gap between high-level term representation and low-level execution.
# compileFastUndo
The `compileFastUndo` function plays a critical role in the HVM3 compilation pipeline by ensuring that terms that cannot be efficiently handled in "fast mode" are still compiled correctly using the "full mode" strategy. This fallback mechanism is essential for maintaining the correctness of the compiled code, especially when dealing with complex or edge-case terms that may not benefit from the aggressive optimizations of the fast mode.

When the fast compilation mode encounters a term that it cannot optimize effectively, `compileFastUndo` is called to switch to the full mode. This involves recompiling the term with a more thorough and less aggressive approach, ensuring that all necessary reductions and transformations are applied correctly. The function leverages the `Book` data structure to access the required function definitions and metadata, and it uses the provided context and iteration information to guide the compilation process.

The `reuse` map is particularly important for optimizing the compilation process. It allows the function to reuse previously compiled components or optimizations, reducing redundant work and improving overall efficiency. By managing this reuse, `compileFastUndo` ensures that the fallback to full mode does not unnecessarily degrade performance.

In summary, `compileFastUndo` is a safety mechanism within the HVM3 compilation pipeline, ensuring that all terms are compiled correctly, even when the fast mode optimizations are not applicable. It bridges the gap between fast and full compilation modes, maintaining both performance and correctness in the compiled output.
# compileFastVar
The `compileFastVar` function is responsible for compiling variable references into low-level C code during the "fast mode" compilation process. In the HVM3 codebase, "fast mode" is an optimized compilation strategy designed to maximize parallel execution efficiency. When the `compileFastCore` function encounters a `Var` term (representing a variable), it delegates the compilation task to `compileFastVar`. 

The function takes a `String` parameter, which represents the name of the variable, and returns a `Compile String`. The `Compile` monad is used to manage the compilation state and generate the corresponding C code. The exact implementation of `compileFastVar` is not provided in the context, but its purpose is to produce a string of C code that correctly references the variable in the runtime environment. This ensures that the variable can be efficiently accessed and manipulated during the execution of the compiled program.

By isolating the compilation of variables into a dedicated function, the HVM3 codebase maintains modularity and clarity in its compilation process. This approach allows for easy optimization and debugging of variable handling, which is crucial for achieving high performance in the parallel execution model.
# compileFull
The `compileFull` function in the HVM3 codebase is a critical part of the compilation pipeline. It takes a `Book` (which contains function definitions and metadata), a function ID (`fid`), a `Core` term (representing the high-level program structure), a `copy` flag, and a list of arguments (`args`). The function generates C code that represents the given `Core` term in a form that can be executed by the HVM3 runtime.

The function starts by emitting a C function declaration for the term, using the function ID to generate a unique name. It then processes the arguments, binding them to local variables in the generated C code. Depending on the `copy` flag, it either reduces the argument terms or retrieves them directly from memory. This step ensures that the arguments are in the correct state for further processing.

The core of the compilation process is handled by the `compileFullCore` function, which is called with the `Core` term and a host location. `compileFullCore` recursively compiles the term, generating C code for each subterm and managing memory allocation through `allocNode` and `set`. The `compileFull` function ensures that the generated code is structured correctly, with proper indentation and variable binding.

Overall, `compileFull` plays a pivotal role in the HVM3 compilation process, bridging the gap between high-level functional programming constructs and low-level C code optimized for parallel execution. It ensures that the resulting code is efficient, correct, and ready for execution in the HVM3 runtime.
# compileFullCore
The `compileFullCore` function is a recursive compiler that translates high-level `Core` terms into low-level C code, which is then executed by the HVM3 runtime. It takes four parameters: `book` (a data structure containing function definitions and metadata), `fid` (a function ID), `core` (the `Core` term to be compiled), and `host` (a string representing the memory location where the compiled term will be stored).

For each term type, `compileFullCore` generates the corresponding C code:
- **Era**: Returns a new `ERA` term.
- **Var**: Compiles a variable reference.
- **Let**: Allocates memory for a `Let` term, compiles its value and body, and binds the variable.
- **Lam**: Allocates memory for a `Lam` term, binds the variable, and compiles the body.
- **App**: Allocates memory for an `App` term and compiles its function and argument.
- **Sup**: Allocates memory for a `Sup` term and compiles its two subterms.
- **Dup**: Allocates memory for a `Dup` term, binds the duplicated variables, and compiles the value and body.
- **Ctr**: Allocates memory for a constructor term and compiles its fields.
- **Mat**: Allocates memory for a `Mat` term, compiles its value and case branches, and applies moved values.
- **U32**: Returns a new `W32` term with the given value.
- **Chr**: Returns a new `CHR` term with the given character value.
- **Op2**: Allocates memory for a binary operation term and compiles its operands.
- **Ref**: Allocates memory for a reference term and compiles its arguments.

The function uses `alloc_node` to allocate memory for new terms and `set` to write terms to specific memory locations. It also uses `bind` to associate variable names with their corresponding terms. The resulting C code is emitted as a string, which is then integrated into the larger compilation process.

Overall, `compileFullCore` plays a crucial role in the HVM3 compilation pipeline, ensuring that high-level `Core` terms are efficiently translated into low-level C code that can be executed by the runtime. Its recursive nature and handling of various term types make it a versatile and essential component of the codebase.
# compileFullVar
The `compileFullVar` function is a specialized component of the HVM3 codebase's compilation pipeline, designed to handle the compilation of variables in the full compilation mode. Its primary role is to translate a variable name (`var`) from the high-level `Core` representation into low-level C code, ensuring that the variable is correctly managed within the runtime's memory model and parallel execution framework.

The function operates within the `Compile` monad, which is used to manage the state and side effects of the compilation process. This monadic context allows `compileFullVar` to interact with other compilation components, such as the `Book` data structure, which stores function definitions and metadata, and the memory management functions like `allocNode` and `set`.

When `compileFullVar` is called, it takes the variable name (`var`) and the host context (`host`) as inputs. The host context likely provides information about the environment in which the variable is being compiled, such as its scope or any associated metadata. The function then generates the corresponding C code for the variable, ensuring that it is correctly integrated into the runtime's memory model and can be efficiently accessed or manipulated during parallel execution.

In summary, `compileFullVar` plays a crucial role in the HVM3 codebase by ensuring that variables are compiled in a way that supports the runtime's parallel evaluation model, contributing to the overall efficiency and performance of the system.
# compileSlow
The `compileSlow` function is part of the compilation pipeline in the HVM3 codebase, which translates high-level functional programs into low-level C code for execution. Unlike `compileFast`, which optimizes for parallel execution and performance, `compileSlow` takes a more straightforward approach, likely generating simpler and more readable C code. This can be useful for debugging or understanding the compilation process, as it avoids the complexities introduced by aggressive optimizations. The function works by taking a `Book` (which contains all necessary function definitions and metadata), a function ID (`fid`) to identify the specific function being compiled, a `Core` term representing the high-level program, a boolean flag (`copy`) that may control whether the term should be copied during compilation, and a list of arguments (`args`) that provide additional context for the compilation. The output is a sequence of C code instructions that can be executed by the runtime. By providing a "Slow-Mode" compilation option, the HVM3 system ensures flexibility in how programs are compiled, catering to different needs such as performance optimization, debugging, or educational purposes.
# compileWith
The `compileWith` function serves as a generalized compilation mechanism in the HVM3 codebase. It accepts a compilation function (`cmp`) as its first argument, which defines the specific compilation strategy to be used (e.g., full, fast, or slow mode). The `Book` argument provides the necessary function definitions and metadata, while the `fid` (function ID) specifies which function to compile. By abstracting the compilation process, `compileWith` allows the system to reuse the same infrastructure for different compilation modes, reducing code duplication and improving maintainability. This function is crucial for translating high-level `Core` terms into low-level C code, ensuring that the runtime can execute programs efficiently on massively parallel hardware. Its flexibility supports various evaluation strategies, enabling the system to optimize for different performance and resource usage scenarios.
# consume
The `consume` function is defined as `consume :: String -> ParserM String`, where `ParserM` is a monadic parser type. The function first calls `skip`, which is likely a utility function to skip any whitespace or irrelevant characters in the input stream. After skipping, it attempts to match and consume the provided string (`str`) using the `string` function, which is a standard parsing function that matches the exact sequence of characters in the input.

The `consume` function is used extensively throughout the parsing logic in `hvm.hs` to handle specific tokens or symbols in the input. For example, it is used to consume symbols like `*`, `Î»`, `(`, `)`, `{`, `}`, `@`, `#`, and others, which are part of the syntax of the language being parsed. By using `consume`, the parser ensures that these symbols are correctly recognized and processed, allowing the parser to proceed with parsing the next part of the input.

In summary, the `consume` function plays a crucial role in the parsing process by ensuring that specific tokens or symbols are correctly consumed from the input stream, enabling the parser to correctly interpret and process the input according to the language's syntax.
# cont
The `cont` function in the HVM3 codebase serves as a continuation mechanism for term reduction. It is used to handle the next step in the reduction process after a specific reduction rule has been applied. The function takes two arguments: `host`, which represents the current state or context of the reduction, and `action`, which is the next reduction step to be performed. By using `cont`, the code ensures that the reduction process is modular and that each reduction rule can be applied in a consistent manner. This approach simplifies the reduction logic and makes it easier to manage complex term transformations. The `cont` function is particularly important in the context of parallel execution, where it helps to coordinate the reduction of multiple terms simultaneously, ensuring that the system remains efficient and scalable.
# coreToString
The `coreToString` function takes a `Core` term as input and returns a string that represents the term in a readable format. The function handles various types of `Core` terms, including `Lam`, `App`, `Sup`, `Dup`, `Ref`, `Ctr`, `Mat`, `Op2`, and `Let`, by recursively converting each component into a string and combining them appropriately. For example:
- A `Lam` term is converted into a string that represents a lambda abstraction, e.g., `Î»x body`.
- An `App` term is converted into a string that represents function application, e.g., `(f x)`.
- A `Sup` term is converted into a string that represents a superposition, e.g., `&label{term1 term2}`.
- A `Dup` term is converted into a string that represents a duplication operation, e.g., `! &label{dp0 dp1} = value\nbody`.

The function is used in several places within the codebase, such as in debugging output (`putStrLn $ coreToString core`) and in error messages, to provide developers with a clear view of the `Core` terms being processed. This is especially valuable in a parallel, functional runtime like HVM3, where understanding the structure of terms is crucial for diagnosing issues and optimizing performance.
# createBook
The `createBook` function serves as the bridge between the parsed program and the runtime environment. It takes the parsed definitions (`defs`), which include function names, their associated metadata, and their `Core` representations, and combines them with mappings from constructor names to constructor IDs (`ctrToCid`) and arities (`ctrToAri`). This combination allows the `Book` data structure to provide quick access to function definitions and metadata during compilation and execution.

The `Book` data structure is vital for the runtime's efficiency, as it enables the system to quickly look up function IDs, names, labels, and constructors. This quick access is essential for the parallel execution model of HVM3, where efficient management of runtime resources is critical for performance. By organizing and storing this information in a structured manner, `createBook` ensures that the runtime can efficiently handle complex, parallel computations.

In summary, `createBook` plays a key role in initializing the runtime environment by constructing the `Book` data structure, which is essential for the efficient compilation and execution of programs in the HVM3 system.
# doCollapseAt
The `doCollapseAt` function is a critical part of the HVM3 runtime system, specifically designed to handle the collapsing of parallel computations. In the context of the HVM3 codebase, which is built around the Interaction Combinator model for parallel evaluation, `doCollapseAt` ensures that multiple parallel computations are correctly reduced and combined into a single result or a list of results.

The function operates within the `HVM` monad, which manages the state and effects of the runtime system. It takes three parameters:
1. `reduceAt`: A function that performs reduction operations on terms, ensuring that they are evaluated to their normal form.
2. `book`: A data structure that stores function definitions and metadata, providing the necessary information for the reduction process.
3. `host`: A memory location where the term to be collapsed is stored.

The `doCollapseAt` function returns a `Collapse Core`, which represents the result of the collapsing process. This result can then be further processed by other functions, such as `doCollapseFlatAt`, which flattens the `Collapse Core` into a list of `Core` terms for easier manipulation and use.

In summary, `doCollapseAt` is essential for managing the outcomes of parallel computations in the HVM3 runtime system. It ensures that parallel evaluations are correctly reduced and combined, enabling the efficient execution of complex, parallel programs on modern hardware.
# doCollapseFlatAt
The `doCollapseFlatAt` function is a specialized function within the HVM3 codebase that manages the collapsing of terms in parallel computations. Its primary purpose is to evaluate multiple possible outcomes or states and reduce them to a single value or a list of results. This is particularly important in the `Collapse` and `Search` modes, where parallel evaluation is crucial for achieving high performance on massively parallel hardware.

The function operates by taking three main arguments:
1. `reduceAt`: A function that performs the actual reduction of terms.
2. `book`: A data structure that stores function definitions and metadata, providing quick access to the necessary information for compilation and execution.
3. `host`: A location in memory where the term to be collapsed is stored.

The function returns a list of `Core` terms, which represent the collapsed results. This output is essential for the normalization process of the main term, ensuring that the program is fully evaluated and ready for execution.

In the `cliRun` function, `doCollapseFlatAt` is used to normalize the main term, which is a critical step in the execution of the program. It is also used in the `reduceRefAt_LogF` function to extract and log terms, demonstrating its versatility in handling different types of parallel computations.

Overall, `doCollapseFlatAt` is a vital component of the HVM3 runtime system, enabling efficient and effective parallel evaluation of terms, which is essential for achieving high performance on modern hardware.
# doExtractCoreAt
The `doExtractCoreAt` function plays a critical role in the HVM3 codebase by enabling the extraction of high-level `Core` terms from specific memory locations. This is essential for tasks such as debugging, logging, and dynamic term evaluation, where the runtime needs to inspect or manipulate terms at a higher level of abstraction. The function takes three parameters: `reduceAt`, which is a function used to reduce terms to their normal form; `book`, which contains function definitions and metadata; and `loc`, which specifies the memory location of the term to be extracted.

When invoked, `doExtractCoreAt` uses the `reduceAt` function to reduce the term at the given location to its normal form. This ensures that the term is fully evaluated before extraction. Once the term is reduced, it is converted into a `Core` representation, which is a high-level data structure that can be easily manipulated and analyzed. This conversion process allows the runtime to bridge the gap between low-level memory operations and high-level term manipulation, providing a powerful tool for inspecting and interacting with the computational graph.

For example, in the `cliRun` function, `doExtractCoreAt` is used to extract the `Core` representation of the main term after normalization, allowing the system to inspect the result of the computation. Similarly, in the `reduceRefAt_LogF` function, `doExtractCoreAt` is used to extract and log a message term, providing valuable debugging information. Overall, `doExtractCoreAt` is a key component of the HVM3 runtime, enabling high-level term manipulation and inspection in a parallel, functional execution environment.
# doInjectCoreAt
The `doInjectCoreAt` function plays a pivotal role in the HVM3 runtime by facilitating the injection of `Core` terms into the runtime's memory model. This is essential for both the initialization of the computation (e.g., starting from the `main` function) and the dynamic evaluation of function calls during the reduction process.

When `doInjectCoreAt` is called, it takes the following steps:
1. **Argument Binding**: The `argList` parameter provides a list of arguments that need to be bound to the `Core` term. These arguments are typically the evaluated terms of the function's parameters.
2. **Term Injection**: The `Core` term is injected into the runtime at the specified `Loc`. This involves allocating memory for the term and setting its values in the runtime's memory model.
3. **Return the Injected Term**: The function returns the `Term` representing the injected term, which can then be further reduced or evaluated by the runtime.

This function is particularly important in the context of the Interaction Combinator model, where terms are represented as nodes in a computational graph. By injecting terms into the runtime, `doInjectCoreAt` ensures that the graph is correctly updated, enabling parallel evaluation and reduction to proceed efficiently.

In summary, `doInjectCoreAt` is a key mechanism for dynamically updating the runtime's state during computation, ensuring that terms are correctly evaluated and reduced in a parallel and efficient manner.
# doLiftDups
The `doLiftDups` function is a utility in the HVM3 codebase designed to process `Core` terms by lifting duplication (`DUP`) operations. Duplication is a key concept in the Interaction Combinator model, enabling parallel evaluation by creating multiple copies of a term for simultaneous processing. The function is used in several critical parts of the codebase:

1. **Term Extraction (`doExtractCoreAt`)**: When extracting a `Core` term from a memory location, `doLiftDups` is applied to ensure that any `DUP` operations in the term are properly lifted and optimized. This prepares the term for further processing or evaluation.

2. **Normalization (`cliRun`)**: During the normalization of the main term, `doLiftDups` is used to process the extracted `Core` term, ensuring that duplication operations are correctly handled before the term is reduced to its normal form.

3. **Debugging (`reduceRefAt_DupF` and `reduceRefAt_LogF`)**: In debugging contexts, `doLiftDups` is applied to `Core` terms to provide a readable and optimized representation of the term, making it easier to diagnose issues related to duplication operations.

By lifting `DUP` operations, `doLiftDups` ensures that the runtime can efficiently manage and execute parallel computations, aligning with the HVM3's goal of high-performance parallel evaluation. This function is a crucial part of the compilation and execution pipeline, enabling the system to handle complex, parallel computations effectively.
# doParseBook
The `doParseBook` function takes a `String` as input, which represents the contents of a file containing the program's definitions and metadata. It uses a parser (`parseBookWithState`) to convert this string into a `Book` data structure. The parser operates within a `ParserState` context, which manages the state of the parsing process, including any necessary mappings or counters. Once the parsing is complete, the function returns an `IO Book`, which is a monadic action that, when executed, produces the `Book` object.

This function is invoked in the `cliRun` function, which is the entry point for running the HVM3 runtime. After initializing the HVM runtime (`hvmInit`), `cliRun` reads the input file and passes its contents to `doParseBook`. The resulting `Book` object is then used throughout the runtime to access function definitions, metadata, and other resources necessary for compilation and execution.

In summary, `doParseBook` plays a crucial role in the HVM3 codebase by transforming raw program definitions into a structured format that the runtime can efficiently use, thereby enabling the execution of complex, parallel computations.
# doParseCore
The `doParseCore` function takes a `String` as input, which represents the source code of the program. It then uses a parser combinator (`runParser`) to parse this string into a `Core` term. The `parseCore` function is likely a custom parser that understands the syntax of the language and constructs the corresponding `Core` term. The `ParserState` is used to manage the state of the parsing process, including any necessary metadata or context.

Once the parsing is complete, the function returns the `Core` term wrapped in an `IO` monad, indicating that the parsing process may involve side effects, such as reading from a file or handling errors. This `Core` term is then passed to the next stages of the compilation process, where it will be translated into low-level C code for execution by the runtime.

In summary, `doParseCore` plays a pivotal role in the HVM3 codebase by bridging the gap between the textual representation of a program and its internal, structured form. This allows the subsequent stages of the compiler to operate on a well-defined and semantically rich representation of the program, facilitating efficient compilation and execution.
# dumpHeap
The `dumpHeap` function operates in the `HVM` monad, which is the computational context for the runtime. It first retrieves the current length of the heap using `getLen` and the current iteration count using `getItr`. It then calls `dumpHeapRange` with the starting address `0` and the heap length. The `dumpHeapRange` function recursively iterates over the memory range, using `got` to fetch the term at each address and accumulating the results in a list. Finally, `dumpHeap` returns a tuple containing the list of memory address-term pairs and the heap length. This output can be used to analyze the state of the heap, identify potential issues, or verify the correctness of the computation.
# dumpHeapRange
The `dumpHeapRange` function serves as a diagnostic tool within the HVM3 runtime system. Its primary purpose is to provide visibility into the contents of the heap, which is a critical component of the runtime's memory model. By extracting and returning a range of terms from the heap, `dumpHeapRange` enables developers to inspect the state of the computation at any given point in time.

The function works by iterating over a specified range of memory addresses, retrieving the terms stored at those addresses, and returning them as a list of tuples. Each tuple contains the memory address and the corresponding term, allowing developers to see both where the term is stored and what it represents. This is particularly useful for debugging, as it allows developers to trace the flow of data through the heap and identify any anomalies or unexpected behavior.

The recursive nature of `dumpHeapRange` ensures that it can handle ranges of arbitrary size, making it a flexible tool for inspecting different portions of the heap. When combined with the `dumpHeap` function, which retrieves the entire heap, `dumpHeapRange` provides a comprehensive view of the runtime's memory state. This can be invaluable for diagnosing issues, optimizing performance, or simply understanding how the runtime is managing memory during execution.

In summary, `dumpHeapRange` is a key utility for debugging and diagnostics in the HVM3 codebase, offering developers the ability to inspect the heap and gain insights into the runtime's behavior. Its role is primarily supportive, aiding in the development and maintenance of the runtime system by providing detailed information about the state of the computation.
# emit
The `emit` function plays a crucial role in the compilation process by facilitating the generation of C code from high-level `Core` terms. It is used extensively in functions like `compileFull`, `compileFast`, and `compileSlow` to emit C code that corresponds to various constructs in the `Core` language, such as function definitions, term allocations, and reduction rules. The function ensures that the generated code is properly indented by using the `tabs` field of the compilation state, which tracks the current level of indentation. This indentation is important for readability and correctness of the generated C code. By appending the emitted line to the `code` field, `emit` builds up the final C code that will be executed by the runtime. Overall, `emit` is a key utility that bridges the gap between high-level functional constructs and low-level C code, enabling the efficient execution of programs on massively parallel hardware.
# emptyState
The `emptyState` symbol is a crucial part of the HVM3 codebase's state management system. It provides a default, empty configuration for the `InjectState` data structure, which is used during the injection of `Core` terms into the runtime. The `InjectState` likely contains metadata or context necessary for the injection process, such as mappings of arguments or other runtime information. By starting with `emptyState`, the system ensures that the injection process begins with a clean, predictable state, avoiding any unintended side effects from previous operations. This is particularly important in a parallel, functional runtime like HVM3, where state management must be precise to ensure correct and efficient execution. The `emptyState` is then updated with the provided `argList` in the `doInjectCoreAt` function, allowing the injection process to proceed with the necessary context.
# extend
The `extend` function is used within the `lexify` function to ensure that each variable in a given scope is uniquely named. This is crucial for avoiding name conflicts, especially in nested scopes or when variables are shadowed. The function works by taking an old variable name, a new unique name, and a context (a map of existing variable names to their unique counterparts). It then updates the context by inserting the new mapping, unless the old variable name starts with '$', in which case it leaves the context unchanged. This special handling of '$' prefixed variables allows for certain variables to remain unaltered, which can be useful for specific use cases or conventions within the codebase. The `extend` function is called in various parts of the `lexify` function, such as when processing `Let`, `Lam`, `Dup`, and `Mat` constructs, ensuring that all variables within these constructs are uniquely named and correctly mapped in the context.
# extractCoreAt
The `extractCoreAt` function plays a pivotal role in the HVM3 compilation pipeline. Its primary purpose is to convert low-level `Term` nodes, which represent the computational graph in the runtime, into high-level `Core` terms, which are more abstract and suitable for further processing or optimization. This conversion is essential for translating the Interaction Combinator-based runtime model into a form that can be compiled into efficient C code.

The function takes four parameters:
1. `dupsRef`: An `IORef IS.IntSet` used to track locations of duplicated terms, preventing infinite recursion or redundant work.
2. `reduceAt`: A `ReduceAt` function that specifies how to reduce terms during extraction.
3. `book`: A `Book` data structure containing function definitions and metadata.
4. `host`: A `Loc` (location) indicating the starting point in the computational graph.

For each term type, `extractCoreAt` performs specific operations:
- For `LET`, it extracts the value and body of the let-binding, constructing a `Let` node in the `Core` representation.
- For `LAM`, it extracts the body of the lambda abstraction, constructing a `Lam` node.
- For `APP`, it extracts the function and argument, constructing an `App` node.
- For `SUP`, it extracts the two superposed terms, constructing a `Sup` node.
- For `VAR`, it handles variable references, either returning a `Var` node or recursively extracting the referenced term.
- For `DP0` and `DP1`, it manages duplication, ensuring that shared terms are handled correctly.
- For `CTR`, it extracts the constructor arguments, constructing a `Ctr` node.
- For `MAT`, it extracts the value and case branches, constructing a `Mat` node.
- For `OPX` and `OPY`, it extracts the operands, constructing an `Op2` node.
- For `REF`, it extracts the function arguments, constructing a `Ref` node.

The function uses `unsafeInterleaveIO` to enable lazy evaluation, which is crucial for handling large or infinite computations efficiently. By recursively traversing the computational graph and reconstructing `Core` terms, `extractCoreAt` ensures that the high-level structure of the program is preserved during the compilation process, enabling further optimizations and transformations.
# extractExpectedTokens
The `extractExpectedTokens` function plays a crucial role in the error handling mechanism of the HVM3 codebase. When parsing input (e.g., source code or configuration files), if the parser encounters an unexpected token or syntax, it generates a `ParseError`. This error contains information about the location of the error and the tokens that were expected at that point. The `extractExpectedTokens` function processes this `ParseError` to extract and format the expected tokens into a human-readable string.

This string is then used by the `showParseError` function to construct a comprehensive error message, which includes the file name, input, error position (line and column), and the expected tokens. This detailed error message is invaluable for debugging, as it helps developers quickly identify and fix syntax errors in their code.

In summary, `extractExpectedTokens` is a helper function that enhances the usability of the HVM3 codebase by providing clear and actionable error messages during the parsing phase, thereby improving the development experience.
# flatten
The `flatten` function serves a critical role in the HVM3 codebase by transforming the `Collapse` monad into a flat list of results. The `Collapse` monad is used to handle parallel computations, where multiple outcomes or states may exist. By flattening this structure, `flatten` allows the system to process and combine these outcomes into a single, manageable list. This is essential for operations that require the aggregation of results from parallel computations, such as reducing multiple possible states to a single result or collecting all possible outcomes for further processing.

The function is implemented using `flattenBFS`, which employs a breadth-first search strategy to traverse the `Collapse` structure. This ensures that all possible outcomes are explored and collected in a systematic and efficient manner. The use of breadth-first search is particularly advantageous in a parallel execution context, as it helps to evenly distribute the workload and avoid potential bottlenecks that could arise from depth-first traversal.

In the context of the HVM3 codebase, `flatten` is used in functions like `doCollapseFlatAt`, where it helps to process the results of parallel computations and prepare them for further evaluation or output. This makes `flatten` a key component in the system's ability to handle complex, parallel computations efficiently, leveraging the Interaction Combinator model to achieve high performance on modern hardware.
# flattenBFS
The `flattenBFS` function plays a crucial role in the HVM3 codebase by converting a `Collapse` monad, which represents a parallel computation with multiple possible outcomes, into a flat list of results. This is particularly important in a parallel runtime system like HVM3, where computations can branch into multiple parallel paths. By using a breadth-first search (BFS) approach, `flattenBFS` ensures that the results are collected in a level-by-level manner, which can be beneficial for certain parallel evaluation strategies.

The function works by recursively processing the `Collapse` structure using a queue (`SQ`), which is a data structure that supports efficient enqueue and dequeue operations. This allows `flattenBFS` to traverse the `Collapse` structure in a BFS manner, ensuring that all possible outcomes are collected in the correct order. The resulting list can then be used for further processing or output.

The fact that `flattenBFS` is aliased as `flatten` suggests that it is the default or preferred method for flattening `Collapse` structures in the codebase. This makes it a key utility function for managing parallel computations and extracting their results in a structured way.
# flattenDFS
The `flattenDFS` function plays a critical role in the HVM3 codebase by simplifying the management of parallel computations. In the context of the Interaction Combinator model, where terms can be evaluated in parallel, the `Collapse` monad represents multiple possible outcomes or states. The `flattenDFS` function traverses this structure in a depth-first manner, collecting all values into a single list.

For example, if a computation results in a superposition of two terms (`CSup`), `flattenDFS` will recursively flatten both terms and combine their results. If the computation yields a single value (`CVal`), it will return a list containing that value. If the computation is empty (`CEra`), it will return an empty list.

This functionality is particularly useful for debugging, analysis, or further processing of parallel computations, as it converts a potentially complex, nested structure into a straightforward list. By doing so, `flattenDFS` helps maintain the efficiency and clarity of the HVM3 runtime system, ensuring that parallel computations can be managed and understood effectively.
# flattenPQ
The `flattenPQ` function is crucial for handling parallel computations in the HVM3 runtime. The `Collapse` monad represents multiple possible outcomes or states of a computation, and `flattenPQ` is used to reduce these multiple outcomes into a single list. This is particularly useful when the runtime needs to evaluate multiple parallel branches of computation and then combine their results.

The function works by recursively traversing the `Collapse` structure, using a priority queue (`PQ`) to manage the order of traversal. The `PQLeaf` is used as the initial state of the priority queue, and the `go` function performs the actual traversal and collection of results. By flattening the `Collapse` structure into a list, `flattenPQ` enables the runtime to handle and process the results of parallel computations in a straightforward and efficient manner.

In summary, `flattenPQ` plays a key role in the parallel execution model of HVM3 by converting the complex, multi-branched `Collapse` structure into a simple list of results, which can then be further processed or combined as needed.
# fmap
In the context of the HVM3 codebase, `fmap` is used to apply a function to the values contained within the `Collapse` monad. The `Collapse` monad can hold different types of values: `CVal` for a single value, `CSup` for a superposition of two values, and `CEra` for an erased value. The `fmap` function handles each case appropriately:
- For `CVal v`, it applies the function `f` directly to the value `v`, resulting in `CVal (f v)`.
- For `CSup k x y`, it recursively applies `fmap f` to both `x` and `y`, resulting in `CSup k (fmap f x) (fmap f y)`.
- For `CEra`, it returns `CEra` unchanged, as there is no value to apply the function to.

This implementation ensures that the function `f` is applied uniformly across all possible values within the `Collapse` monad, maintaining the structure and semantics of parallel computations. This is crucial for the correct and efficient execution of parallel tasks in the HVM3 runtime, where the `Collapse` monad plays a key role in managing and reducing parallel computations.
# fork
The `fork` function is defined within the `bind` function and is used to process `Collapse` computations, particularly when dealing with `CSup` terms. Hereâ€™s a breakdown of its behavior:

1. **Handling `CEra`**: If the input is `CEra` (an empty computation), `fork` simply returns `CEra`, as there is nothing to process.

2. **Handling `CVal`**: If the input is `CVal v` (a value), `fork` applies the continuation function `f` to the value `v` and updates the `paths` map by applying the transformation `E` (empty) to all paths. This ensures that the value is passed through the computation pipeline correctly.

3. **Handling `CSup`**: If the input is `CSup k x y` (a superposed term), `fork` recursively processes the left (`x`) and right (`y`) branches. It updates the `paths` map for each branch:
   - For the left branch (`x`), it uses `putO` to mark the path as the "left" choice.
   - For the right branch (`y`), it uses `putI` to mark the path as the "right" choice.
   This ensures that the parallel computations are tracked and combined correctly.

The `fork` function is essential for managing the parallel evaluation of terms within the `Collapse` monad, ensuring that the results of parallel computations are correctly reduced and combined. It plays a critical role in the system's ability to handle complex, parallel computations efficiently.
# fresh
1. **Compilation Context (Haskell Frontend)**:
   - In `hvm.hs`, the `fresh` function is used extensively during the compilation process to generate unique names for variables, terms, and intermediate values. This is crucial for avoiding name collisions in lexically scoped environments. For example, when compiling constructs like `Let`, `Lam`, `App`, `Sup`, and `Dup`, `fresh` is called to create unique names for variables and intermediate terms. This ensures that each variable or term has a distinct identifier, preventing ambiguity during execution.
   - The `fresh` function is also used in the `lexify` function, which renames variables to ensure uniqueness across nested scopes. This is particularly important for maintaining the correctness of the program during compilation.

2. **Runtime Context (C Backend)**:
   - In `hvm.c`, the `fresh` function is a runtime utility that generates unique labels for duplication operations (`Dup`). These labels are used to manage parallel computations in the Interaction Combinator model. The `fresh` function increments a global counter (`frsh`) each time it is called, ensuring that each label is unique. This is essential for correctly handling parallel reductions and avoiding conflicts in the computational graph.
   - The `fresh` function is also used in the `reduceRefAt_FreshF` function, which handles the `@FRESH` primitive. This primitive is used to generate fresh labels during runtime, supporting the dynamic creation of parallel computations.

In summary, the `fresh` symbol plays a critical role in both the compilation and runtime phases of the HVM3 system. During compilation, it ensures unique variable names, while during runtime, it generates unique labels for parallel computations, enabling the efficient execution of programs on massively parallel hardware.
# genFreshLabel
The `genFreshLabel` function is defined in the Haskell frontend (`hvm.hs`) and is used within the parser to generate unique labels for terms or constructs that require them. In the provided context, `genFreshLabel` is called in two scenarios:
1. When parsing a construct that uses the `&` symbol, and no name is provided, a fresh label is generated to uniquely identify the term.
2. Similarly, when parsing another `&` construct with a specific structure, a fresh label is generated if no name is provided.

The function ensures that each label is unique, which is essential for the runtime to correctly manage and process terms. Unique labels prevent conflicts and ambiguities in the computational graph, enabling the system to efficiently handle parallel execution and term reduction. The use of `Word64` as the label type ensures a large enough namespace to avoid label collisions, even in complex and large-scale computations.

Overall, `genFreshLabel` plays a critical role in maintaining the integrity and correctness of the HVM3 runtime by providing unique identifiers for terms during the parsing phase.
# genMain
The `genMain` function is defined in the Haskell frontend (`hvm.hs`) and is used during the compilation process to generate the main C function for the compiled program. This main C function is essential because it acts as the entry point for the program when it is executed by the C backend. The function takes a `Book` data structure as its input, which contains all the necessary information about the functions, their IDs, labels, and other metadata required for execution.

When `genMain` is called, it constructs the main C function by combining the runtime initialization code with the compiled functions generated from the `Book`. The resulting C code includes the necessary setup for the runtime environment, such as initializing memory and data structures, and then proceeds to call the compiled functions in the correct order to execute the program.

The `genMain` function is invoked within the `cliRun` function, which is responsible for handling the command-line interface and orchestrating the compilation and execution process. After parsing the input file and compiling the individual functions, `cliRun` calls `genMain` to generate the main C function, which is then combined with the runtime code and the compiled functions to produce the final C program.

In summary, `genMain` plays a crucial role in the HVM3 codebase by generating the main C function that serves as the entry point for the compiled program. It ensures that the program can be executed by the C backend, leveraging the Interaction Combinator model for efficient parallel computation.
# genName
The `genName` function plays a critical role in the compilation process of the HVM3 codebase. It is used in various contexts, such as when handling variables (`Var`), lambda bindings (`Lam`), let bindings (`Let`), and duplication operations (`Dup`). In each of these cases, `genName` ensures that the names of variables or bindings are unique, which is essential for the correct execution of the program.

The function works by:
1. Reading a reference (`namesRef`) that contains a map of existing names.
2. Checking if the requested name already exists in the map.
   - If it exists, the function returns the mapped name.
   - If it does not exist, the function generates a new unique name using `genNameFromIndex`.
3. The `genNameFromIndex` function creates a new name based on an index derived from the size of the map, ensuring that the name is unique.

This process is crucial for avoiding name conflicts in the generated code, especially in a parallel execution environment where multiple terms may be evaluated simultaneously. By ensuring unique names, `genName` helps maintain the integrity of the computational graph and supports the efficient execution of programs in the HVM3 runtime.
# genNameFromIndex
The `genNameFromIndex` function is designed to generate unique names for terms or variables in the HVM3 codebase. It operates by taking an integer index (`n`) and recursively constructing a name string. The function uses a helper function `go` to build the name incrementally. The index is incremented by 1 to ensure that the generated names start from a non-zero base, which is a common practice to avoid potential issues with zero-based indexing.

This function is crucial in scenarios where unique identifiers are needed, such as during the compilation process or when managing function definitions in the `Book` data structure. By generating unique names, `genNameFromIndex` helps prevent naming conflicts and ensures that each term or variable can be uniquely identified and referenced within the runtime system.

The function is called within the `genName` function, which is responsible for either retrieving an existing name from a map or generating a new one if it doesn't already exist. This mechanism is essential for maintaining the integrity of the codebase's symbol table and ensuring that all terms and variables are correctly managed during compilation and execution.
# getItr
The `getItr` function serves as a bridge between the Haskell frontend and the C backend of the HVM3 runtime. Its primary purpose is to fetch the count of interactions (reduction steps) that have been performed by the runtime. This count is a critical metric for understanding the computational intensity of the program being executed. In the `cliRun` function, `getItr` is used to display performance statistics, such as the total number of interactions, execution time, and performance in MIPS (Millions of Instructions Per Second). Similarly, in `dumpHeap`, it is used to provide diagnostic information about the state of the runtime, including the number of interactions and the size of the heap. By exposing this low-level runtime information to the Haskell layer, `getItr` enables developers to monitor and optimize the performance of their programs within the HVM3 system.
# getLen
The `getLen` function serves as a bridge between the Haskell frontend and the C backend, allowing the Haskell code to query the runtime's memory state. In the C backend, `get_len` is implemented to return the current length of the heap, which is a measure of the number of nodes allocated in memory. This information is used in several contexts within the Haskell code:

1. **Debugging and Statistics**: In the `cliRun` function, `getLen` is called to retrieve the heap size when displaying runtime statistics. This helps developers understand the memory footprint of the computation and optimize performance.

2. **Heap Inspection**: In the `dumpHeap` function, `getLen` is used to determine the size of the heap before dumping its contents. This is useful for debugging and analyzing the state of the runtime's memory.

3. **Runtime Monitoring**: In the `genMain` function, `getLen` is embedded in the generated C code to print the heap size after the computation completes. This provides a summary of the memory usage for the executed program.

Overall, `getLen` plays a key role in monitoring and managing the runtime's memory, ensuring efficient execution and providing valuable insights for debugging and optimization.
# get_itr
The `get_itr` function serves as a critical tool for performance analysis within the HVM3 codebase. It is called in several contexts:
1. **Performance Statistics**: In the `genMain` function, `get_itr` is used to print the total number of interactions (`WORK`) that occurred during the program's execution. This metric helps developers understand the computational intensity of their programs.
2. **Debugging and Diagnostics**: In the `dumpHeap` function, `get_itr` is used alongside `getLen` to provide a snapshot of the runtime state, including the number of interactions and the heap size. This information is useful for debugging and optimizing the runtime behavior.
3. **Foreign Function Interface**: The function is imported from the C backend using the `foreign import ccall` mechanism, indicating that it is implemented in C and exposed to the Haskell frontend for use in high-level operations.

The `get_itr` function is essential for evaluating the efficiency of the Interaction Combinator model, as it quantifies the number of reduction steps or interactions performed by the runtime. This metric is particularly valuable in a parallel execution environment, where understanding the workload distribution and computational overhead is crucial for optimizing performance.
# get_len
The `get_len` function serves as a bridge between the Haskell frontend and the C backend, allowing the Haskell code to query the runtime's memory state. In the C backend, `get_len` is implemented to return the current length of the heap, which is a measure of the number of nodes allocated in the runtime's memory model. This information is essential for understanding the runtime's behavior, particularly in a massively parallel execution environment where efficient memory management is critical.

In the Haskell frontend, `get_len` is used in several contexts:
1. **Statistics Generation**: When `showStats` is enabled, `get_len` is called to retrieve the heap size, which is then displayed alongside other runtime metrics such as the number of interactions and execution time. This helps developers assess the performance and resource usage of the program.
2. **Heap Dumping**: In the `dumpHeap` function, `get_len` is used to determine the size of the heap before dumping its contents. This is useful for debugging and inspecting the state of the computational graph during execution.
3. **Main Function Generation**: In the `genMain` function, `get_len` is included in the generated C code to print the heap size after the program's execution. This provides a summary of the memory usage at the end of the program's run.

Overall, `get_len` plays a vital role in monitoring and debugging the runtime's memory usage, ensuring that the system operates efficiently and providing valuable insights into the program's execution.
# go
In the HVM3 codebase, `go` is a common pattern used to implement recursive logic in a modular way. For example:
1. In `flattenBFS` and `flattenPQ`, `go` is used to traverse and flatten a `Collapse` structure, handling cases like `CSup`, `CVal`, and `CEra` recursively.
2. In `lexify`, `go` is used to recursively traverse and rename variables in a `Core` term, ensuring unique names for lexically scoped variables.
3. In `prettyRename`, `go` recursively processes a `Core` term to generate pretty-printed names for variables.

The `go` function is often paired with an accumulator (e.g., a queue or a map) to manage state during recursion. This pattern allows the main function to focus on initialization and finalization, while `go` handles the detailed recursive logic. This modular approach improves code readability and maintainability by separating concerns and encapsulating recursion.
# got
The `got` function serves as a low-level operation to fetch a `Term` from a given memory location (`Loc`). It is used in multiple scenarios:
1. **Term Reduction**: During the reduction process, `got` is frequently called to retrieve subterms that need to be evaluated or manipulated. For example, in the `reduceAt` function, `got` is used to fetch the term at the host location before applying reduction rules.
2. **Memory Management**: Functions like `reduce_ref_sup` and `reduce_dup_lam` use `got` to access terms stored at specific memory addresses, enabling dynamic term manipulation and interaction combinator rules.
3. **Compilation**: In the compilation process, `got` is used to retrieve terms during the translation of high-level `Core` terms into low-level C code. For instance, in `compileFull` and `compileFast`, `got` is used to fetch arguments for function calls.
4. **Parallel Execution**: The `Collapse` monad and `Sup` operation rely on `got` to access terms that are part of parallel computations, ensuring that multiple outcomes or states are correctly managed.

Overall, `got` is a critical function that facilitates efficient access to terms in the runtime's memory, supporting the system's core operations and enabling the parallel execution model of the HVM3 codebase.
# heapToString
The `heapToString` function serves as a utility for visualizing the contents of the heap in the HVM3 runtime. The heap is a critical component of the runtime system, storing `Term` nodes that represent the computational graph. By converting the heap into a string, developers can easily inspect the state of the computation, identify potential issues, and verify that terms are being managed correctly. The function takes a list of tuples, where each tuple contains a memory address (`Word64`) and the corresponding `Term` stored at that address. The `itr` parameter might be used to limit the output to a specific range of memory addresses or to control the level of detail in the string representation. This function is particularly useful during debugging, as it provides a clear and concise view of the heap's contents, aiding in the diagnosis of runtime errors or inefficiencies.
# hvmDefine
In the HVM3 codebase, the `hvmDefine` function plays a pivotal role in the compilation and execution pipeline. When the Haskell frontend compiles a program, it generates C code for each function and compiles it into a shared library. The `hvmDefine` function is then used to register these compiled functions in the runtime. Specifically, it associates a function ID (`fid`) with a function pointer (`func`), which points to the compiled C code. This registration process is essential for the runtime to know which function to call when a specific function ID is encountered during execution. By linking the function IDs to their corresponding compiled code, `hvmDefine` ensures that the runtime can efficiently execute the compiled functions, leveraging the performance benefits of native code execution. This mechanism is crucial for the overall performance and functionality of the HVM3 system, as it enables the runtime to handle complex, parallel computations effectively.
# hvmFree
The `hvmFree` function serves as the cleanup mechanism for the HVM3 runtime. After the main computation is executed, whether in compiled or interpreted mode, `hvmFree` is called to release any dynamically allocated memory, close open resources, and reset the runtime state. This is essential for maintaining the system's performance and stability, especially in a massively parallel environment where memory management is critical. By ensuring that all resources are properly freed, `hvmFree` helps prevent memory leaks and other resource-related issues that could degrade the system's performance over time. The function is part of the runtime's lifecycle management, complementing `hvmInit`, which initializes the runtime, and `hvmFree`, which finalizes it.
# hvmGetState
The `hvmGetState` function serves as a bridge between the Haskell frontend and the C backend, allowing the Haskell code to access the runtime state managed by the C code. In the context of the `cliRun` function, `hvmGetState` is called after loading a dynamically compiled shared library (`bookLib`) and registering compiled functions. The retrieved state (`hvmGotState`) is then used to link the compiled state, ensuring that the runtime is correctly initialized and ready for execution. This function is essential for maintaining the integrity and continuity of the runtime state across different phases of the compilation and execution process.
# hvmInit
The `hvmInit` function serves as the initialization routine for the HVM runtime system. When invoked, it prepares the runtime environment, ensuring that all necessary data structures and memory models are set up correctly. This includes initializing the memory management system, setting up the `Book` data structure for function definitions, and preparing the runtime state for parallel execution. The function is called at the start of the `cliRun` function in the Haskell frontend, which orchestrates the execution of the HVM. Additionally, the `genMain` function generates C code that includes a call to `hvm_init()`, ensuring that the runtime is properly initialized before any computation begins. This initialization step is critical for the correct and efficient execution of programs within the HVM, as it lays the groundwork for the parallel evaluation model and memory management system.
# hvmSetState
The `hvmSetState` function plays a pivotal role in the HVM3 runtime by allowing the Haskell frontend to update the internal state of the C backend. This is particularly important during the compilation process, where the runtime state needs to be transferred from the Haskell environment to the compiled C code. The function is called after the C code is compiled into a shared library and loaded into memory. By setting the state, the runtime ensures that all necessary data, such as function definitions, memory allocations, and term representations, are correctly initialized and available for execution. This synchronization is essential for maintaining the integrity and consistency of the runtime, enabling seamless execution of parallel computations and efficient memory management.
# hvm_define
The `hvm_define` function is defined in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). Its primary role is to associate a function ID (`fid`) with a corresponding function pointer (`func`). This association is crucial for the runtime to correctly identify and execute the compiled functions.

During the compilation process, the Haskell frontend generates C code for each function in the `Book` data structure. These functions are compiled into a shared library, which is then loaded into the runtime. The `hvm_define` function is called for each function in the `Book`, registering the function's ID and its corresponding function pointer in the runtime. This allows the runtime to dynamically link and execute these functions as needed during program execution.

In summary, `hvm_define` plays a key role in the dynamic linking and execution of compiled functions within the HVM3 runtime, ensuring that the system can efficiently manage and execute the compiled code.
# hvm_free
The `hvm_free` function serves as the cleanup mechanism for the HVM3 runtime system. Its primary purpose is to release resources allocated during the execution of the program, ensuring that the runtime environment is properly terminated. This includes:
1. **Memory Deallocation**: Freeing memory allocated for nodes, terms, and other runtime structures to prevent memory leaks.
2. **Dynamic Library Release**: If the runtime uses dynamically loaded libraries (e.g., compiled C code), `hvm_free` ensures these libraries are unloaded.
3. **State Reset**: Resetting any global or runtime-specific state to its initial condition, preparing the system for potential subsequent executions.
4. **Resource Cleanup**: Releasing any other system resources (e.g., file handles, network connections) that were acquired during runtime.

In the Haskell frontend, `hvm_free` is called at the end of the `cliRun` function, which orchestrates the execution of the program. This ensures that cleanup occurs regardless of whether the execution was successful or encountered errors. Similarly, in the C backend, `hvm_free` is implemented to handle the low-level details of resource deallocation and state resetting.

By ensuring proper cleanup, `hvm_free` plays a vital role in maintaining the efficiency and reliability of the HVM3 runtime, especially in a massively parallel execution environment where resource management is critical.
# hvm_get_state
The `hvm_get_state` function plays a crucial role in the HVM runtime by providing access to the runtime's internal state. This state includes information about memory allocation, term reduction progress, and other runtime-specific data. In the context of the `cliRun` function in the Haskell frontend, `hvm_get_state` is used after compiling and loading the dynamic library to link the compiled state with the runtime. This ensures that the runtime can correctly execute the compiled functions and manage the computational graph. By retrieving the state, the runtime can maintain consistency and efficiency during parallel execution, which is a core feature of the HVM system. The function's return type, `Ptr ()`, indicates that it provides a raw pointer to the `State` structure, allowing the Haskell code to interact with the C backend's internal state directly.
# hvm_init
The `hvm_init` function serves as the entry point for initializing the HVM3 runtime. Its primary purpose is to set up the environment required for executing programs efficiently on massively parallel hardware. This includes initializing memory management structures, preparing the Interaction Combinator model, and ensuring that all necessary runtime components are in place. By calling `hvm_init` at the beginning of both the Haskell frontend (`cliRun`) and the C backend (`main`), the codebase ensures that the runtime is fully prepared to handle the parallel evaluation of terms. This initialization step is crucial for the correct and efficient execution of programs, as it lays the groundwork for the subsequent reduction and parallel computation processes. Without `hvm_init`, the runtime would lack the necessary setup to manage memory, handle term reduction, and support parallel execution, leading to potential errors or inefficiencies in the system.
# hvm_set_state
The `hvm_set_state` function is defined in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). Its primary role is to update the runtime's internal state with a new state object, which is typically obtained from the compiled C code. This is crucial when the runtime needs to switch between different states, such as when loading a compiled shared library or resetting the runtime environment.

In the context of the `cliRun` function in `hvm.hs`, `hvm_set_state` is used after the runtime has been initialized and the compiled shared library has been loaded. The function `hvmGetState` retrieves the current state of the runtime, and `hvm_set_state` is then called to update this state with the state from the compiled library. This ensures that the runtime is correctly configured to execute the compiled code, maintaining consistency between the Haskell frontend and the C backend.

Overall, `hvm_set_state` plays a vital role in the seamless integration of the Haskell and C components of the HVM3 system, enabling efficient and correct execution of parallel computations.
# ifLetLab
The `ifLetLab` function plays a crucial role in the compilation and execution of pattern matching in the HVM3 codebase. Specifically, it is used in the context of `Mat` terms, which represent pattern matching constructs. The function takes two arguments: a `Book` (which stores function definitions and metadata) and a `Core` term (representing the pattern match). It checks if the pattern match is in the form of an "if-let" match, which is a simplified pattern match that only handles a single constructor and a default case (represented by `"_"`).

If the pattern match is an "if-let" match, the function looks up the constructor (`ctr`) in the `Book` to retrieve its constructor ID (`cid`). If the constructor is found, the function returns `1 + cid`, which is used as a label in the compiled code. This label helps the runtime system identify and optimize the "if-let" pattern match during execution. If the constructor is not found or the pattern match is not an "if-let" match, the function returns `0`, indicating that no special handling is required.

The `ifLetLab` function is used in several places in the codebase, particularly during the compilation of `Mat` terms (`compileFullCore`, `compileFastCore`, and `injectCore`). It ensures that the "if-let" pattern match is correctly identified and optimized, contributing to the overall efficiency of the runtime system.
# incItr
The `incItr` function serves as a mechanism to count the number of reduction steps executed by the HVM3 runtime. It is called in various reduction functions (e.g., `reduce_ref`, `reduce_let`, `reduce_app_lam`, etc.) to increment the iteration counter each time a reduction operation is performed. This counter can be used for several purposes:
1. **Debugging**: By tracking the number of reductions, developers can monitor the execution flow and identify potential inefficiencies or infinite loops.
2. **Performance Monitoring**: The counter provides insights into the computational complexity of the program, helping to optimize the runtime for better performance.
3. **Execution Control**: In some cases, the counter might be used to limit the number of reductions, ensuring that the program does not run indefinitely or consume excessive resources.

The function is implemented in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`), indicating its importance in the runtime system. In the Haskell code, it is imported as a foreign function from the C runtime, while in the C code, it is defined as a function that increments a global iteration counter. This cross-language integration ensures that the iteration count is consistently maintained across the entire system.
# inc_itr
The `inc_itr` function is a utility used to increment an iteration counter in the HVM3 runtime system. Its primary purpose is to track the number of reduction steps performed during the evaluation of terms. This counter is likely used for several purposes:

1. **Debugging and Diagnostics**: By counting the number of reduction steps, developers can monitor the execution flow and identify potential inefficiencies or infinite loops in the evaluation process.

2. **Performance Monitoring**: The counter can provide insights into the runtime's performance, helping to optimize the reduction engine and parallel execution model.

3. **Execution Control**: In some cases, the counter might be used to limit the number of reduction steps, preventing excessive computation or ensuring that the evaluation terminates within a reasonable time frame.

The function is implemented in C (`hvm.c`) and exposed to the Haskell code (`hvm.hs`) via a foreign function interface (FFI). This design choice ensures that the counter is managed efficiently at the low level, minimizing overhead during the reduction process.

In the C code, `inc_itr` is called in nearly every reduction function, such as `reduce_ref`, `reduce_let`, `reduce_app_lam`, and others. This indicates that it is a fundamental part of the runtime's operation, providing a way to measure and control the evaluation of terms.

Overall, `inc_itr` is a small but essential component of the HVM3 runtime, enabling effective monitoring and management of the reduction process.
# injectCore
The `injectCore` function plays a pivotal role in the HVM3 codebase by translating high-level `Core` terms into low-level runtime terms that the HVM3 runtime can execute. This translation is crucial for the compilation process, as it ensures that the high-level program semantics are correctly represented in the runtime's memory model.

The function operates within the `InjectM` monad, which manages the state and effects during the injection process. It takes three main inputs:
1. **`Book`**: A data structure containing function definitions and metadata, which is used to look up information during the injection process.
2. **`Core`**: The high-level term that needs to be translated into a runtime term.
3. **`Loc`**: The memory location where the runtime term should be stored.

The function handles various `Core` term types, each with specific logic to ensure correct translation. For example:
- **`Era`**: Represents an empty term, which is translated into a runtime term with the `_ERA_` tag.
- **`Var`**: Represents a variable, which is translated into a runtime term with the `_VAR_` tag.
- **`Let`**: Represents a let-binding, which involves allocating memory for the bound value and body, updating the state with the variable binding, and setting the runtime term to represent the let-binding.
- **`Lam`**: Represents a lambda abstraction, which involves allocating memory for the lambda body, updating the state with the variable binding, and setting the runtime term to represent the lambda.
- **`App`**: Represents a function application, which involves allocating memory for the function and argument, injecting them recursively, and setting the runtime term to represent the application.
- **`Sup`**: Represents a superposition, which involves allocating memory for the two terms being superposed, injecting them recursively, and setting the runtime term to represent the superposition.
- **`Dup`**: Represents a duplication, which involves allocating memory for the value and body, updating the state with the duplication bindings, and setting the runtime term to represent the duplication.
- **`Ref`**: Represents a reference to a function, which involves allocating memory for the arguments, injecting them recursively, and setting the runtime term to represent the reference.
- **`Ctr`**: Represents a constructor, which involves allocating memory for the fields, injecting them recursively, and setting the runtime term to represent the constructor.
- **`Mat`**: Represents a pattern match, which involves allocating memory for the value being matched and the case bodies, injecting them recursively, and setting the runtime term to represent the pattern match.
- **`U32`**: Represents a 32-bit unsigned integer, which is translated into a runtime term with the `_W32_` tag.
- **`Chr`**: Represents a character, which is translated into a runtime term with the `_CHR_` tag.
- **`Op2`**: Represents a binary operation, which involves allocating memory for the operands, injecting them recursively, and setting the runtime term to represent the operation.

The `injectCore` function is essential for the compilation process, as it ensures that the high-level `Core` terms are correctly translated into runtime terms that the HVM3 runtime can execute. It preserves the structure and semantics of the high-level terms, enabling efficient parallel execution on massively parallel hardware.
# intoIfLetChain
The `intoIfLetChain` function is used in the `parseMat` function to handle pattern matches that include a default case. When parsing a pattern match, if the last case is a default case (denoted by `_`), the function transforms the list of cases into a nested chain of `if-let` expressions. This transformation ensures that the cases are evaluated in the correct order, with the default case being used as a fallback if none of the other cases match.

The function works recursively:
1. If the list of cases (`css`) is empty, it returns the body of the default case (`defBody`).
2. Otherwise, it constructs an `if-let` expression for the first case in the list, with the rest of the cases being handled by a recursive call to `intoIfLetChain`.

This approach allows for a clear and efficient evaluation of pattern matches, especially in the context of the HVM3 runtime, where pattern matching is a common operation. By transforming the cases into a chain of `if-let` expressions, the function ensures that the pattern match is evaluated in a structured manner, which can be more easily optimized by the runtime.
# labToString
The `labToString` function takes a `Word64` value as input, which typically represents a label or location in the computational graph. It converts this value into a hexadecimal string using the `showHex` function. To ensure consistency and readability, the resulting string is padded to a length of 6 characters with leading zeros using the `padLeft` function. This formatted string is then returned as the output.

In the context of the HVM3 codebase, `labToString` is used within the `termToString` function to convert the label of a `Term` into a string representation. This is part of a broader mechanism for converting terms into human-readable strings, which is essential for debugging and understanding the state of the computation. By providing a standardized format for labels, `labToString` helps ensure that the output is clear and consistent, making it easier for developers to interpret the results of their programs.
# lexify
The `lexify` function is defined in the Haskell frontend (`hvm.hs`) and is used during the creation of the `Book` data structure, which stores function definitions and metadata. Specifically, it is applied to each `Core` term in the `createBook` function to ensure that all lexically scoped variables have unique names. This is particularly important for maintaining the correctness of the program during compilation and execution, as it prevents variable shadowing and ensures that each variable reference is unambiguous.

The function works by recursively traversing the `Core` term and renaming variables that are lexically scoped. It uses a state monad to manage the current naming context and the next available identifier. Variables that start with the `$` symbol are exempt from this renaming process, allowing them to retain their original names. This is useful for special variables or placeholders that need to be treated differently.

For example, given the term `Î»x Î»t (t Î»x(x) x)`, the `lexify` function will rename the variables to `Î»x0 Î»t1 (t1 Î»x2(x2) x0)`, ensuring that each `x` and `t` has a unique identifier based on its scope. This transformation is essential for the correct interpretation and execution of the program, especially in complex or nested functions where variable names might otherwise clash.

In summary, the `lexify` function plays a critical role in the compilation process by ensuring that all lexically scoped variables have unique names, thereby preventing name clashes and ensuring the correctness of the program during execution.
# liftDups
The `liftDups` function operates recursively on `Core` terms, which represent the high-level constructs of the program. For each type of `Core` term (e.g., `Var`, `Ref`, `Lam`, `App`, `Sup`, `Dup`, etc.), `liftDups` performs a specific transformation:
1. For simple terms like `Var`, `Era`, `U32`, and `Chr`, it returns the term unchanged along with the identity function (`id`), as these terms do not involve duplication.
2. For composite terms like `Ref`, `Lam`, `App`, `Sup`, `Ctr`, `Op2`, and `Let`, it recursively applies `liftDups` to their subterms, combining the transformed subterms and their corresponding reconstruction functions.
3. For `Dup` terms, which explicitly handle duplication, `liftDups` transforms the value and body of the duplication, returning the transformed body and a function that reconstructs the original `Dup` term with the transformed value and body.

The function also includes helper functions (`liftDupsList`, `liftDupsMov`, `liftDupsCss`) to handle lists, movement patterns, and case structures, ensuring that all parts of the term are processed correctly. The `doLiftDups` function uses `liftDups` to transform a term and then applies the reconstruction function to ensure the duplication logic is preserved.

Overall, `liftDups` plays a critical role in the HVM3 runtime by managing duplication in a way that supports efficient parallel execution, ensuring that the Interaction Combinator model can operate effectively.
# liftDupsCss
The `liftDupsCss` function is used in the compilation phase of the HVM3 runtime system, specifically when handling pattern matching constructs (`Mat`). Its purpose is to ensure that any duplications (`Dup` operations) within the case branches are lifted to the appropriate level, which is crucial for maintaining the correctness and efficiency of the parallel evaluation model. The function takes a list of case branches as input, where each branch is represented as a tuple `(c, fs, b)` containing a constructor name (`c`), a list of field names (`fs`), and a body term (`b`). It recursively processes each branch, applying the `liftDups` function to the body term to lift any duplications. The function returns a tuple containing the transformed list of case branches and a function that can be used to apply the lifted duplications to other terms. This ensures that the duplications are correctly handled during the compilation process, enabling efficient parallel execution of the resulting code.
# liftDupsList
The `liftDupsList` function is defined to work on a list of `Core` terms, which are the high-level representations of computational constructs in the HVM3 system. The function processes each element in the list by recursively applying the `liftDups` function, which is responsible for lifting duplication operations within the `Core` terms. This lifting process is crucial for ensuring that duplication operations are correctly handled during the compilation and execution phases, particularly in the context of parallel evaluation.

The function returns a tuple `([Core], Core -> Core)`, where the first element is a list of transformed `Core` terms, and the second element is a function that can be used to apply the same transformation to additional terms. This design allows for a modular approach to term transformation, where the transformation logic can be reused and applied consistently across different parts of the codebase.

In the context of the HVM3 codebase, `liftDupsList` is used in conjunction with `liftDups` to process terms that involve references (`Ref`) and constructors (`Ctr`). For example, when processing a `Ref` term, `liftDupsList` is used to transform the list of arguments associated with the reference. Similarly, when processing a `Ctr` term, `liftDupsList` is used to transform the list of fields associated with the constructor.

Overall, `liftDupsList` plays a critical role in the term transformation pipeline, ensuring that duplication operations are correctly lifted and handled, which is essential for the efficient execution of parallel computations in the HVM3 system.
# liftDupsMov
The `liftDupsMov` function is designed to work in conjunction with the `liftDups` function, which is responsible for lifting duplication operations in `Core` terms. When processing a `Mat` term, which represents pattern matching, the `liftDupsMov` function is called to handle the movement patterns (`mov`) associated with the `Mat` term.

The function operates recursively on the list of movement patterns. For each pattern, it applies the `liftDups` function to the `Core` term, which returns a transformed term and a function that can be used to apply further transformations. The `liftDupsMov` function then combines these results, ensuring that the transformations are applied consistently across all patterns.

The base case of the recursion is when the list of movement patterns is empty, in which case the function returns an empty list and the identity function (`id`). This indicates that no further transformations are needed.

In summary, `liftDupsMov` plays a critical role in the compilation process by ensuring that duplication operations within movement patterns are correctly lifted, which is essential for the efficient and correct execution of programs in the HVM3 runtime.
# locToString
The `locToString` function takes a `Word64` value, which represents a memory location, and converts it into a string. The conversion is done by first converting the `Word64` to a hexadecimal string using `showHex`. The resulting string is then padded with leading zeros to ensure it is exactly 9 characters long, using the `padLeft` function. This padding ensures that all memory locations are displayed in a uniform format, making it easier to read and compare them during debugging or inspection of the runtime state. The function is used within `termToString` to provide a string representation of the location component of a `Term`, which is essential for understanding the structure and state of the computational graph during execution.
# main
The `main` function in the HVM3 codebase is the central entry point for executing programs. It performs several key tasks:
1. **Initialization**: It starts by initializing the HVM runtime using `hvmInit`, setting up the necessary environment for execution.
2. **File Parsing**: It reads the input file and parses it into a `Book` data structure, which contains function definitions and metadata.
3. **Compilation**: It generates C code from the parsed `Book` and compiles it into a shared library using `gcc`. This step is optional and depends on whether the `compiled` flag is set.
4. **Execution**: It locates the `main` function in the `Book` and normalizes it, effectively executing the program. If the `main` function is not found, it exits with an error.
5. **Cleanup**: It removes temporary files and ensures that the runtime is properly shut down.

The `main` function is essential for the HVM3 runtime, as it ties together the parsing, compilation, and execution phases, ensuring that the program runs correctly and efficiently.
# mget
The `mget` function is a simple yet essential utility in the HVM3 codebase. It takes two arguments: a map and a key, and returns the value associated with that key in the map. This function is used in multiple contexts, such as retrieving function names from function IDs, accessing function definitions, and managing metadata during the compilation process. For example, in the `compileWith` function, `mget` is used to extract the copy flag, arguments, and core term associated with a specific function ID from the `Book` data structure. Similarly, in the `cliRun` function, `mget` is used to retrieve the function ID for the `main` function, ensuring that the program can be executed correctly. The consistent use of `mget` across the codebase highlights its importance in facilitating efficient and reliable access to the various mappings stored in the `Book`, thereby supporting the overall functionality and performance of the HVM3 runtime system.
# modeT
The `modeT` function maps specific label values (`Lab`) to corresponding `Mode` values. The `Mode` type likely represents different evaluation strategies such as lazy (`LAZY`), strict (`STRI`), and parallel (`PARA`). The function is defined with pattern matching, where:
- `0x00` maps to `LAZY`, indicating lazy evaluation.
- `0x01` maps to `STRI`, indicating strict evaluation.
- `0x02` maps to `PARA`, indicating parallel evaluation.
If the label does not match any of these predefined values, the function raises an error with a message indicating an unknown mode.

This function is used in the codebase to determine the evaluation mode of a term based on its label. For example, in the context provided, `modeT` is called with `termLab term` to extract the mode from a term's label. This mode is then used to guide the runtime's behavior during term reduction and execution. The `modeToString` function, which converts a `Mode` to a string representation, is also related to this functionality, providing a human-readable form of the mode for debugging or output purposes.

Overall, `modeT` plays a critical role in the runtime's ability to adapt its evaluation strategy based on the characteristics of the terms it processes, ensuring efficient and correct execution of programs in the HVM3 system.
# modeToString
The `modeToString` function serves a specific purpose in the HVM3 codebase: it translates evaluation modes into their string representations. This is particularly useful when generating human-readable or debug-friendly output for `Core` terms, especially in the context of `Let` expressions. The function takes a mode as input, which can be one of three values: `LAZY`, `STRI`, or `PARA`. These modes represent different evaluation strategies:
- `LAZY` corresponds to lazy evaluation, which is the default and is represented by an empty string (`""`).
- `STRI` corresponds to strict evaluation, represented by a dot (`"."`).
- `PARA` corresponds to parallel evaluation, represented by a caret (`"^"`).

When constructing a `Let` expression, the `modeToString` function is used to include the appropriate symbol in the output string, indicating the evaluation strategy for the binding. For example, if the mode is `STRI`, the output will include a dot before the variable name, signaling that the binding should be evaluated strictly. This function is a small but essential part of the codebase's string generation logic, ensuring that the evaluation strategy is clearly communicated in the output.
# mut
The `mut` function operates by recursively traversing the list until it reaches the desired index. Once the index is found, it applies the provided transformation function to the element at that position and constructs a new list with the modified element. If the index is out of bounds or the list is empty, the function returns the original list unchanged. This approach ensures that the function is both safe and efficient, as it only modifies the necessary element and leaves the rest of the list intact. In the context of the HVM3 codebase, `mut` could be used in scenarios where specific elements in a list need to be updated during the compilation or execution process, such as modifying function definitions or term representations in the `Book` data structure.
# normal
The `normal` function is a critical component of the HVM3 runtime, responsible for reducing terms to their normal form. In the context of the codebase, a "normal form" refers to a fully evaluated term that cannot be reduced further. This is essential for ensuring that computations are complete and correct before proceeding to the next steps, such as output or further processing.

In `hvm.hs`, the `normal` function is invoked on the root term after the runtime is initialized. This ensures that the main computation is fully evaluated before the program terminates. The `normal` function is part of the high-level orchestration of the runtime, bridging the gap between the Haskell frontend and the C backend.

In `hvm.c`, the `normal` function is implemented to handle specific term types, such as `LAM` (lambda), `APP` (application), `SUP` (superposition), `DP0`/`DP1` (duplication), `CTR` (constructor), and `MAT` (pattern matching). For each term type, `normal` recursively reduces its subterms, ensuring that the entire term is fully evaluated. This recursive reduction process is key to the runtime's ability to handle complex, nested computations efficiently.

The `normal` function leverages the Interaction Combinator model to manage parallel evaluation, ensuring that terms are reduced in a way that maximizes parallelism and performance. By reducing terms to their normal form, `normal` ensures that the runtime produces correct and complete results, making it a cornerstone of the HVM3 evaluation mechanism.
# operToString
The `operToString` function serves as a bridge between the internal representation of operators (`Oper`) and their human-readable string forms. It takes an `Oper` as input and returns a `String` that represents the operator. For example, `OP_ADD` is mapped to `"+"`, `OP_SUB` to `"-"`, and so on. This function is particularly useful in two main scenarios:
1. **Parsing**: When parsing expressions, the function is used to match operator strings in the input with their corresponding `Oper` types. This allows the parser to correctly interpret and process operator symbols in the source code.
2. **String Representation**: When converting `Core` terms to strings (e.g., for debugging or output), `operToString` ensures that operators are displayed in a familiar and understandable format. This is evident in the `Op2` case, where the function is used to construct a string representation of a binary operation.

By encapsulating the mapping logic in a single function, `operToString` promotes code reuse and consistency across the codebase. It also simplifies maintenance, as any changes to operator representations can be made in one place without affecting the rest of the system.
# padLeft
The `padLeft` function plays a crucial role in the HVM3 codebase by ensuring that hexadecimal values are consistently formatted. This is particularly important in contexts like memory address representation, where consistent formatting aids in debugging and understanding the state of the runtime. For example, in the `labToString` and `locToString` functions, `padLeft` is used to ensure that labels and locations are displayed as 6-digit and 9-digit hexadecimal strings, respectively, padded with zeros. Similarly, in the `heapToString` function, it ensures that memory addresses and iteration counters are formatted uniformly. By providing this formatting utility, `padLeft` enhances the readability and maintainability of the codebase, especially when dealing with low-level memory and runtime details.
# parseADT
The `parseADT` function is responsible for parsing the definition of an algebraic data type (ADT) in the input program. It follows a specific structure:
1. **Keyword Matching**: It first attempts to match the keyword `"data"`, which signifies the start of an ADT definition. This is done using the `consume` function, which ensures that the expected keyword is present in the input.
2. **Name Extraction**: After matching the keyword, it extracts the name of the ADT using the `parseName` function. This name is used to identify the ADT in the program.
3. **Constructor Parsing**: The function then parses the constructors of the ADT by consuming an opening brace `"{"` and using the `parseADTCtr` function to parse each constructor. The `parseADTCtr` function returns a tuple containing the constructor name and its associated parameters.
4. **Integration with `parseBook`**: The `parseADT` function is used within the `parseBook` function, which is responsible for parsing the entire program. `parseBook` calls `parseADT` multiple times to parse all ADT definitions in the program, building a comprehensive representation of the program's structure.

The parsed ADT definitions are crucial for the compilation process, as they provide the necessary information to generate low-level C code that can be executed by the HVM3 runtime. The `parseADT` function ensures that the ADT definitions are correctly extracted and structured, enabling the compiler to handle complex data types and their associated operations efficiently.
# parseADTCtr
The `parseADTCtr` function is defined as a `ParserM` action that returns a tuple `(String, [String])`. The first element of the tuple is the name of the constructor, and the second element is a list of argument types associated with that constructor. This function is called within the `parseADT` function, which is responsible for parsing the entire ADT definition. 

When `parseADT` encounters a constructor definition in the source code, it delegates the parsing of individual constructors to `parseADTCtr`. The `parseADTCtr` function uses a combination of parser combinators to extract the constructor name and its arguments. This information is then used to build the internal representation of the ADT, which is later used during the compilation process to generate the corresponding low-level C code.

In summary, `parseADTCtr` plays a critical role in the parsing phase of the HVM3 codebase by extracting and structuring the information needed to represent ADT constructors in the internal data structures of the system. This ensures that the runtime can correctly handle and execute programs that use algebraic data types.
# parseBook
The `parseBook` function plays a crucial role in the HVM3 codebase by transforming raw input (a string) into a structured format that the runtime can work with. Specifically, it parses a string representation of a book into a list of function definitions, where each definition includes a function name, metadata (such as whether the function is recursive and its argument patterns), and the corresponding `Core` term. This parsed data is then passed to the `createBook` function, which constructs a `Book` data structure. The `Book` data structure is vital for the runtime as it stores all function definitions and metadata, enabling quick lookup and efficient management of resources during execution. Without `parseBook`, the system would not be able to interpret and process the input program correctly, making it a foundational component of the compilation and execution pipeline.
# parseBookWithState
The `parseBookWithState` function is a key component in the parsing phase of the HVM3 codebase. It takes a string input representing the program and parses it into a structured format that includes function definitions and metadata. This structured format is essential for the subsequent compilation and execution phases. The function operates within the `ParserM` monad, which allows it to manage the parsing state and handle any errors that may occur during the parsing process. The parsed data is then used to create a `Book` object, which stores all the necessary information for the runtime to execute the program. Without `parseBookWithState`, the system would not be able to interpret and process the input program, making it a critical part of the HVM3 codebase.
# parseChr
The `parseChr` function plays a crucial role in the parsing phase of the HVM3 codebase. When the parser encounters a single quote (`'`), it delegates the task of parsing the subsequent character literal to `parseChr`. This function reads the character from the input stream, ensures it is valid, and then constructs a `Core` term representing the character. The `Core` term is a high-level representation used internally by the HVM3 system for further processing, such as compilation and execution.

By isolating the parsing of character literals into a dedicated function like `parseChr`, the codebase maintains modularity and clarity. This separation of concerns allows the parser to handle different types of literals (e.g., numbers, strings, characters) in a consistent and organized manner. Additionally, `parseChr` leverages the `ParserM` monad to manage the parsing state and handle potential errors, ensuring robust and reliable parsing of character literals.

Overall, `parseChr` is a key component in the parsing infrastructure of the HVM3 codebase, enabling the system to accurately interpret and process character literals in the input program.
# parseCore
The `parseCore` function plays a critical role in the HVM3 codebase by bridging the gap between the textual representation of programs and their internal `Core` term representation. It is the entry point for parsing user-defined programs or expressions into a structured format that the compiler and runtime can process. The function is highly modular, delegating the parsing of specific constructs to specialized helper functions. For example:
- Lambda expressions (`Lam`) are parsed by recognizing the `Î»` symbol and parsing the variable name and body.
- Operators are parsed by recognizing specific sequences of characters (e.g., `+`, `-`, `*`) and delegating to `parseOper`.
- References (`@`), constructors (`#`), and pattern matching (`~`) are handled by `parseRef`, `parseCtr`, and `parseMat`, respectively.
- Let bindings (`Let`) are parsed by recognizing the `&`, `!`, or `^` symbols and parsing the associated names, values, and bodies.

The function is recursive, enabling it to handle nested expressions and terms. For instance, when parsing a function application, it first parses the function and then recursively parses its arguments. This recursive nature ensures that complex expressions are correctly parsed into a hierarchical `Core` term structure.

The parsed `Core` terms are then passed to the compilation phase, where they are translated into low-level C code for execution by the runtime. This makes `parseCore` a foundational component of the HVM3 system, as it ensures that the input programs are correctly interpreted and prepared for further processing.
# parseCtr
The `parseCtr` function is a critical component of the parsing phase in the HVM3 codebase. It is responsible for interpreting constructor terms, which are fundamental elements in functional programming languages. Constructors are used to define data types and their instances, and they play a key role in pattern matching and term reduction. When the parser encounters the `#` symbol, it delegates the parsing task to `parseCtr`, which processes the constructor's name, arguments, and any associated metadata. The function returns a `Core` term that represents the parsed constructor, ensuring that it can be correctly compiled and executed by the runtime. This step is essential for maintaining the integrity of the program's structure and enabling efficient evaluation in the Interaction Combinator model. By accurately parsing constructor terms, `parseCtr` contributes to the overall correctness and performance of the HVM3 system.
# parseDef
The `parseDef` function is a key component of the HVM3 codebase's parsing infrastructure. It operates within the `ParserM` monad, which is likely a custom parser monad or a wrapper around a standard parsing library like Parsec. The function's type signature, `ParserM (String, ((Bool, [(Bool, String)]), Core))`, indicates that it returns a tuple containing:
1. A `String` representing the function's name.
2. A nested tuple `((Bool, [(Bool, String)]), Core)` where:
   - The `Bool` likely indicates whether the function is recursive.
   - The list `[(Bool, String)]` represents the function's parameters, where each `Bool` might indicate whether the parameter is strict, and the `String` is the parameter's name.
   - The `Core` type represents the parsed body of the function, which is a high-level term in the `Core` language.

The `parseDef` function is used in the `parseBook` function, which collects all function definitions into a list. This list is then stored in the `Book` data structure, which serves as a repository of function definitions and metadata for the runtime. By parsing function definitions into this structured format, `parseDef` enables the compiler to translate high-level `Core` terms into low-level C code efficiently. This step is critical for the overall compilation process, as it ensures that the input program is correctly interpreted and prepared for execution in the HVM3 runtime.
# parseEscapedChar
The `parseEscapedChar` function plays a critical role in the parsing process of the HVM3 codebase. When the parser encounters an escaped character (e.g., `\n` for a newline or `\t` for a tab), it delegates the interpretation of that character to `parseEscapedChar`. This function uses the `choice` combinator to match the escaped character against a predefined set of patterns and returns the corresponding `Char` value. For example, it would map `\n` to the newline character or `\\` to a backslash. This ensures that escaped characters are correctly interpreted during the parsing phase, which is essential for accurately translating the input program into the high-level `Core` representation used by the rest of the system. Without `parseEscapedChar`, the parser would fail to handle escaped characters, leading to errors in the compilation and execution of programs.
# parseLst
The `parseLst` function is a critical component of the parsing process in the HVM3 codebase. Its primary role is to handle the parsing of list structures in the input program. When the parser encounters a '[' character, it triggers `parseLst` to process the subsequent elements as part of a list. This function ensures that the list is correctly interpreted and transformed into a `Core` term, which is the intermediate representation used by the compiler.

The `Core` representation is essential for the compilation process, as it serves as the bridge between the high-level input program and the low-level C code generated by the compiler. By accurately parsing lists into `Core` terms, `parseLst` enables the compiler to handle list operations efficiently during the compilation and execution phases.

In summary, `parseLst` plays a vital role in the initial stages of the HVM3 pipeline, ensuring that list structures in the input program are correctly parsed and prepared for further processing by the compiler. This function contributes to the overall efficiency and correctness of the system by providing a robust mechanism for handling list-related constructs in the input program.
# parseMat
The `parseMat` function plays a crucial role in the parsing phase of the HVM3 codebase. It is a `ParserM Core` function, meaning it operates within the `ParserM` monad and produces a `Core` term as its output. The `Core` term represents the abstract syntax tree (AST) of the input program, which is later compiled into executable code. When the parser encounters the `~` symbol, it invokes `parseMat` to parse the subsequent pattern matching construct. This construct could involve matching a value against a pattern, such as a constructor or a variable, and defining the corresponding behavior for each case. The `parseMat` function ensures that this high-level construct is correctly represented in the `Core` term, enabling the compiler to generate the appropriate low-level code for pattern matching during execution. This is essential for the runtime's ability to handle complex, parallel computations efficiently, as pattern matching is a fundamental operation in functional programming.
# parseName
The `parseName` function plays a crucial role in the parsing phase of the HVM3 codebase. It is responsible for extracting identifiers (names) from the input program, which are used to represent variables, functions, constructors, and other entities. The function is defined to skip any leading whitespace (using `skip`) and then consume a sequence of characters that can include alphanumeric characters (`alphaNum`), underscores (`_`), dollar signs (`$`), and ampersands (`&`). This flexibility allows the parser to handle a wide range of naming conventions, which is essential for parsing complex programs.

The function is used in multiple parsing contexts, such as:
1. **Lambda Expressions**: In `BLOCK 215`, `parseName1` (a variant of `parseName`) is used to parse the variable name in a lambda expression.
2. **References**: In `BLOCK 230`, `parseName1` is used to parse the name of a reference.
3. **Constructors**: In `BLOCK 231`, `parseName1` is used to parse the name of a constructor.
4. **Pattern Matching**: In `BLOCK 232`, `parseName1` is used to parse the names of variables in pattern matching cases.
5. **Function Definitions**: In `BLOCK 241`, `parseName` is used to parse the name of a function definition.
6. **Algebraic Data Types**: In `BLOCK 242` and `BLOCK 243`, `parseName` is used to parse the names of data types and their constructors.

Overall, `parseName` is a fundamental utility in the parsing infrastructure of the HVM3 codebase, enabling the extraction of meaningful identifiers from the input program, which are then used in subsequent compilation and execution phases.
# parseName1
The `parseName1` function is a critical component of the parsing infrastructure in the HVM3 codebase. It is designed to parse valid names, which are essential for identifying variables, functions, constructors, and other entities in the input program. The function uses the `many1` combinator to parse one or more characters that match the allowed set (alphanumeric characters, underscores, dollar signs, and ampersands). This ensures that the parsed names are syntactically correct and can be used unambiguously in the subsequent compilation and execution phases.

The function is employed in multiple parsing scenarios, such as:
1. **Lambda Expressions**: Extracting the variable name in lambda abstractions.
2. **References**: Parsing the name of a reference in the `parseRef` function.
3. **Constructors**: Extracting the constructor name in the `parseCtr` function.
4. **Pattern Matching**: Parsing variable names in pattern matching cases within the `parseMat` function.

By providing a consistent and reusable way to parse names, `parseName1` simplifies the parsing logic and ensures that all names in the input program are handled uniformly. This contributes to the robustness and maintainability of the codebase, as it reduces the likelihood of parsing errors and inconsistencies.
# parseOper
The `parseOper` function plays a critical role in the parsing phase of the HVM3 codebase. Its primary purpose is to parse binary and relational operators from the input program and convert them into the `Core` representation used by the runtime. This function is invoked when the parser encounters specific operator symbols, such as `+`, `-`, `*`, `/`, `%`, `=`, `!`, `&`, `|`, `^`, `<`, and `>`.

When the parser detects an operator, it calls `parseOper` with the corresponding `Oper` value (e.g., `OP_ADD` for `+`, `OP_SUB` for `-`, etc.). The function then constructs a `Core` term that represents the operator in the intermediate representation used by the compiler. This `Core` term is later translated into low-level C code during the compilation process, enabling the runtime to execute the operator efficiently.

The `parseOper` function is part of the larger parsing logic in the Haskell frontend, which is responsible for transforming the input program into a format that the C backend can execute. By correctly parsing operators, `parseOper` ensures that the compiler can handle complex expressions involving arithmetic, logical, and relational operations. This is crucial for the correct execution of programs, as operators are fundamental to most computational tasks.

In summary, `parseOper` is a key component of the HVM3 parsing infrastructure, enabling the system to interpret and compile operator expressions accurately. Its role is essential for the correct functioning of the entire compilation and execution pipeline.
# parseRef
The `parseRef` function plays a crucial role in the parsing phase of the HVM3 codebase. When the parser encounters the `@` symbol, it triggers `parseRef` to parse the subsequent input as a reference term. References are essential in the Interaction Combinator model, as they allow terms to point to other terms or memory locations, enabling efficient graph-based computation and parallel evaluation. By parsing references into the `Core` representation, `parseRef` ensures that the input program is correctly translated into a format that the runtime can efficiently process. This function is part of the broader parsing infrastructure that bridges the gap between the high-level input program and the low-level runtime execution, ensuring that all necessary information is captured and prepared for subsequent stages of compilation and evaluation.
# parseStr
The `parseStr` function is a critical component of the parsing process in the HVM3 codebase. It is implemented as a monadic parser (`ParserM Core`), which means it operates within the context of a parser monad, allowing it to handle input streams and produce `Core` terms as output. When the parser encounters a double-quote (`"`), it triggers `parseStr` to read the subsequent characters until the closing double-quote is found. The parsed string is then encapsulated into a `Core` term, which can be further processed during compilation and execution.

This function ensures that string literals in the input program are correctly interpreted and represented in the computational graph. By handling strings as first-class citizens in the `Core` representation, `parseStr` enables the runtime to manage and manipulate string data efficiently, supporting operations like string concatenation, pattern matching, and function application. Its role is essential for maintaining the integrity of the input program's semantics and ensuring that string literals are accurately translated into the runtime's internal representation.
# pass
The `pass` function is crucial for managing the paths in the `Collapse` monad, which is used to handle parallel computations in the HVM3 runtime. When the `bind` function is called, it uses `fork` to traverse the `Collapse` structure and `pass` to propagate the paths through the structure. The `pass` function ensures that the paths are correctly maintained and updated as the computation progresses. This is particularly important for the `CSup` case, where the function needs to decide which branch to take based on the paths. By correctly managing the paths, the `pass` function helps ensure that the parallel computations are evaluated correctly and efficiently, contributing to the overall performance of the HVM3 runtime.
# pqPop
The `pqPop` function is defined to handle two cases:
1. If the priority queue is empty (`PQLeaf`), it returns `Nothing`, indicating there are no elements to pop.
2. If the priority queue contains elements (`PQNode`), it extracts the highest-priority element (stored in the node) and returns it along with the updated queue, which is formed by merging the left and right subtrees using `pqUnion`.

In the context of the `flattenPQ` function, `pqPop` is used to process elements from the priority queue during the flattening of a `Collapse` computation. The `flattenPQ` function recursively traverses the `Collapse` structure, inserting elements into the priority queue and then using `pqPop` to extract them in order of priority. This ensures that the results of parallel computations are processed efficiently and in the correct order.

Overall, `pqPop` plays a crucial role in managing the priority queue within the `Collapse` monad, enabling the HVM3 runtime to handle parallel computations effectively.
# pqPut
The `pqPut` function plays a crucial role in managing priority queues within the HVM3 codebase, particularly in the context of the `Collapse` monad, which handles parallel computations. In the `flattenPQ` function, `pqPut` is used to insert elements into the priority queue during the traversal of a `Collapse` term. This allows the system to efficiently manage and prioritize computations, ensuring that the most critical or highest-priority tasks are processed first. By leveraging the priority queue, the HVM3 runtime can optimize the execution of parallel computations, improving overall performance and resource utilization.
# pqUnion
The `pqUnion` function is used to merge two priority queues (`PQ`) into a single priority queue. A priority queue is a data structure where each element has an associated priority, and elements with higher (or lower) priority are served before elements with lower (or higher) priority. In the HVM3 codebase, priority queues are likely used to manage tasks or computations that need to be executed in a specific order based on their priority.

The function works as follows:
- If one of the queues is empty (`PQLeaf`), it simply returns the other queue, as there is nothing to merge.
- If both queues are non-empty, it compares the keys (priorities) of the root nodes of the two queues. The key represents the priority of the element.
  - If the key of the first queue's root node (`k1`) is less than or equal to the key of the second queue's root node (`k2`), the function creates a new `PQNode` with the root of the first queue and recursively merges the second queue with the right subtree of the first queue.
  - If the key of the first queue's root node is greater than the key of the second queue's root node, the function creates a new `PQNode` with the root of the second queue and recursively merges the first queue with the right subtree of the second queue.

This recursive merging ensures that the resulting priority queue maintains the correct order of elements based on their priorities. The `pqUnion` function is used in other operations like `pqPop` and `pqPut`, which are essential for managing the priority queue. For example, `pqPop` removes the highest priority element from the queue and uses `pqUnion` to merge the remaining subtrees, while `pqPut` inserts a new element into the queue by creating a new node and merging it with the existing queue.

Overall, `pqUnion` is a fundamental operation that enables efficient management of priority queues in the HVM3 codebase, supporting the runtime's ability to handle prioritized tasks or computations effectively.
# pretty
The `pretty` function is a key utility in the HVM3 codebase for converting `Core` terms into a human-readable format. It is particularly useful for debugging and displaying the structure of `Core` terms during development or runtime inspection. The function works by first attempting to use `prettyStr` to convert the term into a string representation. If `prettyStr` fails (i.e., returns `Nothing`), it then tries `prettyLst` to convert the term into a list representation.

- **`prettyStr`**: This function handles the pretty-printing of string-like `Core` terms. It recognizes specific patterns in the `Core` term, such as empty strings (`Ctr 0 []`) and strings constructed from characters (`Ctr 1 [Chr h, t]`), and converts them into a readable string format. For example, it converts `Ctr 1 [Chr 'a', Ctr 1 [Chr 'b', Ctr 0 []]]` into `"ab"`.

- **`prettyLst`**: This function handles the pretty-printing of list-like `Core` terms. It recognizes empty lists (`Ctr 0 []`) and lists constructed from elements (`Ctr 1 [x, xs]`), and converts them into a readable list format. For example, it converts `Ctr 1 [Num 1, Ctr 1 [Num 2, Ctr 0 []]]` into `[1 2]`.

The `pretty` function is used in various parts of the codebase, such as in the `showCore` function, which is responsible for converting `Core` terms into strings for display. By providing a clear and readable representation of `Core` terms, `pretty` aids in understanding the structure and behavior of the code during development and debugging.
# prettyLst
The `prettyLst` function plays a crucial role in the HVM3 codebase by providing a way to visualize list structures in the `Core` representation. This is particularly useful for debugging, as it allows developers to inspect the structure of terms during compilation or execution. The function is tightly integrated with the `pretty` function, which serves as the main entry point for pretty-printing `Core` terms. By delegating list-specific formatting to `prettyLst`, the `pretty` function can focus on handling other types of terms.

The recursive nature of `prettyLst` ensures that nested lists are properly formatted, making it a robust tool for generating readable output. Its ability to return `Nothing` for non-list terms also makes it flexible, allowing it to be used in conjunction with other pretty-printing functions without causing errors.

Overall, `prettyLst` is a small but essential component of the HVM3 codebase, contributing to the system's usability and maintainability by enabling clear and concise representation of list structures.
# prettyRename
The `prettyRename` function takes a `Core` term as input and returns a modified `Core` term where variable names have been renamed to be more readable. This is particularly useful when displaying the `Core` representation of a program, as it helps avoid confusion caused by arbitrary or non-descriptive variable names. The function is implemented using `unsafePerformIO`, which indicates that it may involve some side effects or external state, such as generating unique names or maintaining a mapping of original to renamed variables. By renaming variables in a consistent and meaningful way, `prettyRename` enhances the usability of the `showCore` function, making it easier for developers to interpret the program's structure and behavior.
# prettyStr
The `prettyStr` function plays a crucial role in the debugging and inspection capabilities of the HVM3 codebase. By converting `Core` terms into human-readable strings, it allows developers to visualize the internal state of the computation, making it easier to identify issues or understand the behavior of the system. This is particularly useful when working with complex, parallel computations, as it provides a way to trace the evaluation of terms and verify their correctness.

The function is tightly integrated with the `pretty` function, which serves as a higher-level pretty-printing utility. When `pretty` is called, it first attempts to use `prettyStr` to generate a string representation. If `prettyStr` fails (i.e., returns `Nothing`), `pretty` falls back to other strategies, such as `prettyLst`, to produce a readable output. This modular approach ensures that the system can handle a wide variety of `Core` terms, providing meaningful representations for different types of data.

In summary, `prettyStr` is a specialized function within the HVM3 codebase that enhances the system's debugging and inspection capabilities by converting specific `Core` terms into human-readable strings. Its integration with the `pretty` function ensures that developers have access to clear and informative representations of the internal state of their computations.
# primitives
The `primitives` list serves as a registry of primitive functions within the HVM3 codebase. Each entry in the list is a tuple where the first element is the name of the primitive function (as a `String`), and the second element is its associated label (`Lab`). These labels are used to uniquely identify and reference primitive functions during the compilation and execution phases.

When the `createBook` function is called to initialize the `Book` data structure, the `primitives` list is merged with other mappings (such as `n2i`) using `MS.union`. This ensures that primitive functions are included in the `Book` and can be quickly looked up when needed. The `Book` data structure is critical for managing function definitions and metadata, and the inclusion of primitives allows the runtime to handle built-in operations seamlessly.

In summary, `primitives` plays a key role in the HVM3 runtime by providing a mapping of primitive function names to their labels, enabling efficient access and execution of these functions during the program's lifecycle.
# printHelp
The `printHelp` function serves as a user-facing utility to provide guidance on how to use the HVM3 runtime system. When the user runs the executable with the `help` command or provides invalid arguments, the `main` function calls `printHelp` to display usage instructions, available commands, and options. This is a common pattern in command-line applications to ensure users can easily understand how to interact with the system. The function's return type, `IO (Either String ())`, suggests that it may handle potential errors internally (e.g., if printing fails) and return an appropriate result. This makes `printHelp` a critical component for user onboarding and error handling in the HVM3 codebase.
# print_heap
The `print_heap` function serves as a diagnostic tool within the HVM3 runtime system. Its primary purpose is to output the current state of the heap, which is crucial for debugging memory-related issues and ensuring the correct execution of the program. The heap in HVM3 is a critical component, as it stores all the `Term` nodes that represent the computational graph. These nodes are dynamically allocated and manipulated during the execution of the program, especially in the context of parallel evaluation.

By calling `print_heap`, developers can inspect:
1. **Memory Allocation**: Verify that nodes are being allocated correctly and that there are no memory leaks or invalid allocations.
2. **Term Manipulation**: Check the state of individual `Term` nodes, including their tags, labels, and locations, to ensure that they are being manipulated as expected.
3. **Graph Structure**: Visualize the structure of the computational graph, which can help in understanding how terms are being reduced and how parallel computations are being managed.

This function is particularly useful during the development and testing phases, where identifying and resolving issues related to memory management and term reduction is essential. It provides a snapshot of the runtime state, allowing developers to trace the flow of execution and pinpoint any anomalies or errors.
# print_tag
The `print_tag` function serves as a debugging tool in the HVM3 codebase. Its primary purpose is to output the tag of a `Term`, which is a critical piece of information in the Interaction Combinator model. Tags define the type of a term, such as whether it is an eraser (`ERA`), a reference (`REF`), a number (`NUM`), a constructor (`CON`), or a duplicator (`DUP`). This information is vital for the runtime to apply the correct reduction rules during evaluation.

The function is typically called within the `print_term` function, which prints the entire term, including its tag, label, and location. This allows developers to inspect the state of the computation at various points, making it easier to debug and understand the behavior of the program. Additionally, `print_tag` is used in other parts of the codebase where it is necessary to log or display the tag of a term, such as in the commented-out debugging code that prints the path of terms during reduction.

In summary, `print_tag` is a simple yet essential utility that aids in the debugging and inspection of terms within the HVM3 runtime, ensuring that developers can effectively monitor and diagnose the execution of parallel computations.
# print_term
The `print_term` function serves as a debugging aid in the HVM3 runtime system. Its primary role is to print the internal representation of a `Term`, which is a core data structure in the system representing nodes in the computational graph. By printing the term's tag, label, and other relevant information, `print_term` helps developers trace the flow of computation and verify that terms are being processed correctly. This is especially useful in a parallel, graph-based runtime like HVM3, where understanding the state of terms at various points in the execution is crucial for debugging and optimization. The function is often used in conjunction with other debugging utilities, such as `print_term_ln` (which adds a newline after printing) and `print_heap` (which prints the entire heap's contents). Overall, `print_term` is an essential tool for maintaining and improving the runtime's correctness and performance.
# print_term_ln
The `print_term_ln` function takes a single argument, `term`, which is of type `Term`. This `Term` represents a node in the computational graph, as defined by the Interaction Combinator model. The function prints the details of this term to the standard output, providing a human-readable representation of the term's structure and contents. After printing the term, it appends a newline character to ensure that the output is clean and readable, especially when multiple terms are printed in sequence.

This function is particularly useful during the development and debugging phases of the runtime. It allows developers to trace the flow of terms through the reduction process, verify the correctness of term manipulations, and diagnose issues related to memory management or parallel execution. By providing a clear and concise representation of terms, `print_term_ln` aids in maintaining the robustness and reliability of the HVM3 runtime system.
# putI
The `putI` function is defined as `putI bs = \x -> bs (I x)`. It takes a function `bs` (which is of type `Bin -> Bin`) and returns a new function that applies `bs` to an `I x` value. Here, `I` is a constructor for the `Bin` type, which represents binary choices in the computation paths. The `putI` function is used in the `fork` function when processing the right branch of a `CSup` (superposition) term. Specifically, it modifies the paths in the `IntMap` to indicate that the right branch is being taken. This allows the `Collapse` monad to correctly manage and reduce parallel computations by tracking which branch of the superposition is being evaluated. The `putI` function, along with `putO`, ensures that the paths are updated appropriately, enabling the runtime to handle parallel execution efficiently.
# putO
The `putO` function plays a crucial role in the `Collapse` monad's handling of parallel computations. When the `fork` function encounters a `CSup` (superposition) term, it splits the computation into two parallel branches. The `putO` function is used to modify the path map (`IntMap`) for the left branch of the superposition. Specifically, `putO` ensures that the path for the left branch is marked with the `O` constructor, which indicates that this branch should be followed during the reduction process. This allows the `Collapse` monad to correctly manage and reduce parallel computations, ensuring that the final result is computed accurately. The function `putO` is thus a key component in the system's ability to handle parallel evaluation efficiently.
# reduce
The `reduce` function is the backbone of the evaluation mechanism in the HVM3 runtime system. It takes a `Term` as input and applies reduction rules based on the term's type, as indicated by its tag. For example, if the term is an application (`APP`), the function will reduce the function and argument terms and then apply the function to the argument. Similarly, if the term is a pattern match (`MAT`), the function will evaluate the value being matched and then apply the corresponding case.

The `reduce` function is used in various parts of the codebase to ensure that terms are evaluated correctly. For instance, during the compilation process, the `reduce` function is called to evaluate terms that are being compiled into C code. During runtime, the `reduce` function is used to evaluate terms as they are executed, ensuring that the program runs correctly.

The function is also used in conjunction with other functions to manage parallel execution. For example, the `Collapse` monad uses the `reduce` function to manage parallel computations, reducing multiple possible outcomes or states to a single value or a list of results. The `Sup` operation, which allows for the combination of two terms into a single superposed term, also relies on the `reduce` function to evaluate the terms in parallel.

In summary, the `reduce` function is a critical component of the HVM3 runtime system, responsible for evaluating terms to their normal form and ensuring correct execution of the program. It is used extensively throughout the codebase, both in the Haskell frontend and the C backend, to handle term evaluation and manage parallel execution.
# reduceAppCtr
The `reduceAppCtr` function plays a crucial role in the evaluation process of the HVM3 runtime. When an application term (`APP`) is encountered, the runtime first reduces the function part of the application. If this function part is a constructor (`CTR`), the `reduceAppCtr` function is called to handle the reduction. Constructors are typically used to build data structures (e.g., lists, trees) in functional programming, and applying a constructor to an argument usually results in a new term that represents the constructed data.

In the context of the Interaction Combinator model, `reduceAppCtr` ensures that the application of a constructor to an argument is correctly evaluated, maintaining the integrity of the computational graph. The function likely performs operations such as allocating memory for the new term, setting the appropriate tags and labels, and updating the graph to reflect the new state of the computation. This process is essential for the correct execution of programs in the HVM3 runtime, as it ensures that constructors are applied correctly and that the resulting terms are properly integrated into the ongoing computation.

The `reduceAppCtr` function is part of a family of reduction functions (`reduceAppEra`, `reduceAppLam`, `reduceAppSup`, etc.) that handle different cases of term interactions. Each of these functions is specialized for a particular type of term, allowing the runtime to efficiently manage a wide variety of computational scenarios. By handling the specific case of constructor application, `reduceAppCtr` contributes to the overall efficiency and correctness of the HVM3 runtime, enabling it to execute complex, parallel computations effectively.
# reduceAppEra
The `reduceAppEra` function plays a crucial role in the HVM3 runtime by handling the interaction between an application (`APP`) term and an erasure (`ERA`) term. In the Interaction Combinator model, erasure terms are used to represent computations that can be safely discarded or simplified without affecting the overall result. When an `APP` term is encountered, the runtime first reduces its function part. If this function part is an `ERA` term, the `reduceAppEra` function is invoked to perform the necessary simplification.

In the C backend, `reduceAppEra` is implemented to process the `APP` and `ERA` terms, likely by returning a simplified term or a placeholder that indicates the erasure has been applied. This ensures that the runtime can efficiently manage and reduce terms, maintaining the correctness and performance of the parallel evaluation process. The function is part of the low-level runtime support that enables the HVM3 system to execute complex, parallel computations efficiently.
# reduceAppLam
The `reduceAppLam` function plays a pivotal role in the evaluation of functional programs within the HVM3 runtime. When the reduction engine encounters an application of a lambda term, it calls `reduceAppLam` to perform the necessary beta-reduction. This involves substituting the argument of the application into the body of the lambda, thereby simplifying the expression.

In the context of the HVM3 codebase, `reduceAppLam` is part of the broader reduction mechanism that ensures terms are evaluated to their normal forms. The function is invoked within the `reduceAt` function, which orchestrates the reduction process by recursively applying reduction rules based on the type of the term. Specifically, `reduceAppLam` is called when the function being applied is identified as a lambda abstraction (`LAM`).

The implementation of `reduceAppLam` in the C backend (`hvm.c`) suggests that the function is optimized for performance, leveraging low-level memory management and term manipulation to achieve efficient execution. This is crucial for the HVM3 runtime, which is designed to handle massively parallel computations and requires high-performance reduction operations.

Overall, `reduceAppLam` is a key function in the HVM3 codebase, enabling the runtime to evaluate functional programs by applying lambda abstractions to their arguments. Its integration into the reduction engine ensures that the system can efficiently reduce terms to their normal forms, supporting the parallel execution model that HVM3 is built upon.
# reduceAppSup
The `reduceAppSup` function is responsible for reducing an application (`APP`) term where the function part is a superposition (`SUP`) term. In the Interaction Combinator model, a superposition represents multiple possible states or outcomes that can be evaluated in parallel. When an `APP` term is applied to a `SUP` term, the `reduceAppSup` function ensures that the application is correctly distributed across the superposed states, enabling parallel evaluation.

The function follows the `APP-SUP` reduction rule, which can be summarized as:
1. The application term (`APP`) is applied to a superposition term (`SUP`).
2. The superposition term is decomposed into its constituent parts (e.g., `x0` and `x1`).
3. The application is then distributed to each part of the superposition, resulting in a new superposition term that combines the results of the individual applications.

This process allows the runtime to handle parallel computations efficiently, leveraging the massively parallel hardware to evaluate multiple states simultaneously. The `reduceAppSup` function is thus a key component in the HVM3 runtime's ability to execute complex, parallel computations, ensuring that superposed terms are correctly reduced and evaluated.
# reduceAppW32
The `reduceAppW32` function is responsible for reducing an application term (`APP`) when the function being applied is a 32-bit word (`W32`). In the HVM3 runtime, terms are represented as nodes in a computational graph, and the `APP` operation signifies function application. When the function is a `W32`, the `reduceAppW32` function is called to handle this specific case.

In the C backend, the `reduce_app_w32` function is defined to process this scenario. The function takes two arguments: the application term (`app`) and the 32-bit word (`w32`). The exact behavior of the reduction is not fully detailed in the provided context, but it likely involves handling the interaction between the application term and the 32-bit word, possibly resulting in a simplified or normalized term.

The presence of `reduceAppW32` in both the Haskell and C codebases underscores its importance in the runtime's evaluation process. It ensures that the system can efficiently handle the application of terms to 32-bit words, which is a common operation in many computational tasks. This function is part of the broader reduction engine that enables the HVM3 runtime to execute programs efficiently on massively parallel hardware, leveraging the Interaction Combinator model for high performance.
# reduceAt
The `reduceAt` function serves as the primary reduction engine in the HVM3 runtime system. It takes a `Book` (which contains function definitions and metadata) and a `host` location (which points to a term in memory) as inputs and reduces the term at that location to its normal form. The function handles different term types (e.g., `LET`, `APP`, `MAT`, `DP0`, `DP1`, etc.) by applying specific reduction rules. For example, in the case of a `LET` term, it evaluates the value part of the let-binding and then proceeds to reduce the body. For `APP` terms, it reduces both the function and the argument before applying the function to the argument. The function also manages memory efficiently by using `got` and `set` operations to retrieve and update terms in memory. Additionally, `reduceAt` supports parallel execution by interacting with the `Collapse` monad, which handles multiple possible outcomes or states and reduces them to a single result. Overall, `reduceAt` is a critical function that ensures the correct and efficient evaluation of terms in the HVM3 runtime system.
# reduceC
The `reduceC` function is a low-level operation that directly interacts with the runtime's memory model and term representation. It takes a `Term` as input and returns a reduced `Term` as output. This function is essential for the evaluation process, as it handles the actual reduction of terms according to the Interaction Combinator model. The `reduceC` function is called within the `reduceCAt` function, which orchestrates the reduction process by first retrieving the term from memory using the `got` function and then applying `reduceC` to reduce the term to its weak head normal form. This process is critical for the parallel execution model of the HVM3 system, as it ensures that terms are evaluated correctly and efficiently, leveraging the massively parallel hardware. The `reduceC` function is part of the C backend, which provides the low-level runtime support necessary for the high-level operations managed by the Haskell frontend.
# reduceCAt
The `reduceCAt` function plays a crucial role in the HVM3 runtime's compiled execution mode. When the code is compiled to C and executed natively, `reduceCAt` is invoked to handle the reduction of terms. This function is a specialized version of `reduceAt`, which is the general-purpose term reduction engine in the runtime. The `Bool` parameter passed to `reduceCAt` is likely used to enable or disable debugging output, allowing developers to inspect the reduction process when necessary.

In the `cliRun` function, `reduceCAt` is used when the `compiled` flag is set to `True`, indicating that the code has been compiled to C. This function is then passed as an argument to other functions that handle term reduction, ensuring that the compiled code is executed efficiently. By using `reduceCAt`, the runtime can leverage the optimizations provided by the C backend, achieving high performance in parallel computations.

Overall, `reduceCAt` is a key component in the compiled execution pipeline of the HVM3 runtime, enabling efficient term reduction in a native execution environment. Its integration into the `cliRun` function highlights its importance in the overall execution flow of the system.
# reduceDupCtr
The `reduceDupCtr` function plays a crucial role in the reduction process by managing the interaction between duplication and constructor terms. In the Interaction Combinator model, duplication terms (`DUP`) are used to create multiple copies of a term, while constructor terms (`CTR`) represent structured data or function applications. When a `DUP` term encounters a `CTR` term, the `reduceDupCtr` function is called to apply the appropriate reduction rules.

The function works by decomposing the constructor term into its constituent parts and then distributing the duplication across these parts. This ensures that the duplication is correctly propagated through the structure of the constructor term, maintaining the integrity of the computation. The result is a new set of terms that represent the duplicated structure, which can then be further reduced by the reduction engine.

In the context of the HVM3 codebase, `reduceDupCtr` is part of a family of reduction functions that handle specific interactions between different types of terms. These functions are essential for the correct and efficient execution of programs, as they ensure that terms are reduced in a way that respects the semantics of the Interaction Combinator model. By handling the interaction between `DUP` and `CTR` terms, `reduceDupCtr` contributes to the overall performance and correctness of the parallel execution engine.
# reduceDupEra
The `reduceDupEra` function is designed to handle the specific case where a duplication term (`DUP`) interacts with an erasure term (`ERA`). In the Interaction Combinator model, this interaction simplifies the computational graph by effectively erasing the duplicated term. The function ensures that both branches of the duplication are set to the erasure term, thereby reducing the complexity of the graph and optimizing the computation. This is crucial for maintaining efficiency in the parallel execution model of HVM3, as it prevents unnecessary computations and memory usage. The function is called during the reduction process when the runtime encounters an `ERA` term in the context of a duplication operation, ensuring that the reduction rules are applied correctly and efficiently.
# reduceDupLam
The `reduceDupLam` function is responsible for reducing terms that involve the duplication of a lambda term. In the HVM3 codebase, duplication (`DUP`) is a mechanism that allows for the parallel evaluation of terms, while lambda (`LAM`) represents function abstraction. When a duplication of a lambda term is encountered, `reduceDupLam` applies specific reduction rules to ensure that the computation is carried out correctly.

The function works by taking two arguments: the duplication term (`dup`) and the lambda term (`lam`). It then performs the necessary transformations to reduce the combined term to a simpler form. This involves creating new lambda terms for the duplicated parts and updating the computational graph accordingly. The goal is to maintain the structure of the graph while enabling parallel evaluation, which is a key feature of the HVM3 runtime.

In the context of the codebase, `reduceDupLam` is part of the broader reduction engine that handles various term types and their interactions. It is called during the reduction process when the term being reduced is identified as a lambda, and it ensures that the duplication of lambda terms is handled in a way that supports the parallel execution model of the HVM3 system.

Overall, `reduceDupLam` is a specialized function that plays a crucial role in the reduction engine, enabling the efficient and correct evaluation of terms involving duplication and lambda abstraction in the HVM3 codebase.
# reduceDupRef
The `reduceDupRef` function plays a key role in the parallel evaluation mechanism of the HVM3 runtime. When a duplication term (`DUP`) encounters a reference term (`REF`), the `reduceDupRef` function is invoked to handle the interaction. This is essential because duplications are a fundamental operation in the Interaction Combinator model, allowing for the parallel evaluation of terms by creating multiple copies of a term.

The `DUP-REF-COPY` rule, implemented by `reduceDupRef`, ensures that when a reference is duplicated, the duplicated references are correctly propagated through the computational graph. This involves creating new terms for each duplicated reference and updating the graph to reflect these changes. The function ensures that the reduction is performed efficiently, maintaining the integrity of the computational graph and enabling parallel execution.

In summary, `reduceDupRef` is a specialized reduction function that handles the interaction between duplication and reference terms, ensuring that the computational graph is correctly updated and evaluated in parallel. This function is a crucial component of the HVM3 runtime, enabling efficient and correct parallel execution of programs.
# reduceDupSup
The `reduceDupSup` function plays a critical role in the HVM3 runtime by managing the interaction between duplication and superposition terms. In the Interaction Combinator model, a `DUP` term represents a point where a term is duplicated, while a `SUP` term represents a superposition of two terms, allowing for parallel evaluation. When these two types of terms interact, the `reduceDupSup` function applies specific rules to ensure that the duplication is handled correctly in the context of parallel execution.

The function operates by examining the labels of the `DUP` and `SUP` terms. If the labels match, it directly assigns the components of the `SUP` term to the duplicated terms. If the labels do not match, it creates new `SUP` terms for the duplicated components and ensures that the original superposition is preserved. This process is essential for maintaining the integrity of the parallel evaluation, as it ensures that the duplication of terms does not interfere with the superposition mechanism.

The `reduceDupSup` function is invoked by the reduction engine when it encounters a `DUP` term that needs to interact with a `SUP` term. This typically occurs during the reduction of complex terms that involve both duplication and superposition, such as in the evaluation of higher-order functions or parallel computations. By handling this interaction correctly, the `reduceDupSup` function enables the runtime to efficiently manage parallel computations and achieve high performance on modern hardware.
# reduceDupW32
The `reduceDupW32` function plays a crucial role in the HVM3 runtime by managing the duplication of 32-bit word terms (`W32`). In the Interaction Combinator model, duplication is a fundamental operation that allows terms to be shared across multiple computational paths, enabling parallel evaluation. When a term with the `W32` tag is encountered during the reduction process, `reduceDupW32` is called to handle the duplication. This function ensures that the 32-bit word is correctly copied and assigned to the appropriate locations in the computational graph, preserving the semantics of the original term. By doing so, `reduceDupW32` supports the efficient and correct execution of parallel computations, contributing to the overall performance and reliability of the HVM3 runtime.
# reduceLet
The `reduceLet` function is responsible for reducing `LET` terms in the HVM3 runtime. A `LET` term is a construct that binds a value to a variable, which can then be used in subsequent computations. The function takes two arguments: the `LET` term itself and the value to be bound. Depending on the evaluation mode (`LAZY` or `STRI`), `reduceLet` either retrieves the value directly from memory (in `LAZY` mode) or fully reduces it before binding (in `STRI` mode). This behavior ensures that the runtime can handle both lazy and strict evaluation strategies efficiently.

In the `LAZY` mode, the function uses the `got` function to retrieve the value from memory without further reduction. This is useful in scenarios where the value does not need to be immediately evaluated, allowing for deferred computation. In `STRI` mode, the function calls `reduceAt` to fully reduce the value before binding it. This ensures that the value is in its normal form before being used in subsequent computations, which is crucial for strict evaluation.

The `reduceLet` function is implemented in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`). In the Haskell code, it is used within the `LET` case of the reduction logic, where it interacts with the `cont` function to continue the reduction process. In the C code, it is defined as `reduce_let` and handles the actual reduction of `LET` terms, including printing debug information when necessary.

Overall, `reduceLet` plays a vital role in the HVM3 runtime by managing the reduction of `LET` terms, enabling the system to efficiently handle both lazy and strict evaluation strategies. This flexibility is essential for optimizing parallel execution and ensuring that the runtime can handle complex computations effectively.
# reduceMatCtr
In the HVM3 codebase, the `reduceMatCtr` function plays a crucial role in the evaluation of pattern matching constructs. When a `MAT` term (which represents a pattern match) encounters a `CTR` term (which represents a constructor), the `reduceMatCtr` function is called to handle this specific interaction. The function applies the `MAT-CTR` reduction rule, which transforms the pattern match and constructor into a new term that represents the result of the pattern match. This transformation is essential for correctly evaluating expressions that involve pattern matching on constructors, ensuring that the program behaves as expected.

The `reduceMatCtr` function is part of the low-level C runtime, and it is called from the Haskell frontend via a foreign function interface (FFI). This allows the Haskell code to delegate the handling of specific reduction rules to the more efficient C implementation. The function works by taking two arguments: the `MAT` term and the `CTR` term, and it returns a new term that represents the result of the reduction. This process is integral to the overall reduction mechanism, which recursively reduces terms to their normal form, enabling the efficient execution of programs in the HVM3 runtime.
# reduceMatEra
The `reduceMatEra` function is responsible for reducing a `MAT` term when it encounters an `ERA` term. In the context of the HVM3 codebase, `MAT` terms are used for pattern matching, while `ERA` terms represent erasure or deletion of terms. When a `MAT` term is applied to an `ERA` term, the `reduceMatEra` function ensures that the reduction is performed correctly according to the Interaction Combinator rules.

The function is implemented in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`). In the Haskell code, `reduceMatEra` is imported as a foreign function from the C runtime, indicating that the actual reduction logic is handled in the C backend for performance reasons. In the C code, `reduce_mat_era` is defined to perform the reduction, likely by simplifying the `MAT` term in the presence of an `ERA` term, possibly by erasing or collapsing the term structure.

This function is crucial for maintaining the correctness and efficiency of the reduction process, especially in a parallel execution environment where terms are evaluated concurrently. By handling the specific case of `MAT` and `ERA` interactions, `reduceMatEra` ensures that the runtime can proceed with further reductions without unnecessary overhead or incorrect term manipulations.
# reduceMatLam
The `reduceMatLam` function is responsible for reducing a `MAT` term when it encounters a `LAM` term. In the HVM3 system, `MAT` terms are used for pattern matching, while `LAM` terms represent lambda abstractions. When a `MAT` term is applied to a `LAM` term, the `reduceMatLam` function performs the necessary reduction to simplify the expression. This reduction is part of the Interaction Combinator model, which enables parallel evaluation of terms.

In the Haskell frontend, `reduceMatLam` is called within the `reduceAt` function when the term being reduced is a `MAT` and the value it is matching against is a `LAM`. The function is then passed to the C backend for execution, where it performs the actual reduction. The C implementation of `reduceMatLam` handles the low-level details of the reduction, ensuring that the computational graph is updated correctly and that the term is simplified according to the rules of the Interaction Combinator model.

The purpose of `reduceMatLam` is to ensure that pattern matching on lambda terms is handled efficiently and correctly within the parallel execution model of HVM3. By reducing `MAT` terms when they encounter `LAM` terms, the function helps maintain the integrity of the computational graph and ensures that the system can continue to evaluate terms in parallel.
# reduceMatSup
The `reduceMatSup` function is responsible for reducing a `MAT` term when it encounters a `SUP` term. In the HVM3 system, a `MAT` term represents a pattern matching operation, while a `SUP` term represents a superposition of two terms, enabling parallel evaluation. When a `MAT` term is applied to a `SUP` term, the `reduceMatSup` function ensures that the pattern matching operation is correctly distributed across the superposed terms.

The function works by decomposing the `SUP` term into its constituent parts and then applying the `MAT` operation to each part separately. This allows the system to handle parallel evaluation efficiently, as the pattern matching can proceed concurrently on the superposed terms. The result is a new term that combines the outcomes of the pattern matching operations, preserving the parallelism inherent in the `SUP` term.

In the C backend, `reduce_mat_sup` is implemented to perform this operation at a low level, directly manipulating the memory and term structures to achieve the desired reduction. The function is called within the reduction engine when a `MAT` term encounters a `SUP` term, ensuring that the interaction is handled according to the rules of the Interaction Combinator model.

Overall, `reduceMatSup` is a crucial component of the HVM3 runtime, enabling efficient and correct evaluation of pattern matching operations in the presence of superposed terms, which is essential for the system's parallel execution capabilities.
# reduceMatW32
The `reduceMatW32` function is responsible for handling the reduction of pattern matching (`MAT`) terms when they encounter a 32-bit word (`W32`) or character (`CHR`) term. In the HVM3 runtime, pattern matching is a fundamental operation that allows the system to branch computation based on the structure or value of a term. When a `MAT` term is reduced, it examines the term it is matching against and applies the appropriate reduction rule based on the term's type.

In the case of `reduceMatW32`, the function is specifically designed to handle the scenario where the term being matched is a `W32` or `CHR`. The function likely performs operations such as extracting the value of the `W32` term and using it to determine the next step in the computation. This could involve selecting a specific branch of the pattern match or performing some transformation on the term.

The implementation in `hvm.c` suggests that `reduceMatW32` is a low-level function that directly manipulates the term structure in memory. The function is called within the context of the broader reduction engine, which ensures that all terms are fully evaluated to their normal form. The presence of debugging output (commented out in the C code) indicates that `reduceMatW32` is a critical part of the runtime, and its behavior is important for the correct execution of programs.

Overall, `reduceMatW32` plays a key role in the HVM3 runtime's ability to handle pattern matching efficiently, particularly when dealing with 32-bit word and character terms. Its integration into the reduction engine ensures that the system can perform complex computations with high performance, leveraging the Interaction Combinator model to achieve parallel execution.
# reduceOpxCtr
The `reduceOpxCtr` function is a critical component of the HVM3 runtime's reduction engine. It is invoked when the runtime encounters an `OPX` term that needs to be reduced in the presence of a `CTR` term. The function's role is to handle the specific interaction between these two types of terms, ensuring that the reduction process is carried out correctly and efficiently.

In the context of the Interaction Combinator model, `OPX` terms represent extended operations, while `CTR` terms represent constructors. When an `OPX` term interacts with a `CTR` term, the `reduceOpxCtr` function is responsible for applying the appropriate reduction rules to ensure that the terms are evaluated in a way that maintains the integrity of the computational graph.

The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the runtime determines that an `OPX` term needs to be reduced in the context of a `CTR` term. The function's implementation involves handling the specific interaction between the `OPX` and `CTR` terms, which may include operations such as pattern matching, term substitution, or other forms of term manipulation.

Overall, `reduceOpxCtr` plays a vital role in the HVM3 runtime's ability to execute complex, parallel computations efficiently. By handling the interaction between `OPX` and `CTR` terms, the function ensures that the reduction process adheres to the rules of the Interaction Combinator model, enabling the runtime to achieve high performance on modern hardware.
# reduceOpxEra
In the HVM3 codebase, `reduceOpxEra` is a critical function within the reduction engine, specifically tailored to handle the interaction between `OPX` and `ERA` terms. The `OPX` term typically signifies an operation that needs to be evaluated, while the `ERA` term indicates that a part of the computation can be erased or simplified. When the reduction engine encounters an `OPX` term interacting with an `ERA` term, it calls `reduceOpxEra` to process this interaction.

The function `reduceOpxEra` is implemented in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). This allows the Haskell code to invoke the C implementation seamlessly. The primary role of `reduceOpxEra` is to simplify the computational graph by reducing the `OPX` term in the context of the `ERA` term, effectively erasing unnecessary parts of the computation and ensuring that the graph remains efficient and manageable.

In the context of the Interaction Combinator model, `reduceOpxEra` plays a vital role in maintaining the integrity and efficiency of the computational graph. By handling the specific interaction between `OPX` and `ERA` terms, it contributes to the overall performance of the runtime system, enabling it to execute complex, parallel computations effectively.
# reduceOpxLam
The `reduceOpxLam` function is responsible for reducing an `OPX` term when it interacts with a `LAM` term. In the HVM3 codebase, `OPX` and `LAM` are specific types of terms in the computational graph. The `OPX` term represents an operation that needs to be reduced, while the `LAM` term represents a lambda abstraction (a function). When the reduction engine encounters an `OPX` term followed by a `LAM` term, it invokes `reduceOpxLam` to handle this specific interaction.

The function's purpose is to apply the reduction rule for this particular combination of terms, ensuring that the computation proceeds correctly. The exact behavior of `reduceOpxLam` is defined in the C backend (`hvm.c`), where it performs the necessary operations to reduce the `OPX` term in the context of the `LAM` term. This might involve manipulating the term's structure, updating memory locations, or triggering further reductions.

In the Haskell frontend (`hvm.hs`), `reduceOpxLam` is referenced as part of the reduction logic, where it is called when the `OPX` term's reduction leads to a `LAM` term. This seamless integration between the Haskell and C components ensures that the reduction rules are consistently applied across the entire runtime system.

Overall, `reduceOpxLam` plays a crucial role in the HVM3 runtime's ability to efficiently evaluate complex, parallel computations by handling specific term interactions according to the Interaction Combinator model.
# reduceOpxSup
The `reduceOpxSup` function is invoked when the reduction engine encounters an `OPX` term that needs to be applied to a `SUP` term. The `SUP` term represents a superposition of two terms, allowing for parallel evaluation. The purpose of `reduceOpxSup` is to apply the operation (`OPX`) to each component of the superposed term (`SUP`), effectively distributing the operation across the parallel components. This is crucial for maintaining the parallelism inherent in the Interaction Combinator model, as it ensures that operations are applied uniformly across all possible values represented by the `SUP` term.

In the context of the codebase, `reduceOpxSup` is part of the low-level C runtime, which handles the actual execution of reduction rules. The function takes two arguments: the `OPX` term and the `SUP` term. It then processes these terms by applying the operation to each component of the superposition, resulting in a new term that represents the combined result of the operation applied in parallel. This function is essential for the correct and efficient execution of parallel computations within the HVM3 runtime, leveraging the capabilities of modern hardware to achieve high performance.
# reduceOpxW32
The `reduceOpxW32` function plays a crucial role in the evaluation of terms in the HVM3 runtime. When the runtime encounters an `OPX` term with a `W32` subterm, it calls `reduceOpxW32` to perform the necessary reduction. This function is part of the Interaction Combinator model, which enables parallel evaluation of terms through a graph-based computational model. By handling the reduction of `OPX` terms with `W32` subterms, `reduceOpxW32` ensures that operations involving 32-bit words are executed correctly and efficiently. This is particularly important in a parallel execution environment, where precise and efficient term reduction is essential for achieving high performance. The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the appropriate term types are encountered during the reduction process.
# reduceOpyCtr
The `reduceOpyCtr` function is a critical component of the reduction engine in the HVM3 runtime. It is invoked when the runtime encounters an `OPY` term that needs to be reduced with a `CTR` term. The `OPY` tag represents a specific operation in the Interaction Combinator model, while the `CTR` tag represents a constructor term. The purpose of `reduceOpyCtr` is to apply the appropriate reduction rule for this interaction, ensuring that the computation proceeds correctly.

In the context of the codebase, `reduceOpyCtr` is part of a larger system of reduction functions that handle various combinations of term types. When the `reduceAt` function encounters an `OPY` term, it evaluates the term at the specified location and then dispatches to the appropriate reduction function based on the type of the resulting term. If the resulting term is a `CTR`, `reduceOpyCtr` is called to handle the reduction.

The function is implemented in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). This allows the Haskell code to call the C implementation of `reduceOpyCtr` when needed. The function takes two arguments: the `OPY` term and the `CTR` term, and it returns the result of the reduction.

Overall, `reduceOpyCtr` plays a vital role in the HVM3 runtime by ensuring that the interaction between `OPY` and `CTR` terms is handled correctly, contributing to the efficient execution of parallel computations in the Interaction Combinator model.
# reduceOpyEra
The `reduceOpyEra` function plays a crucial role in the reduction engine of the HVM3 runtime. Specifically, it handles the case where an `OPY` term interacts with an `ERA` term. In the Interaction Combinator model, `OPY` and `ERA` are specific types of terms that represent operations and erasures, respectively. When an `OPY` term encounters an `ERA` term, the `reduceOpyEra` function is invoked to perform the necessary reduction. This reduction typically involves simplifying the term structure or eliminating unnecessary terms, which helps in optimizing the computation and reducing memory usage. The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) during the reduction process. By handling this specific interaction, `reduceOpyEra` contributes to the overall efficiency and correctness of the parallel evaluation mechanism in the HVM3 runtime.
# reduceOpyLam
The `reduceOpyLam` function plays a crucial role in the reduction process of the HVM3 runtime. When the runtime encounters an `OPY` term interacting with a `LAM` term, it calls `reduceOpyLam` to apply the appropriate reduction rule. This function is part of the Interaction Combinator model, which enables parallel evaluation of terms by transforming them according to specific interaction rules.

In the C implementation (`hvm.c`), `reduce_opy_lam` (the C counterpart of `reduceOpyLam`) is defined to handle the reduction of an `OPY` term with a `LAM` term. The function likely performs operations such as substituting the lambda's body with the operand or simplifying the term structure to facilitate further evaluation. The exact behavior depends on the specific reduction rules defined for the `OPY-LAM` interaction.

The Haskell code (`hvm.hs`) uses `reduceOpyLam` as part of the `reduceAt` function, which is responsible for reducing terms to their normal form. When the `reduceAt` function encounters an `OPY` term and determines that it is interacting with a `LAM` term, it delegates the reduction to `reduceOpyLam`. This modular approach allows the runtime to efficiently handle different types of term interactions while maintaining a clear separation between high-level orchestration (in Haskell) and low-level reduction logic (in C).

Overall, `reduceOpyLam` is a key component of the HVM3 runtime's reduction engine, enabling the system to efficiently process and evaluate complex, parallel computations by applying specific interaction rules to terms.
# reduceOpySup
The `reduceOpySup` function is invoked when the runtime encounters an `OPY` operation applied to a `SUP` term. In the context of the Interaction Combinator model, this situation arises when a parallel computation needs to be reduced. The function takes two arguments: the `OPY` term and the `SUP` term. It then applies the reduction rule specific to this interaction, which involves distributing the `OPY` operation over the components of the `SUP` term. This ensures that the parallel evaluation is correctly handled, and the result is computed in a way that leverages the massively parallel hardware. The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the corresponding reduction rule is triggered. The purpose of `reduceOpySup` is to maintain the integrity of the parallel evaluation process and to ensure that the computation is performed efficiently.
# reduceOpyW32
The `reduceOpyW32` function is a specialized reduction function in the HVM3 runtime system. Its primary purpose is to handle the reduction of terms that involve the `OPY` operation when the operand is a `W32` (32-bit word) term. This function is part of the broader reduction engine, which is responsible for evaluating terms to their normal form by applying specific reduction rules based on the term's type.

In the Haskell frontend (`hvm.hs`), `reduceOpyW32` is invoked within the `OPY` case of the reduction logic. When the runtime encounters an `OPY` operation, it first reduces the operand (`val`) and then dispatches to the appropriate reduction function based on the tag of the reduced term. If the tag is `W32`, `reduceOpyW32` is called to handle the reduction.

In the C backend (`hvm.c`), `reduceOpyW32` is implemented as a function that takes two `Term` arguments: the `OPY` term and the `W32` term. The function applies the specific reduction rules for `OPY` operations involving `W32` terms, ensuring that the computation proceeds correctly. The function is part of a larger switch-case structure that handles different term types and operations, allowing the runtime to efficiently manage and process terms.

Overall, `reduceOpyW32` is a critical component of the HVM3 runtime system, enabling the correct and efficient evaluation of `OPY` operations involving `W32` terms. Its role is to ensure that the reduction process adheres to the rules of the Interaction Combinator model, which is the foundation of the HVM3 system's parallel execution capabilities.
# reduceRefAt
The `reduceRefAt` function plays a crucial role in the HVM3 runtime by managing the reduction of `REF` terms, which are references to other terms in the computational graph. When a `REF` term is encountered during evaluation, `reduceRefAt` is responsible for determining the appropriate reduction strategy based on the term's metadata. This involves:
1. **Retrieving the Term**: The function first retrieves the term from the specified memory location using the `got` function.
2. **Extracting Metadata**: It then extracts the label and location from the term, which are used to determine the function ID (`fid`) and arity (`ari`).
3. **Dispatching to Specific Reducers**: Depending on the function ID, `reduceRefAt` dispatches to specialized reduction functions:
   - `reduceRefAt_DupF` handles dynamic duplication (`@DUP`).
   - `reduceRefAt_SupF` handles dynamic superposition (`@SUP`).
   - `reduceRefAt_LogF` handles logging (`@LOG`).
   - `reduceRefAt_FreshF` handles the generation of fresh duplication labels (`@FRESH`).

This function ensures that `REF` terms are processed correctly and efficiently, contributing to the overall performance of the HVM3 runtime by enabling parallel evaluation and dynamic term manipulation.
# reduceRefAt_DupF
The `reduceRefAt_DupF` function plays a crucial role in the HVM3 runtime by managing the reduction of terms that involve dynamic duplication. Dynamic duplication is a key operation in the Interaction Combinator model, allowing for the parallel evaluation of terms by duplicating them and distributing the computation across multiple nodes. This function ensures that the duplication is performed correctly, taking into account the arity of the operation and the specific context in which it occurs.

When `reduceRefAt` identifies a term with the `_DUP_F_` function ID, it delegates the reduction task to `reduceRefAt_DupF`. This function then retrieves the necessary information from the `Book` and the term's location, and performs the reduction steps required to handle the dynamic duplication. This involves allocating new nodes in the computational graph, setting up the duplicated terms, and ensuring that the reduction rules are applied correctly.

By handling dynamic duplication in a specialized manner, `reduceRefAt_DupF` contributes to the overall efficiency and correctness of the HVM3 runtime. It ensures that parallel computations are managed effectively, leveraging the Interaction Combinator model to achieve high performance on massively parallel hardware. This function is a critical component of the reduction engine, enabling the runtime to handle complex, parallel computations with ease.
# reduceRefAt_FreshF
The `reduceRefAt_FreshF` function plays a critical role in the HVM3 runtime by handling the reduction of terms tagged with the `FRESH_F` label. These terms represent requests for fresh duplication labels, which are essential for the `DUP` operation in the Interaction Combinator model. The `DUP` operation is used to duplicate terms in the computational graph, enabling parallel evaluation and efficient handling of complex computations.

When `reduceRefAt_FreshF` is invoked, it retrieves the necessary information from the `book`, `host`, `loc`, and `ari` parameters. The `book` provides access to function definitions and metadata, while `host` and `loc` specify the memory locations of the term being reduced and its associated location. The `ari` parameter indicates the arity of the term, which influences the structure of the duplication.

The function then generates a fresh duplication label, ensuring that each `DUP` operation is uniquely identified. This is crucial for maintaining the integrity of the computational graph and preventing conflicts during parallel execution. The fresh label is returned as a term, which can then be used in subsequent reduction steps.

In summary, `reduceRefAt_FreshF` is a key component of the HVM3 runtime's reduction mechanism, enabling the generation of fresh duplication labels and supporting the efficient parallel evaluation of terms in the Interaction Combinator model.
# reduceRefAt_LogF
The `reduceRefAt_LogF` function is responsible for handling the reduction of terms tagged with `LOG_F`, which represent logging operations in the HVM3 runtime. When a term with the `LOG_F` tag is encountered, `reduceRefAt_LogF` is called with the following parameters:
- `book`: The `Book` data structure containing function definitions and metadata.
- `host`: The location of the term in memory.
- `loc`: The location of the subterm to be logged.
- `ari`: Additional metadata or arguments associated with the term.

The function performs the following steps:
1. **Extract the Term**: It retrieves the term to be logged from the specified memory location.
2. **Log the Term**: It logs the extracted term, typically for debugging or diagnostic purposes.
3. **Return a Result**: It returns a result, often a placeholder value like `0`, to indicate that the logging operation has been completed.

This function is crucial for debugging and monitoring the execution of programs in the HVM3 runtime, as it allows developers to inspect the state of the computation at specific points. By logging terms, developers can gain insights into the behavior of the program and identify potential issues or optimizations.
# reduceRefAt_SupF
The `reduceRefAt_SupF` function operates within the `reduceRefAt` function, which is responsible for reducing terms at a specific location (`Loc`) in the computational graph. When `reduceRefAt` encounters a term with the `SUP_F` function ID, it delegates the reduction task to `reduceRefAt_SupF`. This function takes several parameters:
- `book`: The `Book` data structure that contains function definitions and metadata.
- `host`: The location of the term being reduced.
- `loc`: The location of the superposed term.
- `ari`: The arity of the term, which is used to determine how many arguments the term expects.

The `reduceRefAt_SupF` function is crucial for handling the `SUP` operation, which allows for the combination of two terms into a single superposed term. This operation is essential for enabling parallel evaluation, as it allows the runtime to explore multiple computational paths simultaneously. By reducing superposed terms correctly, `reduceRefAt_SupF` ensures that the parallel execution model of the HVM3 runtime functions as intended, leading to efficient and correct evaluation of complex, parallel computations.
# reduceRefSup
The `reduceRefSup` function operates by taking a reference term (`ref`) and an index (`idx`) as inputs. It first increments the iteration counter (`inc_itr()`) to track the number of reductions performed. The function then extracts the location (`ref_loc`) and label (`ref_lab`) from the reference term. The label is decoded to obtain the function ID (`fun_id`) and arity (`arity`), which are essential for determining the structure of the term being reduced.

The function checks if the provided index is valid (i.e., within the bounds of the arity). If the index is invalid, it logs an error and terminates the reduction process. Assuming the index is valid, `reduceRefSup` proceeds to handle the superposition by applying the appropriate reduction rules. This involves creating new terms that represent the parallel evaluation paths, ensuring that the computational graph remains consistent and that the reduction process can continue efficiently.

The purpose of `reduceRefSup` is to manage the interaction between reference terms and superposition, a fundamental aspect of the Interaction Combinator model. By correctly reducing these terms, the function enables the runtime to handle complex, parallel computations, leveraging the massively parallel hardware to achieve high performance. This function is a key component in the system's ability to execute programs efficiently, ensuring that the reduction rules are applied correctly and that the computational graph is maintained in a state that supports parallel evaluation.
# reduce_app_ctr
In the HVM3 codebase, the `reduce_app_ctr` function is invoked when the reduction engine encounters an application term (`APP`) where the function being applied is a constructor (`CTR`). Constructors are used to build data structures, and applying a constructor to an argument typically results in a new term that represents the constructed value. The `reduce_app_ctr` function is responsible for handling this specific case, ensuring that the application of a constructor is correctly reduced.

The function is defined in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the reduction engine processes an application term. The function takes two arguments: the application term (`app`) and the constructor term (`ctr`). It then performs the necessary reduction steps, which may involve creating a new term or modifying existing terms in memory.

The `reduce_app_ctr` function is part of a larger family of reduction functions (`reduce_app_era`, `reduce_app_lam`, `reduce_app_sup`, etc.) that handle different types of function applications. Each of these functions is tailored to handle a specific type of function (e.g., eraser, lambda, superposition, constructor), ensuring that the reduction engine can efficiently and correctly evaluate terms in the Interaction Combinator model.

In summary, `reduce_app_ctr` plays a crucial role in the HVM3 runtime by managing the reduction of application terms involving constructors, ensuring that the evaluation of terms proceeds correctly and efficiently.
# reduce_app_era
The `reduce_app_era` function is a critical component of the HVM3 runtime's reduction engine. It is specifically designed to handle the case where an application term (`APP`) is applied to an erasure term (`ERA`). In the Interaction Combinator model, an erasure term represents a computation that can be safely discarded, as it does not contribute to the final result. When the runtime encounters such a scenario, it calls `reduce_app_era` to simplify the term graph.

The function works by taking two arguments: the application term (`app`) and the erasure term (`era`). It then performs the necessary reduction to eliminate the erasure term from the computation. This reduction is essential for maintaining the efficiency of the runtime, as it prevents unnecessary computations from being carried out, especially in a massively parallel environment where computational resources are at a premium.

The `reduce_app_era` function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the runtime detects the appropriate term configuration. This seamless integration between the high-level Haskell code and the low-level C code ensures that the reduction rules are applied correctly and efficiently, contributing to the overall performance of the HVM3 runtime.

In summary, `reduce_app_era` plays a vital role in the HVM3 runtime by optimizing the term graph and eliminating redundant computations, thereby enhancing the system's ability to handle complex, parallel computations efficiently.
# reduce_app_lam
The `reduce_app_lam` function performs the following steps:
1. **Identify the Lambda and Application**: The function takes two arguments: `app`, which represents the application term, and `lam`, which represents the lambda term.
2. **Substitute the Argument**: The function substitutes the argument of the application into the body of the lambda. This is the essence of beta-reduction in lambda calculus.
3. **Return the Reduced Term**: After performing the substitution, the function returns the reduced term, which is the result of applying the lambda to its argument.

In the context of the HVM3 codebase, `reduce_app_lam` is part of the broader reduction mechanism that ensures terms are evaluated correctly and efficiently. It is one of several reduction functions (like `reduce_app_era`, `reduce_let`, etc.) that handle specific cases in the reduction process. The function is crucial for the correct execution of functional programs, as it directly implements one of the core operations of lambda calculus.

The function is optimized for performance, as it operates at the low level of the C runtime, ensuring that the reduction process is as fast as possible. This is particularly important in a parallel runtime system like HVM3, where efficient term reduction is key to achieving high performance on massively parallel hardware.
# reduce_app_sup
In the HVM3 codebase, the `reduce_app_sup` function is invoked when the reduction engine encounters an application (`APP`) term that is being applied to a superposition (`SUP`) term. The superposition term represents a parallel combination of two terms, and the application term represents a function application. The `reduce_app_sup` function is responsible for distributing the application across the components of the superposition, effectively enabling parallel evaluation.

The function works by decomposing the superposition into its constituent parts and then applying the application to each part separately. This ensures that the computation is carried out in parallel, leveraging the massively parallel hardware that HVM3 is designed to run on. The result is a new superposition term that combines the results of the individual applications.

This reduction rule is crucial for maintaining the efficiency and correctness of the parallel evaluation process in HVM3. By handling the interaction between application and superposition terms, `reduce_app_sup` ensures that the system can fully exploit the parallelism inherent in the Interaction Combinator model, leading to high-performance execution of complex computations.
# reduce_app_w32
The `reduce_app_w32` function plays a crucial role in the HVM3 runtime by managing the reduction of terms when a 32-bit word (`W32`) is applied to another term. In the Interaction Combinator model, terms are represented as nodes in a computational graph, and reduction rules like `reduce_app_w32` dictate how these nodes interact and transform during evaluation. Specifically, `reduce_app_w32` handles the case where an application term (`APP`) is applied to a `W32` term, ensuring that the operation is executed correctly within the runtime's memory model. This function is part of the low-level C backend, which is responsible for efficient memory management and parallel execution. By processing `W32` terms appropriately, `reduce_app_w32` contributes to the overall performance and correctness of the HVM3 system, particularly in scenarios involving numerical computations or bit-level operations. The function's integration into the reduction engine highlights its importance in the runtime's ability to handle diverse term types and execute complex, parallel computations efficiently.
# reduce_at
The `reduce_at` function is responsible for reducing a given term to its normal form by applying specific reduction rules based on the term's type. It is a recursive function that processes terms by examining their tags and labels, and then performing the appropriate reduction operations. For example, when encountering an `APP` term, it reduces both the function and the argument before applying the function to the argument. Similarly, for `MAT` terms, it reduces the value being matched and the corresponding case branches. The function also handles special cases like `DUP` and `SUP`, which are essential for managing parallel computations. Additionally, `reduce_at` interacts with the memory management system, using functions like `got` and `set` to read and write terms at specific memory locations. This ensures that the runtime can efficiently manage and manipulate terms during the reduction process. Overall, `reduce_at` is a cornerstone of the HVM3 runtime, enabling the efficient execution of parallel and functional programs.
# reduce_dup_ctr
The `reduce_dup_ctr` function plays a crucial role in the HVM3 runtime by managing the interaction between duplication and constructor terms. In the Interaction Combinator model, duplication terms (`DUP`) are used to create multiple copies of a term, while constructor terms (`CTR`) represent structured data or function applications. When a `DUP` term encounters a `CTR` term, `reduce_dup_ctr` is called to handle this specific interaction.

The function works by decomposing the constructor term into its constituent parts and then distributing these parts across the duplicated terms. This ensures that the duplication is correctly propagated through the computational graph, maintaining the integrity of the parallel evaluation process. The function is part of a larger set of reduction rules (e.g., `reduce_dup_era`, `reduce_dup_lam`, `reduce_dup_sup`) that handle different types of interactions between terms, allowing the runtime to efficiently reduce complex expressions to their normal forms.

In the provided context, `reduce_dup_ctr` is invoked within the `reduceAt` function, which is responsible for recursively reducing terms to their normal form. The function is called when the term being reduced is identified as a `CTR` term, and it ensures that the duplication operation is correctly applied to the constructor term. This is essential for maintaining the correctness of the parallel evaluation process and for ensuring that the runtime can efficiently handle complex, parallel computations.

Overall, `reduce_dup_ctr` is a key component of the HVM3 runtime's reduction engine, enabling the system to handle the interaction between duplication and constructor terms in a way that supports efficient parallel execution.
# reduce_dup_era
In the HVM3 codebase, the `reduce_dup_era` function plays a crucial role in the reduction process by handling a specific interaction rule between `DUP` and `ERA` terms. When a `DUP` term (which duplicates a term) encounters an `ERA` term (which erases a term), the `reduce_dup_era` function is invoked to simplify the graph. This function replaces both the `DUP` and `ERA` terms with a single `ERA` term, effectively erasing the duplicated structure. This simplification is essential for maintaining the efficiency and correctness of the parallel evaluation process, as it reduces unnecessary computations and ensures that the graph remains as compact as possible. The function is implemented in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`), with the C implementation handling the low-level details of term manipulation and memory management. By optimizing the interaction between `DUP` and `ERA` terms, `reduce_dup_era` contributes to the overall performance of the HVM3 runtime, enabling it to handle complex, parallel computations efficiently.
# reduce_dup_lam
The `reduce_dup_lam` function is responsible for reducing a duplication (`DUP`) term in the presence of a lambda (`LAM`) term. In the Interaction Combinator model, duplication terms are used to create multiple copies of a term, while lambda terms represent functions. When a `DUP` term interacts with a `LAM` term, the `reduce_dup_lam` function ensures that the duplication is correctly propagated through the lambda, creating new lambda terms for each duplicated copy.

The function operates by:
1. **Identifying the Interaction**: The function is called when the reduction engine detects a `DUP` term that needs to interact with a `LAM` term.
2. **Creating New Lambda Terms**: The function creates new lambda terms (`Î»x0(f0)` and `Î»x1(f1)`) for each duplicated copy, ensuring that the duplication is correctly handled within the lambda.
3. **Updating the Term Structure**: The function updates the term structure to reflect the new lambda terms and the duplicated copies, ensuring that the computational graph remains consistent.
4. **Continuing the Reduction**: After performing the necessary transformations, the function continues the reduction process, allowing the runtime to further evaluate the terms.

This function is crucial for maintaining the correctness and efficiency of the parallel evaluation process, as it ensures that duplications are correctly handled within the context of lambda terms, enabling the runtime to leverage the massively parallel hardware effectively.
# reduce_dup_ref
The `reduce_dup_ref` function is responsible for reducing a term that involves a duplication (`DUP`) interacting with a reference (`REF`). In the HVM3 runtime, duplications are used to create multiple copies of a term, while references point to specific terms in memory. When a `DUP` term interacts with a `REF` term, the `reduce_dup_ref` function ensures that the duplication is correctly applied to the referenced term, creating multiple copies of it as needed.

The function operates by first identifying the referenced term and then applying the duplication to it. This involves creating new terms that represent the duplicated copies and updating the memory locations accordingly. The function ensures that the duplication process is handled efficiently, supporting the parallel execution model of the HVM3 runtime.

In the provided code context, the `reduce_dup_ref` function is imported from the C backend (`hvm.c`) into the Haskell frontend (`hvm.hs`) using a foreign function interface (FFI). This allows the Haskell code to invoke the C implementation of the reduction rule, ensuring that the low-level details of term manipulation are handled efficiently by the C runtime.

Overall, `reduce_dup_ref` plays a crucial role in the HVM3 runtime by enabling the correct and efficient handling of duplications and references, which are essential for the parallel evaluation of terms in the Interaction Combinator model.
# reduce_dup_sup
The `reduce_dup_sup` function plays a crucial role in the parallel evaluation mechanism of the HVM3 runtime. When a `DUP` term interacts with a `SUP` term, the function applies the DUP-SUP reduction rule, which is essential for managing parallel computations. The rule handles two scenarios:
1. If the labels of the `DUP` and `SUP` terms match, the function directly assigns the components of the `SUP` term to the `DUP` term.
2. If the labels do not match, the function creates new `SUP` terms for the components of the `DUP` term and ensures that the original `SUP` term's components are correctly distributed.

This process allows the runtime to efficiently manage parallel computations by ensuring that terms are correctly duplicated and superposed, enabling the system to leverage massively parallel hardware effectively. The `reduce_dup_sup` function is a key component of the reduction engine, contributing to the overall performance and correctness of the HVM3 runtime.
# reduce_dup_w32
The `reduce_dup_w32` function plays a crucial role in the HVM3 runtime by managing the duplication of 32-bit word terms. In the Interaction Combinator model, duplication is a fundamental operation that allows terms to be shared across multiple contexts, enabling parallel evaluation. When a term tagged as `W32` (or `CHR`, which is treated similarly) is encountered during a duplication operation, `reduce_dup_w32` is called to handle the specific reduction rule for duplicating 32-bit words.

The function ensures that the 32-bit word is correctly copied to both branches of the duplication, preserving the value and allowing subsequent operations to proceed without errors. This is essential for maintaining the correctness of the computational graph, especially in a parallel execution environment where terms may be evaluated concurrently.

The context provided in `hvm.hs` and `hvm.c` shows that `reduce_dup_w32` is integrated into the reduction engine, where it is invoked based on the tag of the term being processed. This integration allows the runtime to efficiently handle different types of terms with specific reduction rules, ensuring that the overall evaluation process is both correct and performant.

In summary, `reduce_dup_w32` is a specialized function within the HVM3 runtime that ensures the correct duplication of 32-bit word terms, supporting the parallel evaluation model and maintaining the integrity of the computational graph.
# reduce_let
The `reduce_let` function plays a pivotal role in the HVM3 runtime system by managing the reduction of `LET` terms, which are used to bind values to variables within the computational graph. Hereâ€™s a detailed breakdown of its purpose and operation:

1. **Handling `LET` Terms**:
   - `LET` terms are used to bind a value to a variable, enabling the use of that value in subsequent computations. The `reduce_let` function is responsible for reducing these terms, ensuring that the bound value is correctly propagated through the computational graph.

2. **Dual Implementation**:
   - The function is implemented in both Haskell and C. In Haskell, `reduceLet` provides a high-level interface for interacting with the C runtime. In C, `reduce_let` defines the low-level logic for reducing `LET` terms, ensuring efficient execution.

3. **Evaluation Modes**:
   - The function supports both lazy and strict evaluation modes. In lazy mode, the value is retrieved from memory using `got` and then reduced. In strict mode, the value is first reduced to its normal form using `reduceAt` before the reduction is applied. This ensures that `LET` terms are handled correctly in both evaluation strategies.

4. **Integration with the Runtime**:
   - The function is integrated into the broader reduction engine, working in conjunction with other reduction functions like `reduce` and `reduceAt` to ensure that all terms are fully evaluated. This integration is crucial for maintaining the correctness and efficiency of the runtime system.

5. **Memory Management**:
   - The function interacts with the runtime's memory management system, using functions like `got` to retrieve values from memory and `set` to update the computational graph. This ensures that the bound value is correctly stored and accessible for subsequent computations.

6. **Parallel Execution**:
   - By correctly handling `LET` terms, the function supports the system's parallel execution model. Properly reduced `LET` terms enable the runtime to efficiently manage and process parallel computations, leveraging the Interaction Combinator model for high performance.

In summary, `reduce_let` is a fundamental function in the HVM3 runtime system, essential for managing variable bindings and ensuring the correct evaluation of expressions involving `LET` terms. Its dual implementation and support for different evaluation modes make it a versatile and critical component of the system.
# reduce_mat_ctr
The `reduce_mat_ctr` function plays a crucial role in the evaluation of pattern matching constructs within the HVM3 runtime. When a `MAT` term is encountered, it is used to match against different types of terms, including constructors (`CTR`). The `reduce_mat_ctr` function specifically handles the case where the term being matched is a constructor. 

In the Interaction Combinator model, constructors are used to represent data structures or specific values, and pattern matching is a fundamental operation for deconstructing these values. The `reduce_mat_ctr` function ensures that the pattern matching operation is correctly applied when the term being matched is a constructor. This involves simplifying the term graph by applying the appropriate reduction rule, which may involve further reductions or transformations of the term.

The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the runtime encounters a `MAT` term that needs to be reduced against a `CTR` term. The function's logic is designed to efficiently handle this specific interaction, contributing to the overall performance and correctness of the parallel evaluation process.

In summary, `reduce_mat_ctr` is a specialized reduction function that ensures the correct and efficient handling of pattern matching operations involving constructors, which is essential for the proper execution of programs in the HVM3 runtime.
# reduce_mat_era
In the HVM3 codebase, the `reduce_mat_era` function plays a crucial role in the reduction process, specifically when a pattern matching (`MAT`) term interacts with an erasure (`ERA`) term. The `MAT` term is used for pattern matching, while the `ERA` term represents an erasure or deletion of a term. When these two terms interact, the `reduce_mat_era` function simplifies the computation by effectively removing the `ERA` term, as it does not contribute to the final result. This optimization is essential for maintaining the efficiency of the runtime, especially in a massively parallel execution environment.

The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the reduction engine encounters a `MAT` term that needs to be reduced with an `ERA` term. The `reduce_mat_era` function ensures that the interaction between these terms is handled correctly, adhering to the rules of the Interaction Combinator model. By eliminating unnecessary terms, the function helps to streamline the computation, reducing the overall complexity and improving the performance of the runtime system.

In summary, `reduce_mat_era` is a specialized reduction rule that optimizes the evaluation of pattern matching terms when they interact with erasure terms, contributing to the overall efficiency and correctness of the HVM3 runtime.
# reduce_mat_lam
The `reduce_mat_lam` function is a critical component of the HVM3 runtime's reduction engine. It specifically handles the case where a pattern matching term (`MAT`) interacts with a lambda term (`LAM`). In the Interaction Combinator model, this interaction is governed by the MAT-LAM reduction rule, which simplifies the computation by reducing the combination of these two terms to a simpler form, often resulting in a `âŠ¥` (bottom) term, which represents an undefined or non-computable value.

The function is called during the reduction process when the runtime encounters a `MAT` term that needs to be matched against a `LAM` term. This is part of the broader term reduction mechanism that ensures all terms are evaluated to their normal form. The `reduce_mat_lam` function is implemented in the C backend for performance reasons, as the reduction engine needs to be highly efficient to support the massively parallel execution model of HVM3.

In the Haskell frontend, the function is invoked through a foreign function interface (FFI), which allows Haskell code to call C functions directly. This is done in the context of the `reduceAt` function, which orchestrates the reduction of terms by applying the appropriate reduction rules based on the term's type. The `reduce_mat_lam` function is one of many such rules, each designed to handle specific interactions between different types of terms.

Overall, `reduce_mat_lam` plays a crucial role in the HVM3 runtime by ensuring that the MAT-LAM interaction is handled correctly, contributing to the efficient and parallel execution of programs within the Interaction Combinator model.
# reduce_mat_sup
The `reduce_mat_sup` function plays a crucial role in the HVM3 runtime by enabling the parallel evaluation of pattern matching (`MAT`) operations on superposed (`SUP`) terms. When a `MAT` term encounters a `SUP` term, the `reduce_mat_sup` function decomposes the `SUP` term into its constituent parts and applies the pattern matching operation to each part in parallel. This allows the runtime to efficiently handle cases where a pattern match needs to be performed on multiple possible values simultaneously, which is a common scenario in parallel functional programming.

The function works by first extracting the components of the `SUP` term, which typically represent multiple possible values or states. It then applies the `MAT` operation to each component, effectively distributing the pattern matching across the superposed terms. This decomposition and parallel application of the `MAT` operation are essential for maintaining the efficiency and correctness of the parallel evaluation process.

In the context of the HVM3 codebase, `reduce_mat_sup` is one of several reduction rules that handle specific interactions between different types of terms. These rules are critical for ensuring that the runtime can correctly and efficiently reduce terms to their normal forms, even in the presence of complex, parallel computations. By handling the interaction between `MAT` and `SUP` terms, `reduce_mat_sup` contributes to the overall performance and scalability of the HVM3 runtime, enabling it to execute highly parallel programs on modern hardware.
# reduce_mat_w32
The `reduce_mat_w32` function plays a crucial role in the evaluation of pattern matching operations involving 32-bit words (`W32`). When a `MAT` term is encountered during the reduction process, the runtime checks the type of the term it is matching against. If the term is a `W32`, the `reduce_mat_w32` function is invoked to handle the reduction. This function is responsible for determining the appropriate branch to take based on the value of the `W32` term, effectively reducing the `MAT` term to its normal form. The function is part of the Interaction Combinator model, which enables parallel evaluation of terms, and it ensures that pattern matching operations involving `W32` terms are executed efficiently. The implementation in `hvm.c` includes logic to handle the specific reduction rules for `W32` terms, contributing to the overall performance and correctness of the HVM3 runtime system.
# reduce_opx_ctr
The `reduce_opx_ctr` function plays a crucial role in the HVM3 runtime's reduction engine. It is responsible for reducing terms that involve an operation extension (`OPX`) and a constructor (`CTR`). This function is part of the low-level C backend, which handles the actual computation and memory management during term reduction.

When the reduction engine encounters an `OPX` term followed by a `CTR` term, it calls `reduce_opx_ctr` to apply the appropriate reduction rules. The function processes these terms by executing the necessary computational steps to reduce them to their normal form. This involves handling the interaction between the operation extension and the constructor, ensuring that the reduction is performed correctly and efficiently.

The `reduce_opx_ctr` function is imported into the Haskell frontend via the FFI, allowing the high-level Haskell code to delegate the reduction of `OPX` and `CTR` terms to the optimized C implementation. This separation of concerns between the Haskell frontend and the C backend enables the HVM3 runtime to leverage the strengths of both languages: Haskell for high-level term manipulation and C for low-level, efficient computation.

Overall, `reduce_opx_ctr` is a critical component of the HVM3 runtime's reduction engine, ensuring that terms involving operation extensions and constructors are reduced correctly and efficiently, contributing to the system's ability to handle complex, parallel computations.
# reduce_opx_era
The `reduce_opx_era` function is responsible for reducing an `OPX` term when it encounters an `ERA` term. In the context of the Interaction Combinator model, `ERA` represents an erasure or deletion operation, which effectively removes or simplifies terms in the computational graph. When an `OPX` term interacts with an `ERA` term, the `reduce_opx_era` function applies the appropriate reduction rule to simplify the computation.

In the Haskell frontend (`hvm.hs`), `reduce_opx_era` is called within the `OPX` case of the reduction logic, specifically when the term being reduced is identified as an `ERA` term. This indicates that the function is part of the high-level reduction strategy, ensuring that the correct reduction rules are applied based on the term's type.

In the C backend (`hvm.c`), `reduce_opx_era` is implemented as a low-level function that directly manipulates the terms in memory. The function takes two arguments: the `OPX` term and the `ERA` term. It then performs the necessary operations to reduce the `OPX` term in the presence of the `ERA` term, simplifying the computational graph and ensuring efficient execution.

Overall, `reduce_opx_era` plays a crucial role in the HVM3 runtime by handling a specific interaction between `OPX` and `ERA` terms, contributing to the system's ability to efficiently evaluate complex, parallel computations.
# reduce_opx_lam
The `reduce_opx_lam` function is a critical component of the HVM3 runtime's reduction engine, which is responsible for evaluating terms in the computational graph. Specifically, this function handles the reduction of an `OPX` term when it interacts with a `LAM` term. The `OPX` term represents an operation extension, which is a placeholder for extending the functionality of the runtime, while the `LAM` term represents a lambda abstraction, which is a fundamental construct in functional programming.

When the runtime encounters an `OPX` term that needs to interact with a `LAM` term, it calls the `reduce_opx_lam` function to perform the reduction. The function processes the interaction by simplifying the terms, effectively reducing the complexity of the computation. This reduction is essential for ensuring that the runtime can efficiently evaluate terms and produce the correct results.

The `reduce_opx_lam` function is part of a larger set of reduction rules that handle various interactions between different types of terms (e.g., `ERA`, `REF`, `NUM`, `CON`, `DUP`). Each reduction rule is designed to process specific term interactions, ensuring that the runtime can handle a wide range of computational scenarios. By implementing these reduction rules, the HVM3 runtime can leverage the Interaction Combinator model to achieve high performance and scalability on massively parallel hardware.

In summary, the `reduce_opx_lam` function plays a crucial role in the HVM3 runtime by handling the reduction of `OPX` terms when they interact with `LAM` terms. This function is part of the broader reduction mechanism that ensures the correct and efficient evaluation of terms in the computational graph, enabling the runtime to execute complex, parallel computations effectively.
# reduce_opx_sup
The `reduce_opx_sup` function operates by decomposing the `SUP` term into its constituent parts and then applying the `OPX` operation to each part individually. This allows the system to handle the superposition of terms in a parallel manner, leveraging the underlying hardware's capabilities for concurrent execution. The function ensures that the result of the reduction is a new term that correctly represents the combination of the `OPX` and `SUP` terms, maintaining the integrity of the computational graph.

In the context of the HVM3 codebase, `reduce_opx_sup` is crucial for enabling efficient parallel evaluation of terms. It is one of many reduction rules that collectively form the reduction engine, which is responsible for transforming terms into their normal forms. By handling the interaction between `OPX` and `SUP` terms specifically, `reduce_opx_sup` contributes to the overall performance and scalability of the system, particularly in scenarios involving complex, parallel computations.
# reduce_opx_w32
The `reduce_opx_w32` function plays a crucial role in the evaluation of terms within the HVM3 runtime. When the runtime encounters a term with the `OPX` tag and a `W32` tag, it invokes `reduce_opx_w32` to handle the reduction. This function takes two arguments: `opx`, which represents the operation to be performed, and `w32`, which is the 32-bit word on which the operation is applied.

The function's primary responsibility is to execute the operation on the 32-bit word and return the resulting term. This involves interpreting the operation encoded in the `opx` term and applying it to the `w32` term. The exact nature of the operation depends on the specific context in which `reduce_opx_w32` is called, but it typically involves arithmetic or bitwise operations on the 32-bit word.

The `reduce_opx_w32` function is part of a larger family of reduction functions that handle different combinations of tags and operations. These functions are essential for the correct and efficient execution of programs in the HVM3 runtime, as they ensure that all terms are reduced to their normal form according to the rules of the Interaction Combinator model.

In summary, `reduce_opx_w32` is a specialized reduction function that processes terms involving operations on 32-bit words, contributing to the overall evaluation mechanism of the HVM3 runtime.
# reduce_opy_ctr
The `reduce_opy_ctr` function is used in the context of the HVM3 runtime's reduction engine, which is built around the Interaction Combinator model. This model enables parallel evaluation of terms through a graph-based computational model. The `reduce_opy_ctr` function specifically handles the case where an `OPY` operation interacts with a constructor (`CTR`). 

In the HVM3 codebase, terms are represented by the `Term` data type, which encodes a tag, label, and location. The tag identifies the type of the term, and in this case, the `CTR` tag indicates that the term is a constructor. The `OPY` operation is one of the interaction combinators that the runtime uses to manage term interactions.

When the reduction engine encounters an `OPY` operation with a `CTR` term, it calls `reduce_opy_ctr` to perform the necessary reduction. This function takes two arguments: the `OPY` term and the `CTR` term. The function then applies the specific reduction rules for this interaction, which are defined by the Interaction Combinator model. The result of this reduction is a new term that represents the outcome of the interaction.

The `reduce_opy_ctr` function is part of a larger family of reduction functions, each handling different combinations of operations and term types. These functions are essential for the correct and efficient execution of programs in the HVM3 runtime, as they ensure that terms are reduced to their normal form according to the rules of the Interaction Combinator model.

In summary, `reduce_opy_ctr` is a specialized reduction function in the HVM3 runtime that handles the interaction between an `OPY` operation and a constructor (`CTR`) term, ensuring that the term is correctly reduced according to the rules of the Interaction Combinator model.
# reduce_opy_era
In the HVM3 runtime, the `reduce_opy_era` function is invoked when an `OPY` term encounters an `ERA` term during the reduction process. The `OPY` term typically represents a specific operation or transformation, while the `ERA` term is used to erase or remove parts of the computation graph. The `reduce_opy_era` function defines the behavior of this interaction, ensuring that the `ERA` term effectively cancels out or simplifies the `OPY` term, leading to a more efficient computation.

The function is implemented in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) when the runtime encounters an `OPY` term followed by an `ERA` term. The function takes two arguments: the `OPY` term and the `ERA` term. It then performs the necessary reduction steps, which may involve simplifying the terms, updating the computation graph, or freeing memory resources.

The `reduce_opy_era` function is part of the broader reduction engine in HVM3, which applies various reduction rules based on the types of terms encountered. By handling the specific case of `OPY` and `ERA` interactions, `reduce_opy_era` contributes to the overall efficiency and correctness of the parallel evaluation process in the HVM3 runtime.
# reduce_opy_lam
The `reduce_opy_lam` function plays a critical role in the HVM3 runtime by handling the reduction of terms when an `OPY` operation encounters a `LAM` term. In the Interaction Combinator model, `OPY` represents a specific interaction rule that must be applied when certain term types interact. When the term being processed is a lambda (`LAM`), `reduce_opy_lam` ensures that the reduction is performed correctly, maintaining the integrity of the computational graph.

The function takes two arguments: `opy` (the `OPY` term) and `era` (the term being processed, which in this case is a `LAM`). It then applies the appropriate reduction rule, which is defined in the C implementation (`hvm.c`). This rule is part of the broader reduction engine that ensures all terms are evaluated to their normal form, enabling the runtime to execute programs efficiently on massively parallel hardware.

By handling this specific interaction, `reduce_opy_lam` contributes to the overall performance and correctness of the HVM3 runtime, ensuring that lambda terms are processed correctly in a parallel execution environment.
# reduce_opy_sup
The `reduce_opy_sup` function is defined in the C backend of the HVM3 codebase and is imported into the Haskell frontend via a foreign function interface (FFI). Its purpose is to apply the `OPY` operation to a `SUP` term, which is a superposition of two terms. The function takes two arguments: `opy`, which represents the `OPY` operation, and `sup`, which represents the `SUP` term. The function then constructs a new term that represents the parallel application of the `OPY` operation to the components of the `SUP` term.

In the context of the Interaction Combinator model, this reduction rule ensures that the `OPY` operation is correctly applied in a parallel context, allowing for efficient evaluation of terms on massively parallel hardware. The function is called during the reduction process when the runtime encounters an `OPY` operation applied to a `SUP` term. The result of this reduction is a new term that can be further reduced or evaluated as part of the overall computation.

The `reduce_opy_sup` function is part of a larger family of reduction functions that handle different combinations of operations and term types, ensuring that the runtime can efficiently evaluate complex, parallel computations. Its role is crucial in maintaining the correctness and performance of the HVM3 runtime, particularly in scenarios where parallel evaluation is required.
# reduce_opy_w32
The `reduce_opy_w32` function plays a crucial role in the evaluation of terms within the HVM3 runtime. Specifically, it handles the reduction of an `OPY` term when it interacts with a `W32` term. The `OPY` term is an operation that needs to be applied to another term, and the `W32` term represents a 32-bit word. When the reduction engine encounters an `OPY` term with a `W32` term, it calls `reduce_opy_w32` to perform the necessary computation. This function is part of the broader reduction mechanism that ensures terms are evaluated correctly and efficiently, leveraging the Interaction Combinator model to achieve parallel execution. The function is implemented in the C backend for performance reasons and is integrated into the Haskell frontend to maintain the high-level logic of the reduction process. This separation allows the system to combine the expressive power of Haskell with the performance benefits of C, ensuring that the runtime can handle complex, parallel computations effectively.
# reduce_ref
The `reduce_ref` function operates within the HVM3 runtime to manage the reduction of reference terms (`REF`). When a term is identified as a reference, `reduce_ref` is invoked to resolve it. The function first retrieves the referenced term from memory using the `got` function, which accesses the term's location. Once the term is fetched, `reduce_ref` examines its type and applies the corresponding reduction rules. This might involve further recursive reductions, especially if the referenced term is a complex expression or another reference.

In the context of the HVM3 codebase, `reduce_ref` is part of the broader reduction engine that ensures terms are evaluated correctly and efficiently. It works in conjunction with other reduction functions like `reduce_ref_sup`, which handles the reduction of superposed terms, and `reduceAt`, which manages the overall reduction process. By resolving references and applying the appropriate reduction rules, `reduce_ref` plays a crucial role in the parallel evaluation of terms, contributing to the system's high performance on massively parallel hardware.
# reduce_ref_sup
The `reduce_ref_sup` function operates in the following way:
1. **Input Parameters**: It takes two parameters: `ref`, which is the reference term, and `idx`, which is the index of the argument within the reference term that is a superposition (`SUP`).
2. **Initialization**: The function increments the iteration counter (`inc_itr()`) to track the number of reductions performed.
3. **Term Extraction**: It extracts the location (`ref_loc`) and label (`ref_lab`) from the reference term. The label is further decomposed into the function ID (`fun_id`) and arity (`arity`).
4. **Validation**: The function checks if the provided index (`idx`) is within the valid range of the arity. If not, it raises an error.
5. **Reduction Logic**: The function then proceeds to handle the superposition term by decomposing it and applying the reference function to each component. This ensures that the superposition is correctly evaluated in parallel, leveraging the Interaction Combinator model.
6. **Parallel Execution**: By handling the superposition in this manner, `reduce_ref_sup` enables the runtime to execute multiple branches of the computation simultaneously, optimizing for performance on parallel hardware.

In summary, `reduce_ref_sup` is essential for managing the interaction between reference terms and superposition terms, ensuring that the runtime can efficiently handle parallel computations and maintain the correctness of the evaluation process.
# runtime_c
The `runtime_c` symbol serves as a bridge between the Haskell frontend and the C backend in the HVM3 codebase. It embeds the contents of the `Runtime.c` file, which contains the essential low-level functions and data structures needed for the runtime execution of HVM3 programs. When the `cliRun` function is invoked, it reads the input file, parses it into a `Book` data structure, and then compiles the functions into C code. The `runtime_c` string is included in the generated C file content, ensuring that the runtime support is always present. This approach allows the Haskell frontend to dynamically generate the necessary C code for execution, while maintaining a clear separation between the high-level term manipulation and the low-level runtime operations. The `runtime_c` symbol thus plays a crucial role in the compilation and execution pipeline of the HVM3 system, enabling efficient and parallel execution of programs on modern hardware.
# set
The `set` function is responsible for writing a `Term` to a specified memory location (`Loc`). This operation is essential for the runtime's memory model, which is based on Interaction Combinators. The function is used in several key scenarios:

1. **Term Reduction**: During the reduction process, `set` is used to update the state of terms in memory. For example, when reducing a `DUP` term, the function writes the new terms to their respective locations, ensuring that the computational graph is correctly updated.

2. **Memory Management**: The `set` function is used in conjunction with `allocNode` to manage memory allocation. After allocating memory for a new node, `set` is called to initialize the node with the appropriate terms.

3. **Compilation**: During the compilation process, `set` is used to write compiled terms to memory. This is particularly important when translating high-level `Core` terms into low-level C code, as it ensures that the runtime can correctly execute the compiled terms.

4. **Parallel Execution**: In parallel computations, `set` is used to manage the state of terms across different execution paths. This is crucial for ensuring that parallel evaluations are correctly synchronized and that the final result is consistent.

The `set` function is also used in various reduction rules, such as `reduce_app_sup`, `reduce_dup_lam`, and `reduce_mat_sup`, where it updates the state of terms based on the specific reduction logic. Additionally, it is used in the `compileFullCore` and `compileFastCore` functions to write compiled terms to memory, ensuring that the runtime can execute them correctly.

Overall, the `set` function is a critical component of the HVM3 runtime, enabling efficient memory management and ensuring that terms are correctly updated and manipulated during execution. Its widespread use across the codebase highlights its importance in the overall functioning of the system.
# setRefIds
The `setRefIds` function is used during the creation of the `Book` data structure, which stores function definitions and metadata. When the `createBook` function is called, it processes a list of function definitions and constructs a `Book` that maps function names to their corresponding IDs. The `setRefIds` function is applied to each `Core` term within these definitions to ensure that all `Ref` constructors are annotated with the correct function IDs.

The function works by pattern matching on the `Core` term type. For each type of term (e.g., `Var`, `Let`, `Lam`, `App`, etc.), it recursively applies `setRefIds` to the subterms. When it encounters a `Ref` constructor, it looks up the function name in the provided `fids` map and assigns the corresponding ID to the `Ref` constructor. This ensures that all references to functions are correctly annotated with their IDs, which is crucial for the runtime to efficiently lookup and execute these functions.

For example, if a `Ref` constructor references a function named "foo", `setRefIds` will look up "foo" in the `fids` map and assign the corresponding ID to the `Ref` constructor. This ID is then used by the runtime to quickly locate and execute the function during evaluation.

In summary, `setRefIds` plays a vital role in the compilation process by ensuring that all `Ref` constructors in the `Core` terms are correctly annotated with function IDs. This enables the runtime to efficiently manage and execute function references, contributing to the overall performance and correctness of the HVM3 system.
# set_itr
The `set_itr` function serves as a mechanism to update the iteration counter (`itr`) in the HVM3 runtime. This counter is essential for tracking the progress of computations, particularly in a parallel execution model where multiple terms are being evaluated simultaneously. In the Haskell frontend, `set_itr` is referenced when generating a string representation of the heap, indicating that the iteration count is part of the runtime state that can be inspected or logged. In the C backend, `set_itr` is implemented as a function that directly modifies the iteration counter, ensuring that the runtime can accurately manage and synchronize parallel computations. By updating the iteration counter, `set_itr` helps maintain the integrity of the computational state, enabling efficient and correct execution of programs in the HVM3 system.
# set_len
The `set_len` function is used to set the length of a memory block or data structure in the HVM3 runtime. In a system designed for parallel execution, managing memory efficiently is critical to avoid bottlenecks and ensure optimal performance. By setting the length of a memory block, the runtime can keep track of how much space is allocated and how much is in use, which is essential for operations like memory allocation, deallocation, and resizing. This function likely interacts with other memory management functions like `allocNode`, `set`, and `got` to ensure that the runtime can handle large-scale, parallel computations without running into memory issues. The `Loc` parameter suggests that the function operates on a specific memory location, updating its length property to reflect the current state of the data structure or memory block. This functionality is crucial for maintaining the integrity and efficiency of the runtime's memory model, especially in a system that leverages the Interaction Combinator model for parallel evaluation.
# showCore
The `showCore` function plays a crucial role in the HVM3 codebase by providing a way to visualize and inspect `Core` terms, which are the high-level representations of the computational graph. This is especially important during debugging or when developers need to understand the intermediate or final results of computations. The function is used in the `cliRun` function to print the results of normalization or collapse operations, depending on the run mode. By converting `Core` terms into a readable string format, `showCore` helps developers verify the correctness of the program's execution and facilitates easier debugging and analysis of the computational process.
# showHex
The `showHex` function plays a crucial role in the HVM3 codebase by providing a standardized way to represent numerical values in hexadecimal format. This is particularly useful for debugging, logging, and displaying memory addresses, labels, and other numerical data in a format that is both compact and easy to interpret. For example, in the `labToString` and `locToString` functions, `showHex` is used to convert labels and locations into hexadecimal strings, which are then padded with zeros to ensure a consistent length. Similarly, in the `heapToString` function, `showHex` is used to format memory addresses and iteration counters, making it easier to inspect the state of the heap during debugging. By abstracting the conversion logic into a single function, `showHex` promotes code reuse and ensures consistency across the codebase.
# showParseError
The `showParseError` function takes three parameters: a `filename` (which is often an empty string in the provided context), the `input` string that was being parsed, and a `ParseError` object representing the error that occurred. Its primary role is to format and display this error information in a user-friendly manner. This is particularly useful during the development and debugging phases, as it helps developers understand why their code failed to parse and where the issue might be located.

In the context of the HVM3 codebase, `showParseError` is called within the `doParseCore` and `doParseBook` functions. These functions attempt to parse `Core` terms and `Book` definitions, respectively. If the parsing process encounters an error, `showParseError` is used to output the error details before the function returns a default or placeholder value (e.g., `Ref "âŠ¥" 0 []` for `doParseCore`). This ensures that the program can continue running even if parsing fails, while still providing the necessary feedback to the developer.

Overall, `showParseError` plays a critical role in the robustness and usability of the HVM3 codebase, making it easier for developers to diagnose and fix parsing issues in their code.
# skip
The `skip` function is a critical component of the HVM3 parser, responsible for ignoring whitespace and comments in the input program. It is implemented as a parser monad (`ParserM`) that uses `skipMany` to repeatedly skip over spaces and comments. Specifically, it handles two types of input:
1. **Whitespace**: It skips over spaces using the `parseSpace` function, which matches any space character.
2. **Comments**: It skips over single-line comments using the `parseComment` function, which matches the `//` sequence and skips all characters until the end of the line.

By ignoring these irrelevant characters, `skip` ensures that the parser can focus on meaningful input, such as keywords, identifiers, and expressions, without being disrupted by formatting or comments. This functionality is crucial for the robustness and flexibility of the parser, allowing it to handle input programs with varying styles of formatting and commenting.

The `skip` function is used extensively throughout the parsing logic, as it is called before parsing almost every construct in the input program. This widespread usage highlights its importance as a foundational utility for the parser, enabling it to process input programs accurately and efficiently. Without `skip`, the parser would be prone to errors or misinterpretations due to the presence of whitespace or comments in the input.
# sqPop
The `sqPop` function is a critical component of the Simple Queue (`SQ`) data structure in the HVM3 codebase. Its primary purpose is to remove and return the first element from the queue, along with the updated queue. The function is implemented in a purely functional manner, meaning it does not modify the original queue but instead returns a new queue with the element removed.

The function works as follows:
1. If the queue is empty (i.e., both the popping list `xs` and the pushing list `ys` are empty), it returns `Nothing`, indicating that there are no elements to pop.
2. If the popping list `xs` is empty but the pushing list `ys` is not, it reverses the pushing list `ys` and uses it as the new popping list, then recursively calls `sqPop` on the updated queue.
3. If the popping list `xs` is not empty, it returns the first element `x` of the popping list `xs` along with the updated queue, where the popping list is now `xs` without its first element.

In the context of the `flattenBFS` function, `sqPop` is used to manage the queue of `Collapse` terms that need to be processed during the breadth-first search traversal. This allows the `flattenBFS` function to handle parallel computations efficiently by maintaining a queue of terms that are yet to be processed, ensuring that the traversal is performed in a breadth-first manner.

Overall, `sqPop` plays a crucial role in the efficient management of the queue data structure, enabling the HVM3 runtime to handle parallel computations effectively.
# sqPut
The `sqPut` function is defined as follows:
```haskell
sqPut :: a -> SQ a -> SQ a
sqPut x (SQ xs ys) = SQ xs (x:ys)
```
Here, `SQ` is a simple queue data structure that maintains two lists: `xs` (the front of the queue) and `ys` (the back of the queue). The `sqPut` function takes an element `x` and a queue `SQ xs ys`, and it appends `x` to the back of the queue by prepending it to the `ys` list. This operation is efficient because it only involves a single list cons operation (`x:ys`).

In the context of the `flattenBFS` function, `sqPut` is used to enqueue elements during a BFS traversal of a `Collapse` monad. The `Collapse` monad represents a computation that may have multiple possible outcomes or states, and `flattenBFS` is responsible for reducing these outcomes to a single list. By using `sqPut`, the function ensures that elements are processed in a breadth-first manner, which is essential for maintaining the correct order of evaluation in parallel computations.

Overall, `sqPut` is a simple yet crucial utility for managing queues in the HVM3 codebase, particularly in scenarios involving parallel evaluation and BFS traversal. Its efficient implementation supports the codebase's goal of handling complex, parallel computations effectively.
# sub
The `sub` function serves as a fundamental building block in the HVM3 runtime, enabling the dynamic manipulation of terms within the computational graph. Its primary role is to update the content of a specific memory location (`loc`) with a new term (`term`). This operation is essential during the reduction process, where terms are continuously transformed and replaced as part of the evaluation mechanism.

For example, in the `reduce_let` function, `sub` is used to substitute the value of a variable (`val`) into the body of a `let` expression. Similarly, in `reduce_app_lam`, it substitutes the argument of a function application into the body of a lambda abstraction. These substitutions are critical for correctly evaluating expressions and ensuring that the computational graph reflects the current state of the computation.

The `sub` function is also used in more complex reduction rules, such as `reduce_dup_lam` and `reduce_dup_sup`, where it helps manage the duplication and superposition of terms. By updating the relevant memory locations with the appropriate terms, `sub` ensures that the parallel evaluation model functions correctly and efficiently.

Overall, `sub` is a key operation in the HVM3 runtime, enabling the dynamic and parallel evaluation of terms by facilitating the substitution of terms within the computational graph.
# swap
The `swap` function serves a critical role in the HVM3 runtime's memory management and term manipulation. It takes two arguments: a memory location (`loc`) and a term (`term`). When invoked, it swaps the current term at the specified memory location with the provided term, returning the original term that was stored at that location. This operation is particularly useful in scenarios where terms need to be updated or replaced dynamically during the reduction process.

In the context of the HVM3 runtime, `swap` is often used in conjunction with other memory management functions like `set` and `got`. For example, `set` writes a term to a specific memory location, while `got` retrieves a term from a location. `swap` complements these operations by allowing the runtime to both update a term and retrieve the previous term in a single atomic operation, which is crucial for maintaining consistency in parallel execution.

Additionally, the `take` function, which is defined in terms of `swap`, demonstrates a common use case for `swap`. `take` retrieves the term at a given location and replaces it with `VOID`, effectively "taking" the term out of memory. This is implemented by calling `swap` with the location and `VOID`, highlighting how `swap` can be used to both retrieve and clear a term in one step.

Overall, `swap` is a fundamental operation in the HVM3 runtime, enabling efficient and atomic manipulation of terms in the computational graph, which is essential for the system's parallel evaluation model.
# tabDec
The `tabDec` function is defined as follows:
```haskell
tabDec :: Compile ()
tabDec = modify $ \st -> st { tabs = tabs st - 1 }
```
It operates within the `Compile` monad, which encapsulates the state of the compilation process. The function uses the `modify` operation to update the state by decrementing the `tabs` field by 1. This field represents the current indentation level, which is used to format the emitted C code with the appropriate number of tabs or spaces.

In the context of the HVM3 codebase, `tabDec` is typically called after emitting a block of code that requires indentation, such as the body of a function or a loop. For example, in the `compileFull` function, `tabDec` is called after emitting the function body and before closing the function definition with a closing brace. Similarly, in `compileFast`, `tabDec` is used to reduce the indentation level after emitting nested blocks of code, such as `if` statements or `switch` cases.

By managing the indentation level, `tabDec` ensures that the generated C code is well-formatted and easy to read, which is important for debugging and maintaining the runtime system. It works in tandem with `tabInc`, which increments the indentation level, to maintain a consistent and logical structure in the emitted code.
# tabInc
The `tabInc` function plays a crucial role in the code generation process by managing the indentation of the emitted C code. It works by modifying the state of the `Compile` monad, specifically incrementing the `tabs` field. This field tracks the current indentation level, which is used to format the generated code appropriately. For example, when compiling a function body or a nested conditional block, `tabInc` is called to increase the indentation level, ensuring that the emitted code is properly aligned. This improves the readability and maintainability of the generated C code, making it easier to debug and understand. The function is typically paired with `tabDec` (not shown in the context) to decrement the indentation level when exiting a nested block, ensuring that the indentation remains consistent throughout the compilation process.
# tagT
The `tagT` function serves as a bridge between the low-level representation of terms (using raw hexadecimal tags) and the high-level logic of the runtime system. It is defined in the Haskell frontend (`hvm.hs`) and is used in various parts of the codebase, especially in the reduction engine. For example, in the `reduceAt` function, `tagT` is used to determine the type of a term before applying the appropriate reduction rules. This ensures that the runtime can correctly handle different types of terms, such as `APP`, `MAT`, `OPX`, `OPY`, `DP0`, and `DP1`, among others. Additionally, `tagT` is used in debugging and diagnostic functions like `tagToString` and `termToString`, which convert tags and terms into human-readable strings for easier inspection and debugging. Overall, `tagT` plays a crucial role in the type-driven logic of the HVM3 runtime, enabling efficient and correct term reduction and manipulation.
# tagToString
The `tagToString` function takes a `Tag` as input and returns a `String` representation of that tag. The `Tag` type is likely an enumeration or a data type that represents different types of terms in the computational graph, such as `ERA`, `REF`, `NUM`, `CON`, or `DUP`. The function uses the `show` function to convert the `Tag` into a string, which is a common way to represent data types in Haskell for debugging or logging purposes.

In the context of the HVM3 codebase, `tagToString` is used within the `termToString` function to help convert a `Term` into a string. This is useful for developers who need to inspect the state of the computation or debug issues in the runtime. By converting the tag of a term into a string, developers can more easily understand the structure and type of the terms being processed by the runtime.

Overall, `tagToString` plays a small but important role in the HVM3 codebase by providing a way to visualize and debug the types of terms in the computational graph, aiding in the development and maintenance of the system.
# take
The `take` function serves the purpose of fetching a term from a given memory location (`loc`) in the runtime's memory model. This is crucial for the reduction process, where terms need to be accessed and modified dynamically. In the context of the `reduce_dup_sup` function, `take` is used to retrieve terms from specific locations in memory during the reduction of duplicated and superposed terms. This operation is essential for ensuring that the correct terms are processed and that the reduction rules are applied accurately. By providing a way to access terms directly from memory, `take` enables efficient and parallel evaluation of terms, which is a core feature of the HVM3 runtime system.
# termGetBit
The `termGetBit` function serves as a utility to extract a specific bit from a `Term` object, which is a fundamental data structure in the HVM3 runtime. This bit is used as a flag to control or influence the behavior of the runtime during term reduction and evaluation. For example, in the context of `VAR`, `DP0`, and `DP1` terms, `termGetBit` is used to check whether a subterm has a particular bit set, which can determine whether certain operations should be performed or whether the term should be further reduced. This function is essential for the runtime's decision-making process, ensuring that terms are processed correctly according to their internal state. The function's presence in both the Haskell and C parts of the codebase underscores its importance in the overall architecture of the HVM3 system, bridging high-level term manipulation with low-level runtime operations.
# termLab
The `termLab` function retrieves the label (`Lab`) of a given `Term`. In the HVM3 codebase, a `Term` represents a node in the computational graph, and its label provides additional metadata that is essential for various operations. For example:
- **Function IDs**: In the context of function calls (`REF`), the label contains the function ID, which is used to look up the corresponding function definition in the `Book` data structure.
- **Constructor IDs**: For constructors (`CTR`), the label contains the constructor ID, which is used during pattern matching (`MAT`) to determine the correct branch of execution.
- **Arity Information**: The label also encodes arity information, which is used to ensure that function calls have the correct number of arguments.

The `termLab` function is used in multiple reduction rules, such as `reduce_ref`, `reduce_dup_lam`, and `reduce_mat_ctr`, to extract the label and determine the appropriate reduction strategy. It is also used in debugging and diagnostic functions, like `print_term`, to provide detailed information about the state of the computation.

In summary, `termLab` is a fundamental function in the HVM3 codebase that enables the runtime system to interpret and manipulate terms based on their labels, ensuring correct and efficient execution of parallel computations.
# termLoc
The `termLoc` function is defined in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). Its purpose is to extract the `Loc` field from a `Term` data structure, which represents the memory address where the term is stored. This location is essential for operations like term reduction, where the runtime needs to access and manipulate terms in memory. For example, during the reduction process, `termLoc` is used to retrieve the memory addresses of subterms, enabling the runtime to apply reduction rules efficiently. Additionally, `termLoc` is used in debugging and diagnostic functions, such as `print_term`, to provide detailed information about the state of the computation. Overall, `termLoc` plays a critical role in the HVM3 runtime by facilitating efficient memory access and term manipulation, which are essential for the system's parallel execution model.
# termNew
The `termNew` function is used in various contexts within the HVM3 codebase to create new terms. For example, in the Haskell frontend, it is used during the compilation process to generate low-level C code representations of high-level `Core` terms. In the C backend, it is used during runtime to allocate and initialize new terms in memory. The function is also employed in reduction rules, where it constructs new terms as part of the evaluation process. For instance, in the `reduce_ref_sup` function, `termNew` is used to create new `REF` and `SUP` nodes during the reduction of a reference term. Similarly, in the `reduce_dup_lam` function, it is used to create new `LAM` and `SUP` nodes during the reduction of a duplication term. Overall, `termNew` is a critical utility that facilitates the creation and manipulation of terms, enabling the efficient execution of parallel computations in the HVM3 runtime system.
# termRemBit
The `termRemBit` function is a low-level operation that modifies a `Term` by removing a specific bit from it. This bit is likely used as a flag or marker within the term, and removing it changes the term's state or behavior. The function is called in several scenarios:

1. **Reduction Operations**: During the reduction of terms (e.g., in `reduce_dup_era`, `reduce_dup_lam`, `reduce_dup_sup`, etc.), `termRemBit` is used to clear a bit from a term after it has been processed. This ensures that the term is in the correct state for further evaluation.

2. **Memory Management**: In memory management operations, such as when setting or retrieving terms from specific memory locations, `termRemBit` is used to modify terms before they are stored or after they are retrieved. This helps maintain the integrity of the memory model and supports the parallel execution model.

3. **Term State Management**: The function is also used to manage the state of terms during various operations, such as when handling variables (`VAR`) or duplication (`DP0`, `DP1`). By removing a bit, the function ensures that terms are correctly interpreted and processed by the runtime.

Overall, `termRemBit` plays a crucial role in the HVM3 runtime by ensuring that terms are correctly modified and processed, which is essential for the efficient execution of parallel computations.
# termSetBit
The `termSetBit` function plays a crucial role in the HVM3 runtime by managing the internal state of `Term` objects. Specifically, it sets a bit within a term's representation, which is likely used as a flag to indicate whether the term has been evaluated or is in a specific state (e.g., normalized or reduced). This bit is checked in functions like `normalAtWith` to determine whether a term needs further reduction or can be returned as-is. By setting this bit, `termSetBit` ensures that terms are correctly marked after they have been processed, preventing redundant evaluations and optimizing the runtime's performance. The function is tightly integrated with the memory management system, as it is often used in conjunction with `set` to update terms in memory. This makes `termSetBit` a key component in the efficient execution of the Interaction Combinator model, enabling the runtime to handle parallel computations effectively.
# termTag
The `termTag` function is defined in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). Its primary purpose is to extract the tag from a `Term`, which is a numeric identifier representing the term's type. This tag is used throughout the codebase to guide the reduction process. For example, in the `reduceAt` function, the tag is used to determine which reduction rule to apply based on the term's type. Similarly, in the `compileFast` function, the tag is used to generate conditional statements in the compiled C code, ensuring that the correct operations are performed based on the term's type. The `termTag` function is also used in debugging and diagnostic output, allowing developers to inspect the state of the computation by printing the tag of a term. Overall, `termTag` is a fundamental utility that enables the runtime to manage and process terms efficiently, ensuring that the correct reduction rules are applied and that the system operates as intended.
# termToString
The `termToString` function serves as a critical debugging tool in the HVM3 codebase. It takes a `Term` as input, which represents a node in the computational graph, and converts it into a string that can be easily read and interpreted by developers. This is particularly useful in scenarios where runtime errors occur, as it allows developers to inspect the problematic term and understand its structure. For example, in the context of dynamic DUP operations, if an error arises due to an invalid label, `termToString` is used to print the label's string representation, aiding in diagnosing the issue. Additionally, `termToString` is used in the `heapToString` function to convert the entire heap's state into a readable format, providing a comprehensive view of the runtime's memory and term structures. Overall, `termToString` enhances the debuggability of the system by making the internal state of terms accessible and interpretable.
# term_get_bit
The `term_get_bit` function plays a critical role in the HVM3 runtime by providing a mechanism to inspect a specific bit within a `Term`. This bit is likely used as a flag to indicate certain properties or states of the term, such as whether it has been fully evaluated, is in a superposition state, or requires further reduction. The function is used extensively in the reduction engine, particularly in cases involving `VAR`, `DP0`, and `DP1` terms, where it helps determine the next steps in the evaluation process. For example, in the `VAR` case, `term_get_bit` is used to check if a subterm has been evaluated (bit is 0) or if further reduction is needed (bit is 1). Similarly, in `DP0` and `DP1` cases, it checks the state of subterms to decide whether to proceed with reduction or handle parallel execution. By providing this low-level bit inspection capability, `term_get_bit` ensures that the runtime can efficiently manage and process terms in a massively parallel environment, adhering to the Interaction Combinator model's principles.
# term_lab
The `term_lab` function is defined in both the Haskell frontend (`hvm.hs`) and the C backend (`hvm.c`). In the Haskell code, it is used to retrieve the label of a `Term` during various operations, such as reduction, compilation, and pattern matching. For example, in the `reduceAt` function, `term_lab` is used to determine the label of a term, which is then used to decide how to reduce it. Similarly, in the `compileFast` function, `term_lab` is used to check the label of a term to determine if it is a `SUP` (superposition) term, which requires special handling during compilation.

In the C backend, `term_lab` is implemented as a function that directly accesses the label field of a `Term`. This function is used in various reduction rules, such as `reduce_ref_sup`, `reduce_dup_lam`, and `reduce_mat_ctr`, where the label of a term is needed to determine the correct reduction strategy. For instance, in `reduce_ref_sup`, the label of a `REF` term is used to extract the function ID and arity, which are then used to perform the reduction.

Overall, `term_lab` plays a crucial role in the HVM3 runtime by providing access to the label of a `Term`, which is essential for the correct and efficient execution of the program. It is used in both the high-level Haskell code and the low-level C code, making it a fundamental part of the system's operation.
# term_loc
In the HVM3 codebase, the `term_loc` function plays a vital role in the runtime's ability to manage and manipulate terms. Each `Term` in the system is represented as a node in a computational graph, and the location of a term is essentially a pointer to where that term is stored in memory. This location is used in various operations, such as reducing terms, allocating new nodes, and accessing subterms.

For example, in the `reduceAt` function, `term_loc` is used to get the location of the term being reduced, which is then used to access and manipulate its subterms. Similarly, in the `compileFast` function, `term_loc` is used to generate C code that accesses terms at specific memory locations. The function is also used in the `reduce_ref_sup` and `reduce_dup_lam` functions to access the locations of terms involved in reduction rules.

Overall, `term_loc` is a fundamental utility that enables the runtime to efficiently navigate and manipulate the computational graph, ensuring that terms are processed correctly and efficiently.
# term_new
The `term_new` function is used in various contexts within the HVM3 codebase to create new `Term` instances. For example, during the compilation process in `hvm.hs`, it is used to generate C code that constructs terms for different constructs like `Lam`, `App`, `Sup`, and `Dup`. In the C backend (`hvm.c`), `term_new` is used in reduction rules and memory management functions to create and manipulate terms dynamically. For instance, in the `reduce_ref_sup` function, `term_new` is used to create new `REF` and `SUP` nodes during the reduction process. Similarly, in the `reduce_dup_lam` function, it is used to create new `LAM` and `SUP` nodes. The function is also used in debugging and diagnostic output, such as in the `print_term` function, to format and display term information. Overall, `term_new` is a core utility that facilitates the creation and management of terms, enabling the HVM3 runtime to execute programs efficiently on massively parallel hardware.
# term_rem_bit
The `term_rem_bit` function plays a crucial role in the HVM3 runtime by ensuring that terms are correctly updated during the reduction process. In the Interaction Combinator model, terms are represented as nodes in a computational graph, and each term contains metadata, including a bit that can be set or cleared to indicate certain states or conditions. When a term is processed (e.g., during duplication or substitution), the `term_rem_bit` function is used to clear this bit, effectively updating the term's state.

For example, in the `reduce_dup_era` function, after performing the necessary operations to handle an `ERA` term, the function calls `term_rem_bit` to clear the bit from the resulting term. This ensures that the term is in the correct state for further processing. Similarly, in `reduce_dup_lam`, `reduce_dup_sup`, and other reduction functions, `term_rem_bit` is used to finalize the term's state after complex operations involving lambda expressions, superposition, or constructors.

The function is also used in the context of memory management, where it helps ensure that terms are correctly updated in memory. For instance, in the `VAR`, `DP0`, and `DP1` cases, `term_rem_bit` is called to modify terms that have been retrieved from memory, ensuring that they are in the correct state before being used in further computations.

Overall, `term_rem_bit` is a low-level utility function that supports the higher-level reduction and memory management mechanisms in the HVM3 runtime, ensuring that terms are correctly processed and updated during parallel execution.
# term_set_bit
The `term_set_bit` function is a critical part of the HVM3 runtime's memory management and term evaluation system. Its primary role is to modify a bit within the `Term` data structure, which is used to represent nodes in the computational graph. This bit likely serves as a flag to indicate whether a term has been fully evaluated or is in a specific state (e.g., normalized or reduced). By setting this bit, the runtime can efficiently track the evaluation status of terms, avoiding redundant computations and ensuring correct parallel execution.

In the `normalAtWith` function, `term_set_bit` is used after reducing a term to its weak head normal form (`whnf`). This suggests that the bit is set to mark the term as evaluated, allowing the runtime to skip further reductions when the term is accessed again. This optimization is crucial for performance, especially in a massively parallel system where minimizing redundant work is essential.

The function is implemented in the C backend (`hvm.c`) and exposed to the Haskell frontend via FFI, highlighting its role as a low-level operation that bridges the high-level term manipulation in Haskell with the efficient memory management in C. Overall, `term_set_bit` is a small but vital component that supports the HVM3 runtime's ability to handle complex, parallel computations efficiently.
# term_tag
The `term_tag` function plays a pivotal role in the HVM3 runtime system by providing the type information of a `Term`. Each `Term` in the system is associated with a tag that indicates its type, such as `ERA`, `REF`, `NUM`, `CON`, `DUP`, etc. This tag is essential for the runtime to apply the correct reduction rules and optimizations during evaluation.

For example, in the reduction engine, the `reduce` function uses `term_tag` to determine the type of a term and then applies the appropriate reduction rules. Similarly, during compilation, the `compileFastCore` function uses `term_tag` to generate optimized C code based on the term's type. The `term_tag` function is also used in debugging and diagnostic functions like `print_term` to provide detailed information about the state of the computation.

In summary, `term_tag` is a fundamental utility in the HVM3 codebase that enables the runtime to efficiently manage and process terms by providing their type information. This function is integral to the correct and efficient execution of programs in the HVM3 system.
# u12v2New
The `u12v2New` function is a utility that combines two 12-bit values (`x` and `y`) into a single 64-bit unsigned integer. This encoding is useful in the HVM3 runtime for compactly storing pairs of small integers, such as function IDs and their arities, or constructor IDs and their arities. The function is defined in the C backend (`hvm.c`) and is called from the Haskell frontend (`hvm.hs`) during the compilation process. Specifically, it is used when creating new terms (`Term`) in the runtime, such as constructors (`Ctr`), matchers (`Mat`), and references (`Ref`). By encoding these pairs into a single 64-bit integer, the runtime can efficiently manage and manipulate terms, reducing memory overhead and improving performance. The function is essential for the correct operation of the runtime, as it ensures that the necessary metadata for each term is properly encoded and accessible during execution.
# u12v2X
The `u12v2X` function is a utility that extracts a specific component (likely the first 12 bits) from a 64-bit label (`Lab`). This extracted component is used to determine various attributes of terms, such as constructor IDs (`cid`), function IDs (`fid`), and lengths (`len`). For example:
- In `CTR` blocks, `u12v2X` is used to extract the constructor ID (`cid`) from the term's label.
- In `MAT` blocks, it extracts the length (`len`) of the match pattern.
- In `REF` blocks, it retrieves the function ID (`fid`) associated with the reference term.

This function is essential for the runtime to correctly interpret and process terms during reduction and evaluation. It ensures that the system can efficiently access and manipulate the metadata encoded in term labels, which is crucial for the parallel execution model of HVM3. The function's consistent use across different parts of the codebase highlights its role as a foundational utility in the Interaction Combinator model.
# u12v2Y
The `u12v2Y` function is a utility that extracts a specific piece of information from a term's label (`Lab`). In the HVM3 codebase, labels are used to encode metadata about terms, such as function IDs, constructor IDs, and arity. The `u12v2Y` function is specifically designed to extract the arity (`ari`) from a label, which represents the number of arguments a function or constructor expects. This information is crucial during term reduction and manipulation, as it determines how terms are processed and evaluated. For example, in the `reduce_ref_sup`, `reduce_dup_ctr`, and `reduce_mat_ctr` functions, `u12v2Y` is used to retrieve the arity of terms, enabling the runtime to correctly handle function application, duplication, and pattern matching. By providing this critical metadata, `u12v2Y` ensures that the runtime can efficiently and accurately execute parallel computations based on the Interaction Combinator model.
# u12v2_new
The `u12v2_new` function is a utility that constructs a label (`Lab`) by combining two 64-bit values (`x` and `y`) into a single 64-bit value. This label is used in the runtime system to encode metadata for terms, such as function IDs, constructor IDs, and arity. For example, when creating a `CTR` (constructor) term, `u12v2_new` is called with the constructor ID and the arity of the constructor. Similarly, for `MAT` (pattern matching) and `REF` (reference) terms, it is used to encode the number of cases and the function ID, respectively. The function is defined in the C backend (`hvm.c`) and is imported into the Haskell frontend (`hvm.hs`) via a foreign function interface (FFI). This allows the Haskell code to generate labels for terms during compilation and runtime initialization. The compact representation provided by `u12v2_new` is crucial for efficient memory usage and parallel execution in the HVM3 runtime system.
# u12v2_x
The `u12v2_x` function is a utility that extracts specific information from a term's label, which is represented as a 64-bit unsigned integer (`u64`). In the HVM3 runtime, term labels encode metadata such as function IDs, constructor IDs, or lengths, depending on the term's type. The `u12v2_x` function is used to decode this metadata by extracting the relevant portion of the label. For example:
- In `reduce_ref`, it extracts the function ID (`fun_id`) from the label of a reference term.
- In `reduce_mat_sup`, it extracts the length (`mat_len`) from the label of a match term.
- In `reduce_mat_ctr`, it extracts the constructor number (`ctr_num`) from the label of a constructor term.

This function is essential for the runtime to correctly interpret and process terms during reduction and evaluation. It ensures that the system can efficiently access the necessary metadata encoded in term labels, enabling operations like function application, pattern matching, and parallel execution.
# u12v2_y
The `u12v2_y` function is a low-level utility that extracts a specific piece of information from a label (`Lab`) associated with a term. In the HVM3 codebase, labels are used to store metadata about terms, such as function IDs, constructor IDs, and arity. The `u12v2_y` function is specifically used to extract the arity (number of arguments) of a function or constructor from its label. This is crucial for the reduction engine, as it needs to know how many arguments a function or constructor expects to correctly apply reduction rules.

For example:
- In `reduce_ref_sup`, `u12v2_y` is used to extract the arity of a reference term (`ref_lab`), which determines how many arguments the referenced function expects.
- In `reduce_dup_ctr`, it extracts the arity of a constructor term (`ctr_lab`), which is necessary for handling duplication operations.
- In `reduce_mat_ctr`, it extracts the arity of a constructor term (`ctr_lab`) to correctly apply pattern matching rules.

The function is part of the runtime's low-level machinery, enabling efficient decoding of term metadata and ensuring that the reduction engine can operate correctly based on the structure of the terms it processes.
# u32
In the HVM3 codebase, `u32` serves as a fundamental data type for representing various components of the computational graph. Specifically:
1. **Memory Management**: `u32` is used to define memory locations (`Loc`) and labels (`Lab`) for terms. This allows the runtime to efficiently allocate, access, and manipulate terms in memory.
2. **Term Representation**: `u32` is used to store tags (`Tag`) that identify the type of a term (e.g., `ERA`, `REF`, `NUM`, `CON`, `DUP`). This enables the runtime to apply the correct reduction rules based on the term's type.
3. **Reduction Operations**: In functions like `reduce_ref_sup` and `reduce_opy_w32`, `u32` is used to store indices, tags, and intermediate results during the reduction process. This ensures that the reduction engine can handle parallel computations efficiently.
4. **Compilation**: During the compilation process, `u32` is used to generate low-level C code that interacts with the runtime. For example, in the Haskell frontend, `u32` is used to emit C code that retrieves and manipulates term locations and tags.

Overall, `u32` is a critical component of the HVM3 codebase, providing a consistent and efficient way to manage memory, represent terms, and execute reduction operations in a massively parallel environment.
# u64
In the HVM3 codebase, `u64` is defined as a type alias for `uint64_t` in the C backend (`hvm.c`). This type is used in various contexts, including:
1. **Memory Management**: Functions like `alloc_node`, `inc_itr`, and `reduce_ref_sup` use `u64` to manage memory addresses, iteration counts, and other numerical values that require a large range.
2. **Parallel Execution**: The `Collapse` monad and functions like `reduce_dup_ctr` and `reduce_mat_sup` use `u64` to handle indices, counts, and other numerical data that are critical for parallel computation.
3. **Global State**: The global state structure (`HVM`) uses `u64` for fields like `spos`, `size`, `itrs`, and `frsh`, which track the state of the runtime, including stack positions, heap sizes, and interaction counts.
4. **Compilation**: In the Haskell frontend (`hvm.hs`), `u64` is used in the compilation process to handle function IDs and other numerical values that are passed to the C backend.

The use of `u64` ensures that the HVM3 runtime can handle large numerical values efficiently, which is essential for its massively parallel execution model. This type provides the necessary range and precision to manage memory, iterations, and other numerical data without overflow or loss of precision.
